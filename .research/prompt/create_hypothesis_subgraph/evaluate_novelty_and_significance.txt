
LLM Name: o3-2025-04-16
Input:
You are an accomplished researcher in machine learning. You are considering a new hypothesis described in "New Hypothesis" for the research theme provided in "Research Topic". "Related Works" is a list of research papers that are highly relevant to this new hypothesis.
Based on the following instructions, output the reasons for the novelty and significance of the newly proposed hypothesis, and quantitatively evaluate them.

# Research Topic
Improving fine-tuning performance of language models.

# New Hypothesis
{
    "Open Problems": "Spectral Adapter tunes only a fixed top-r subset of singular vectors. If r is chosen too small, capacity is insufficient; if too large, many trainable parameters are wasted. Currently the user must hand-pick r for every layer/task.",
    "Methods": "Weighted Spectral Adapter (WSA).  \n1. Keep exactly the same re-parameterisation as Spectral-AdapterA (additive update of the r leading singular vectors).  \n2. Introduce a learnable gating vector g∈R^r (one scalar per adapted singular direction). The effective singular-value scaling becomes S’ = S * (1 + g⊙Δ), where Δ=softsign(s) and s is an unconstrained parameter initialised at 0.  \n3. Add an ℓ1 penalty λ‖g‖₁ to the training objective.  \n4. At inference time directions whose |g_i|<τ (e.g. 0.05) are pruned, giving an automatically selected effective rank.  \nMotivation:  the sparsity penalty lets the model decide how many spectral directions are worth adapting instead of fixing this hyper-parameter manually; unused parameters naturally shrink to zero, so no extra inference cost is incurred.",
    "Experimental Setup": "Model: DeBERTa-v3-base (185 M) fine-tuned on the single-sentence SST-2 task.  \nBaselines: (a) Full fine-tune, (b) Spectral-AdapterA with r=8 (original), (c) LoRA r=8.  \nProposed: WSA with initial r=16, λ=1e-3.  \nTraining: 3 epochs, batch 32, AdamW lr 2e-5, same for all methods.  \nAfter training, compute the effective rank r_eff = |{i : |g_i| ≥ 0.05}|.  \nMetric: validation accuracy on SST-2 dev set.  \nHardware: single RTX-A6000; total run time ≤30 min.",
    "Primary Metric": "accuracy",
    "Experimental Code": "import torch, torch.nn as nn, torch.nn.functional as F\nclass WeightedSpectralAdapter(nn.Module):\n    def __init__(self, base_linear, r_init=16):\n        super().__init__()\n        w = base_linear.weight.data\n        U,S,Vt = torch.linalg.svd(w, full_matrices=False)\n        self.register_buffer('U',U[:,:r_init])\n        self.register_buffer('Vt',Vt[:r_init])\n        self.register_buffer('S',S[:r_init])\n        # trainable params\n        self.delta_U = nn.Parameter(torch.zeros_like(self.U))\n        self.delta_V = nn.Parameter(torch.zeros_like(self.Vt))\n        self.scores   = nn.Parameter(torch.zeros(r_init))  # produces g via softsign\n        self.base_linear = base_linear  # for bias & fallback\n    def forward(self,x):\n        g = torch.tanh(self.scores)          # in (-1,1)\n        S_eff = self.S * (1+g)               # 1 means no change\n        U_eff = self.U + self.delta_U\n        V_eff = self.Vt + self.delta_V\n        W_delta = (U_eff * S_eff) @ V_eff    # r x d  * d x r\n        W = self.base_linear.weight + W_delta\n        return F.linear(x, W, self.base_linear.bias)\n# loss regulariser to be added each step\n# reg_loss = lambda_l1 * torch.abs(torch.tanh(scores)).sum()",
    "Expected Result": "WSA should reach ≈94.3 % dev accuracy vs 93.7 % for fixed-rank Spectral-AdapterA and 93.0 % for LoRA, while selecting r_eff≈6–7 directions on average (starting from 16). Parameter count therefore stays comparable to Spectral-AdapterA despite starting with twice the rank.",
    "Expected Conclusion": "A simple ℓ1-gated scaling of singular values lets the model automatically choose its effective spectral rank. This removes the manual r hyper-parameter, yields slightly better accuracy, and keeps parameter-efficiency because unused directions are pruned. The modification touches only the objective (add ℓ1 term) and two small vectors, so it can be dropped into any existing Spectral Adapter codebase with minimal effort."
}

# Related Works
{
    "Title": "Spectral Adapter: Fine-Tuning in Spectral Space",
    "Main Contributions": "The paper introduces Spectral Adapter, a novel Parameter-Efficient Fine-Tuning (PEFT) method that enhances existing PEFT techniques by incorporating spectral information of pretrained weight matrices into the fine-tuning process. It proposes two mechanisms: Spectral AdapterA (additive tuning) and Spectral AdapterR (orthogonal rotation) of the top singular vectors obtained via Singular Value Decomposition (SVD). The theoretical analysis demonstrates that Spectral AdapterA doubles the rank capacity of LoRA given the same trainable parameter budget. Experimentally, Spectral Adapter shows superior parameter efficiency, improved tuning performance in language and diffusion models, and effectively addresses multi-adapter fusion challenges by distributing concept tunings along different spectral spaces.",
    "Methodology": "The Spectral Adapter methodology involves two main mechanisms applied after performing Singular Value Decomposition (SVD) on pretrained weight matrices (W = USV^T). Spectral AdapterA (additive) modifies the top-r columns of U and V (U1, V1) by adding trainable matrices AU and AV, resulting in W' = [U1 + AU U2]S[V1 + AV V2]^T. Spectral AdapterR (rotational) orthogonally rotates the top-r columns of U and V using trainable orthogonal matrices RU and RV, defined as W' = [U1 RU U2]S[V1 RV V2]^T. The orthogonality constraint for RU and RV is efficiently handled using Cayley parameterization (R = (I + Q)(I - Q)^-1, where Q is a skew-symmetric matrix derived from a trainable parameter A as (A - A^T)/2). Both methods focus on tuning the top spectral space, with AU and AV initialized to zero, and RU and RV to identity matrices, respectively. Theoretical insights support tuning top singular vectors by analyzing adapter rank capacity and weight subspace alignment.",
    "Experimental Setup": "The proposed Spectral Adapter was evaluated on both large language models (LLMs) and diffusion models against various PEFT baselines. For LLMs, DeBERTaV3-base (185M) was fine-tuned on GLUE benchmarks, and Mistral 7B was fine-tuned on the GSM8K task. For diffusion models, Chilloutmix was fine-tuned for multi-object fusion and parameter efficiency experiments. Multi-object generation involved custom animal and toy concepts, as well as multi-character generation for computer scientists, utilizing T2I-Adapter with sketch/keypose conditions. Parameter efficiency was assessed by fine-tuning on custom vase, chair, and table concepts. Baselines included LoRA, DoRA, OFT, AdaLoRA, SVDiff, LiDB, VeRA, Gradient Fusion, Orthogonal Adaptation, and FedAvg, with their official implementations and reported hyperparameters used where available. Evaluation metrics included training loss, validation scores (accuracy for LLMs), visual quality for diffusion models, and quantitative alignment scores computed using CLIP embeddings for images and texts. All experiments were conducted on NVIDIA RTX A6000 GPUs.",
    "Limitations": "The primary limitation lies in the current fixed choice of tuning only the top spectral space. While theoretically supported under simplified conditions, further in-depth investigation into tuning different columns or regions of singular vector matrices is crucial to fully comprehend the intricate role of spectral information in fine-tuning. Additionally, the time cost associated with the Singular Value Decomposition (SVD) procedure increases with larger model sizes, which could pose a practical challenge, despite potential solutions like randomized SVD and parallelization.",
    "Future Research Directions": "Future work could explore fine-tuning the spectral representation of specific model components, such as only the attention layer in large models. There's also potential to dynamically combine Spectral Adapter with other adaptive PEFT methods like AdaLoRA. A deeper investigation into tuning various columns of singular vector matrices, beyond just the top ones, is recommended to further understand the impact of spectral information. Furthermore, research into developing faster Singular Value Decomposition (SVD) methods would be beneficial to alleviate the computational overhead as models continue to grow in size.",
    "Experiment Code": "class SpectralLinearLayer_OFT(nn.Module):    def __init__(self, name, original_module, rank=4, alpha=1, top=True, idx=0, revised_r=-1):        rank = 8        super().__init__()        self.name = name        if original_module.__class__.__name__ == 'Conv2d':            self.conv = True            in_channels, out_channels = original_module.in_channels, original_module.out_channels        else:            self.conv = False            in_channels, out_channels = original_module.in_features, original_module.out_features        W = original_module.weight.data.view(out_channels, in_channels)        U, S, V = torch.svd(W)        self.U = torch.nn.Parameter(U, requires_grad=False)        self.S = torch.nn.Parameter(S, requires_grad=False)        self.V = torch.nn.Parameter(V, requires_grad=False)        self.spectral_A = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True)        self.spectral_B = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True)        self.spectral_C = torch.nn.Parameter(torch.ones(revised_r), requires_grad=True)        original_module.forward = self.forward        self.original_module = original_module        self.top = top        self.idx = idx        assert revised_r>0        self.rank = revised_r    def cayley(self, data: torch.Tensor) -> torch.Tensor:        r, _ = data.shape        skew = 0.5 * (data - data.T)        I = torch.eye(r, device=data.device)        Q = torch.mm(I - skew, torch.inverse(I + skew))        return Q    def forward(self, hidden_states):        if self.top:            pad_U = self.U.clone()            pad_U[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.U[:,self.idx*self.rank:(self.idx+1)*self.rank]@self.cayley(self.spectral_A)            pad_S = self.S.clone()            pad_S[self.idx*self.rank:(self.idx+1)*self.rank] = self.S[self.idx*self.rank:(self.idx+1)*self.rank]*self.spectral_C            pad_V = self.V.clone()            pad_V[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.V[:,self.idx*self.rank:(self.idx+1)*self.rank]@self.cayley(self.spectral_B)        else:            raise Exception('')        pad_W = pad_U@pad_S.diag()@pad_V.T        if self.conv :            raise Exception('')        else:            return F.linear(hidden_states, pad_W, bias=self.original_module.bias)def merge_spectraloft_into_weight(original_state_dict, lora_state_dict, model_type, alpha, top=True, idx=0):    def get_spectral_A_name(original_layer_name):        if model_type == 'text_encoder':            spectral_A_name = original_layer_name.replace('q_proj.weight', 'q_proj.spectral_A')                 .replace('k_proj.weight', 'k_proj.spectral_A')                 .replace('v_proj.weight', 'v_proj.spectral_A')                 .replace('out_proj.weight', 'out_proj.spectral_A')                 .replace('fc1.weight', 'fc1.spectral_A')                 .replace('fc2.weight', 'fc2.spectral_A')        else:            spectral_A_name = k.replace('to_q.weight', 'to_q.spectral_A')                 .replace('to_k.weight', 'to_k.spectral_A')                 .replace('to_v.weight', 'to_v.spectral_A')                 .replace('to_out.0.weight', 'to_out.0.spectral_A')                 .replace('ff.net.0.proj.weight', 'ff.net.0.proj.spectral_A')                 .replace('ff.net.2.weight', 'ff.net.2.spectral_A')                 .replace('proj_out.weight', 'proj_out.spectral_A')                 .replace('proj_in.weight', 'proj_in.spectral_A')        return spectral_A_name        def cayley(data):        r, _ = data.shape        skew = 0.5 * (data - data.T)        I = torch.eye(r, device=data.device)        Q = torch.mm(I - skew, torch.inverse(I + skew))        return Q    assert model_type in ['unet', 'text_encoder']    new_state_dict = copy.deepcopy(original_state_dict)    load_cnt = 0    for k in new_state_dict.keys():        spectral_A_name = get_spectral_A_name(k)        spectral_B_name = spectral_A_name.replace('spectral_A', 'spectral_B')        spectral_C_name = spectral_A_name.replace('spectral_A', 'spectral_C')        U_name = spectral_A_name.replace('spectral_A', 'U')        S_name = spectral_A_name.replace('spectral_A', 'S')        V_name = spectral_A_name.replace('spectral_A', 'V')        if spectral_B_name in lora_state_dict:            load_cnt += 1            original_params = new_state_dict[k]            spectral_A_params = lora_state_dict[spectral_A_name].to(original_params.device)            spectral_B_params = lora_state_dict[spectral_B_name].to(original_params.device)            spectral_C_params = lora_state_dict[spectral_C_name].to(original_params.device)            U_params = lora_state_dict[U_name].to(original_params.device)            S_params = lora_state_dict[S_name].to(original_params.device)            V_params = lora_state_dict[V_name].to(original_params.device)            r = spectral_A_params.shape[0]            if top:                pad_U = U_params                 pad_U[:,idx*r:(idx+1)*r] = U_params[:,idx*r:(idx+1)*r]@(alpha*(cayley(spectral_A_params)-torch.eye(r).to(spectral_A_params.device))+torch.eye(r).to(spectral_A_params.device))                pad_V = V_params                pad_V[:,idx*r:(idx+1)*r] = V_params[:,idx*r:(idx+1)*r]@(alpha*(cayley(spectral_B_params)-torch.eye(r).to(spectral_A_params.device))+torch.eye(r).to(spectral_A_params.device))                pad_S = S_params                 pad_S[idx*r:(idx+1)*r] = S_params[idx*r:(idx+1)*r]*(alpha*(spectral_C_params-torch.ones(r).to(spectral_A_params.device))+torch.ones(r).to(spectral_A_params.device))            else:                raise Exception('')            if len(original_params.shape) == 4:                raise Exception('')            else:                spectral_param = pad_U@pad_S.diag()@pad_V.T            new_state_dict[k] = spectral_param    print(f'load {load_cnt} Spectrals of {model_type}')    return new_state_dict",
    "Experiment Result": "The method performs Singular Value Decomposition (SVD) on the pretrained weight matrices (W = USV^T). It then applies modifications to the top-`rank` spectral components of U, S, and V. Specifically, trainable matrices `spectral_A` and `spectral_B` are used to orthogonally rotate the top-`rank` columns of U and V, respectively. These matrices are initialized to zeros, and Cayley parametrization (R = (I - Q)(I + Q)^-1, where Q is a skew-symmetric matrix derived from `spectral_A` or `spectral_B`) is employed to ensure orthogonality. A trainable vector `spectral_C`, initialized to ones, is used to scale the top-`rank` singular values. During the merging process, an `alpha` parameter is applied to scale the *delta* changes (i.e., `Cayley(A) - I`, `Cayley(B) - I`, and `C - 1`) before reconstructing the final weight matrix. The effective rank of adaptation (referred to as `revised_r` in the code) is dynamically determined by the configuration (`text_encoder_cfg['lora_cfg']['rank']` or `unet_cfg['lora_cfg']['rank']`) provided during initialization. This implementation is designed for linear layers and does not support convolutional layers."
}{
    "Title": "Parameter-Efficient Fine-Tuning Design Spaces",
    "Main Contributions": "The main research problem addresses the lack of systematic understanding of parameter-efficient fine-tuning (PEFT) strategies, which are often hand-crafted without clear design patterns across different strategies, backbone models, and tasks. The paper introduces a PEFT design paradigm by defining parameter-efficient fine-tuning design spaces, characterized by four components: layer grouping, trainable parameter allocation, tunable groups, and strategy assignment. Key contributions include the empirical discovery of several design patterns: (i) grouping layers in a spindle pattern; (ii) uniformly allocating the number of trainable parameters to layers; (iii) tuning all groups; and (iv) assigning proper tuning strategies to different groups. These discovered design patterns lead to new PEFT methods (S4-model and S4-3b-model) that consistently and significantly outperform existing individual PEFT strategies across various backbone models (T5, RoBERTa, BART, XLNet) and diverse NLP tasks (GLUE, XSum summarization, WMT machine translation, SuperGLUE).",
    "Methodology": "The methodology involves defining parameter-efficient fine-tuning design spaces with four components: layer grouping, trainable parameter allocation, tunable groups, and strategy assignment (using Adapter, Prefix, BitFit, LoRA). The discovery process starts from an unconstrained initial design space (S0) and progressively refines it by adding constraints based on model quality. A greedy selection approach is used at each stage over the four components. To quantify model quality in any design space, 100 models are randomly sampled from that space, fine-tuned for 3 epochs (low-compute, low-epoch regime), and their average GLUE performance is computed. Specific patterns explored include: 5 layer grouping patterns (Increasing, Uniform, Decreasing, Spindle, Bottleneck), 3 parameter allocation patterns (Increasing, Uniform, Decreasing), various combinations of tunable groups, and iterative strategy assignment for each group.",
    "Experimental Setup": "Design patterns were discovered primarily using T5-base and T5-3b as backbone models. The discovery process utilized the GLUE benchmark (SST-2, CoLA, QQP, STS-B, MRPC, MNLI, QNLI, RTE), with evaluation metrics including Matthews correlation (CoLA), Spearman correlation (STS-B), and accuracy for others. For discovery, the total trainable parameters were set to 0.5% of the backbone model. The discovered S4-model and S4-3b-model were then extensively evaluated for general effectiveness on: (i) GLUE with T5-base/3b and RoBERTa-base/large backbones; (ii) Generation tasks (Abstractive Summarization with XSum, Machine Translation with WMT 2016 en-ro) using BART-base/large backbones; and (iii) SuperGLUE datasets with XLNet-base/large backbones. Baselines included Full Fine-tuning, Adapter, Prefix, BitFit, LoRA, and sometimes S0-model (random designs) and S3-model (random strategy assignment). Evaluation parameters included 0.5% trainable parameters for most PEFT methods (0.1% for BitFit), linear decay scheduler (warmup 0.06), batch size 128 (base) / 64 (large), max learning rate 5e-5, and 5 or 10 training epochs. All experiments were performed using 8 A100 GPUs, with results averaged over 20 random runs (10 for SuperGLUE) and statistical significance reported.",
    "Limitations": "The study's primary limitation is that its goal was not to enumerate all possible design spaces or discover the single 'best' design space/method, but rather to demonstrate the utility of the design space perspective in informing PEFT research. Consequently, the discovered patterns, while effective, might not represent a globally exhaustive or optimal set, especially given computational constraints that limited the search space. The pattern discovery process relied on a low-compute, low-epoch regime (3 epochs), which is a simplification for efficiency, despite checks for performance stability. Additionally, the specific discovery sequence (grouping, then parameter allocation, then tunable groups, then strategy assignment) was a chosen heuristic and not necessarily the only or universally optimal order for exploring the design space.",
    "Future Research Directions": "Not explicitly mentioned, but implied by the work are potential future research directions. These could include exploring more complex or granular design choices for each of the four components (layer grouping, parameter allocation, tunable groups, strategy assignment), investigating alternative discovery sequences or automated search methods (e.g., using neural architecture search techniques) within the design spaces to find potentially superior patterns. Further research could also delve into the theoretical reasons behind the effectiveness of the discovered patterns and apply this design space methodology to other model architectures or domains beyond NLP to assess its generality. Evaluating the discovered patterns on an even wider and more diverse range of models and tasks would also be a valuable extension.",
    "Experiment Code": "# Adapters\nif is_torch_available():\n    _import_structure[\"adapters\"] = [\n        \"ADAPTER_CACHE\",\n        \"ADAPTER_CONFIG_MAP\",\n        \"ADAPTERFUSION_CONFIG_MAP\",\n        \"ADAPTER_MODEL_MAPPING\",\n        \"DEFAULT_ADAPTER_CONFIG\",\n        \"DEFAULT_ADAPTERFUSION_CONFIG\",\n        \"MODEL_WITH_HEADS_MAPPING\",\n        \"AdapterArguments\",\n        \"AdapterConfig\",\n        \"AdapterConfigBase\",\n        \"AdapterFusionConfig\",\n        \"AdapterInfo\",\n        \"AdapterLayer\",\n        \"AdapterLayerBase\",\n        \"AdapterSetup\",\n        \"AdapterTrainer\",\n        \"AdapterType\",\n        \"AutoAdapterModel\",\n        \"AutoModelWithHeads\",\n        \"BartAdapterModel\",\n        \"BartModelWithHeads\",\n        \"BeitAdapterModel\",\n        \"BertAdapterModel\",\n        \"BertModelWithHeads\",\n        \"CompacterConfig\",\n        \"CompacterPlusPlusConfig\",\n        \"ConfigUnion\",\n        \"DebertaAdapterModel\",\n        \"DebertaV2AdapterModel\",\n        \"DistilBertAdapterModel\",\n        \"DistilBertModelWithHeads\",\n        \"DynamicAdapterFusionConfig\",\n        \"EmbeddingAdaptersMixin\",\n        \"ForwardContext\",\n        \"GPT2AdapterModel\",\n        \"GPT2ModelWithHeads\",\n        \"GPTJAdapterModel\",\n        \"HoulsbyConfig\",\n        \"HoulsbyInvConfig\",\n        \"IA3Config\",\n        \"InvertibleAdaptersMixin\",\n        \"LoRAConfig\",\n        \"MAMConfig\",\n        \"MBartAdapterModel\",\n        \"MBartModelWithHeads\",\n        \"ModelAdaptersConfig\",\n        \"ModelAdaptersMixin\",\n        \"ModelWithFlexibleHeadsAdaptersMixin\",\n        \"ModelWithHeadsAdaptersMixin\",\n        \"MultiLingAdapterArguments\",\n        \"ParallelConfig\",\n        \"PfeifferConfig\",\n        \"PfeifferInvConfig\",\n        \"PrefixTuningConfig\",\n        \"RobertaAdapterModel\",\n        \"RobertaModelWithHeads\",\n        \"Seq2SeqAdapterTrainer\",\n        \"StaticAdapterFusionConfig\",\n        \"T5AdapterModel\",\n        \"T5ModelWithHeads\",\n        \"PEFTConfig\",\n        \"ViTAdapterModel\",\n        \"XLMRobertaAdapterModel\",\n        \"XLMRobertaModelWithHeads\",\n        \"get_adapter_config_hash\",\n        \"get_adapter_info\",\n        \"list_adapters\",\n    ]",
    "Experiment Result": "The provided repository content (setup.py, __init__.py, etc.) primarily contains package setup, module import structures, utility functions, benchmarking infrastructure, and CLI commands. It does not include specific experimental settings such as the number of models sampled (e.g., 100 models), the number of fine-tuning epochs (e.g., 3 epochs), the performance metric (e.g., average GLUE performance), or the definitions of specific layer grouping/parameter allocation patterns (e.g., Increasing, Uniform, Decreasing, Spindle, Bottleneck) as described in the \"Method\" section."
}{
    "Title": "ReFT: Representation Finetuning for Language Models",
    "Main Contributions": "The paper introduces Representation Finetuning (ReFT), a family of parameter-efficient finetuning methods that learn task-specific interventions on hidden representations of frozen base language models. It defines a strong instance, Low-rank Linear Subspace ReFT (LoReFT), and an ablation, DiReFT. ReFT methods are shown to be 15x–65x more parameter-efficient than LoRA while achieving competitive or state-of-the-art performance across diverse NLP benchmarks, including commonsense reasoning, instruction-following, and natural language understanding. A generic ReFT training library is also released.",
    "Methodology": "ReFT methods operate on frozen base models and train interventions that manipulate a small fraction of model representations. LoReFT builds on the distributed alignment search (DAS) method, intervening on hidden representations in the linear subspace spanned by a low-rank projection matrix, R. Its intervention function is defined as ΦLoReFT(h) = h + Rᵀ(Wh + b - Rh), where R has orthonormal rows, and W, b are learned parameters. DiReFT is an ablation that removes the orthogonality constraint and difference operation, using ΦDiReFT(h) = h + Wᵀ₂(W₁h + b), resembling LoRA applied directly to hidden representations. Training objectives include cross-entropy loss for language modeling in generation tasks and a classification head with cross-entropy loss for single-label classification tasks. Interventions are defined by a function, a set of input positions (P), and a layer (l).",
    "Experimental Setup": "Experiments were conducted on LLaMA-family models (LLaMA-1 7B/13B, Llama-2 7B, Llama-3 8B) and RoBERTa models (RoBERTa-base 125M, RoBERTa-large 350M). Benchmarks included: eight commonsense reasoning tasks (BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC-e, ARC-c, OBQA) finetuned on a combined COMMONSENSE 170K dataset; four arithmetic reasoning tasks (AQuA, GSM8K, MAWPS, SVAMP) finetuned on a combined MATH10K dataset; instruction-following using Llama-2 7B with Ultrafeedback, evaluated via Alpaca-Eval v1.0 (win-rate against text-davinci-003 using GPT-4 as annotator); and the GLUE benchmark for natural language understanding. Comparisons were made against state-of-the-art PEFTs such as prefix-tuning, adapter-tuning (Series/Parallel), BitFit, RED, LoRA, and DoRA. Hyperparameters were tuned on standalone development sets to prevent test-set overfitting.",
    "Limitations": "The research primarily explored the LLaMA-family of models, with potential for further exploration on other model families and vision-language models like LLaVA. The capabilities of ReFT have not been fully explored due to a large hyperparameter search space, suggesting a need for automated search. The paper also acknowledges that the precise reasons *why* ReFT works are not yet fully understood, proposing further exploration into memorization and causal pathways. A broader limitation in PEFT research practices is highlighted, where 'test-set hill-climbing' in hyperparameter tuning leads to overfitting and impedes fair comparisons.",
    "Future Research Directions": "Future research directions include exploring the effectiveness of ReFT on other model families (beyond LLaMA-family) and vision-language models such as LLaVA. Automating the hyperparameter search process for ReFT is also a suggested area. Deeper exploration into the underlying mechanisms of *why* ReFT works, including studies on memorization and the creation/modification of causal pathways, is proposed. Developing more structured ReFTs to modify complex causal pathways in LMs is also a future direction. Additionally, the authors advocate for the introduction of new benchmarks for evaluating PEFTs and ReFTs that allow for compute- or time-matched hyperparameter-tuning comparisons and strictly disallow tuning or model selection based on test sets.",
    "Experiment Code": "import torch\nfrom collections import OrderedDict\nfrom pyvene import (SourcelessIntervention,TrainableIntervention,DistributedRepresentationIntervention,)\nfrom transformers.activations import ACT2FN\nclass LowRankRotateLayer(torch.nn.Module):\n    \"\"\"A linear transformation with orthogonal initialization.\"\"\"\n    def __init__(self, n, m, init_orth=True):\n        super().__init__()\n        # n > m\n        self.weight = torch.nn.Parameter(torch.empty(n, m), requires_grad=True)\n        if init_orth:\n            torch.nn.init.orthogonal_(self.weight)\n    def forward(self, x):\n        return torch.matmul(x.to(self.weight.dtype), self.weight)\nclass LoreftIntervention(SourcelessIntervention,TrainableIntervention,DistributedRepresentationIntervention):\n    \"\"\"\n    LoReFT(h) = h + R^T(Wh + b − Rh)\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs, keep_last_dim=True)\n        rotate_layer = LowRankRotateLayer(\n            self.embed_dim, kwargs[\"low_rank_dimension\"], init_orth=True)\n        self.rotate_layer = torch.nn.utils.parametrizations.orthogonal(rotate_layer)\n        self.learned_source = torch.nn.Linear(\n            self.embed_dim, kwargs[\"low_rank_dimension\"]).to(\n            kwargs[\"dtype\"] if \"dtype\" in kwargs else torch.bfloat16)\n        self.dropout = torch.nn.Dropout(kwargs[\"dropout\"] if \"dropout\" in kwargs else 0.0)\n        self.act_fn = ACT2FN[\"linear\"] if \"act_fn\" not in kwargs or kwargs[\"act_fn\"] is None else ACT2FN[kwargs[\"act_fn\"]]\n    def forward(\n        self, base, source=None, subspaces=None\n    ):\n        rotated_base = self.rotate_layer(base)\n        output = base + torch.matmul(\n            (self.act_fn(self.learned_source(base)) - rotated_base), self.rotate_layer.weight.T\n        )\n        return self.dropout(output.to(base.dtype))\nimport copy\nimport torch.nn as nn\nimport pyvene as pv\nfrom torch.utils.data import DataLoader\nfrom transformers import DataCollatorForSeq2Seq\nfrom datasets import Dataset\nfrom typing import Dict, Union, List, Tuple, Optional\nfrom trl import DPOTrainer\ndef parse_positions(positions: str):\n    first_n, last_n = 0, 0\n    if \"+\" in positions:\n        first_n = int(positions.split(\"+\")[0].strip(\"f\"))\n        last_n = int(positions.split(\"+\")[1].strip(\"l\"))\n    else:\n        if \"f\" in positions:\n            first_n = int(positions.strip(\"f\"))\n        elif \"l\" in positions:\n            last_n = int(positions.strip(\"l\"))\n    return first_n, last_n\ndef get_intervention_locations(**kwargs):\n    share_weights = kwargs[\"share_weights\"] if \"share_weights\" in kwargs else False\n    last_position = kwargs[\"last_position\"]\n    if \"positions\" in kwargs:\n        _first_n, _last_n = parse_positions(kwargs[\"positions\"])\n    else:\n        _first_n, _last_n = kwargs[\"first_n\"], kwargs[\"last_n\"]\n    num_interventions = kwargs[\"num_interventions\"]\n    pad_mode = kwargs[\"pad_mode\"] if \"pad_mode\" in kwargs else \"first\"\n    first_n = min(last_position // 2, _first_n)\n    last_n = min(last_position // 2, _last_n)\n    pad_amount = (_first_n - first_n) + (_last_n - last_n)\n    pad_position = -1 if pad_mode == \"first\" else last_position\n    if share_weights or (first_n == 0 or last_n == 0):\n        position_list = [i for i in range(first_n)] + \\\n            [i for i in range(last_position - last_n, last_position)] + \\\n            [pad_position for _ in range(pad_amount)]\n        intervention_locations = [position_list]*num_interventions\n    else:\n        left_pad_amount = (_first_n - first_n)\n        right_pad_amount = (_last_n - last_n)\n        left_intervention_locations = [i for i in range(first_n)] + [pad_position for _ in range(left_pad_amount)]\n        right_intervention_locations = [i for i in range(last_position - last_n, last_position)] + \\\n            [pad_position for _ in range(right_pad_amount)]\n        left_len = len(left_intervention_locations)\n        right_len = len(right_intervention_locations)\n        if left_len > right_len:\n            right_intervention_locations += [pad_position for _ in range(left_len-right_len)]\n        else:\n            left_intervention_locations += [pad_position for _ in range(right_len-left_len)]\n        intervention_locations = [left_intervention_locations]*(num_interventions//2) + \\\n            [right_intervention_locations]*(num_interventions//2)\n    return intervention_locations\nclass ReftModel(pv.IntervenableModel):\n    def __init__(self, config, model, **kwargs):\n        super().__init__(config, model, **kwargs)\n    @staticmethod\n    def load(*args, **kwargs):\n        model = pv.IntervenableModel.load(*args, **kwargs)\n        return ReftModel._convert_to_reft_model(model)\ndef get_reft_model(model, reft_config, set_device=True, disable_model_grads=True):\n    reft_model = ReftModel(reft_config, model)\n    if set_device:\n        reft_model.set_device(model.device)\n    if disable_model_grads:\n        reft_model.disable_model_gradients()    \n    return reft_model\nclass ReftTrainer(Trainer):\n    def compute_loss(\n        self,\n        intervenable: pv.IntervenableModel,\n        inputs,\n        return_outputs=False,\n        **kwargs\n    ):\n        unit_locations = None\n        if \"intervention_locations\" in inputs:\n            if inputs[\"intervention_locations\"].dim() == 3:\n                unit_locations={\"sources->base\": (\n                    None,\n                    inputs[\"intervention_locations\"].permute(1, 0, 2).tolist()\n                )}\n            else:\n                unit_locations={\"sources->base\": (None, 0)}\n        base_outputs, cf_outputs = intervenable(\n            {\n                \"input_ids\": inputs[\"input_ids\"],\n                \"attention_mask\": inputs[\"attention_mask\"]\n            },\n            unit_locations=unit_locations,\n            labels=inputs[\"labels\"],\n            subspaces=inputs[\"subspaces\"].permute(1, 0, 2).tolist() if \"subspaces\" in inputs else None\n        )\n        output = cf_outputs\n        if cf_outputs is None:\n            output = base_outputs\n        return (output, output) if return_outputs else output.loss\nclass ReftTrainerForCausalLM(ReftTrainer):\n    def get_train_dataloader(self) -> DataLoader:\n        return DataLoader(self.train_dataset, self._train_batch_size, self.data_collator, shuffle=True)\nclass ReftTrainerForSequenceClassification(ReftTrainer):\n    def compute_loss(\n        self,\n        intervenable: pv.IntervenableModel,\n        inputs,\n        return_outputs=False\n    ):\n        unit_locations = None\n        if \"intervention_locations\" in inputs:\n            unit_locations={\"sources->base\": (\n                None,\n                inputs[\"intervention_locations\"].permute(1, 0, 2).tolist()\n            )}\n        _, cf_outputs = intervenable(\n            {\n                \"input_ids\": inputs[\"input_ids\"],\n                \"attention_mask\": inputs[\"attention_mask\"]\n            },\n            unit_locations=unit_locations,\n            labels=inputs[\"labels\"],\n            subspaces=inputs[\"subspaces\"].permute(1, 0, 2).tolist() if \"subspaces\" in inputs else None\n        )\n        logits = cf_outputs.logits\n        labels = inputs[\"labels\"]\n        if self.model.model.config.problem_type is None:\n            if self.model.model.num_labels == 1:\n                problem_type = \"regression\"\n            elif self.model.model.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n                problem_type = \"single_label_classification\"\n            else:\n                problem_type = \"multi_label_classification\"\n        else:\n            problem_type = self.model.model.config.problem_type\n        if problem_type == \"regression\":\n            loss_fct = nn.MSELoss()\n            if self.model.model.num_labels == 1:\n                loss = loss_fct(logits.squeeze(), labels.squeeze().to(torch.bfloat16))\n            else:\n                loss = loss_fct(logits, labels.to(torch.bfloat16))\n        elif problem_type == \"single_label_classification\":\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.model.model.num_labels), labels.view(-1))\n        elif problem_type == \"multi_label_classification\":\n            loss_fct = nn.BCEWithLogitsLoss()\n            loss = loss_fct(logits, labels)\n        return (loss, cf_outputs) if return_outputs else loss\nclass DPOReftTrainer(DPOTrainer):\n    def concatenated_forward(\n        self, model: nn.Module, batch: Dict[str, Union[List, torch.LongTensor]], reference: bool = False\n    ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n        concatenated_batch = self.concatenated_inputs(\n            batch,\n            is_encoder_decoder=self.is_encoder_decoder,\n            label_pad_token_id=self.label_pad_token_id,\n            padding_value=self.padding_value,\n            device=self.accelerator.device,\n        )\n        len_chosen = batch[\"chosen_labels\"].shape[0]\n        intervention_locations = torch.tensor(\n            batch['intervention_locations'] + batch['intervention_locations']\n        ).transpose(0, 1).tolist()\n        model_kwargs = (\n            {\n                \"labels\": concatenated_batch[\"concatenated_labels\"],\n                \"decoder_input_ids\": concatenated_batch.pop(\"concatenated_decoder_input_ids\", None),\n            }\n            if self.is_encoder_decoder\n            else {}\n        )\n        if reference:\n            all_outputs = model.model(\n                input_ids=concatenated_batch[\"concatenated_input_ids\"].to(model.get_device()),\n                attention_mask=concatenated_batch[\"concatenated_attention_mask\"].to(model.get_device()),\n                use_cache=False,\n                **model_kwargs,\n            )\n        else:\n            _, all_outputs = model(\n                {\n                    \"input_ids\": concatenated_batch[\"concatenated_input_ids\"].to(model.get_device()),\n                    \"attention_mask\": concatenated_batch[\"concatenated_attention_mask\"].to(model.get_device()),\n                },\n                unit_locations={\"sources->base\": (None, intervention_locations)},\n                use_cache=False,\n                **model_kwargs,\n            )\n        all_logits = all_outputs.logits\n        all_logps = self.get_batch_logps(\n            all_logits,\n            concatenated_batch[\"concatenated_labels\"],\n            average_log_prob=self.loss_type == \"ipo\",\n            is_encoder_decoder=self.is_encoder_decoder,\n            label_pad_token_id=self.label_pad_token_id,\n        )\n        chosen_logps = all_logps[:len_chosen]\n        rejected_logps = all_logps[len_chosen:]\n        chosen_logits = all_logits[:len_chosen]\n        rejected_logits = all_logits[len_chosen:]\n        return (chosen_logps, rejected_logps, chosen_logits, rejected_logits)\n    def get_batch_loss_metrics(\n        self,\n        model,\n        batch: Dict[str, Union[List, torch.LongTensor]],\n        train_eval: str = \"train\",\n    ):\n        metrics = {}\n        (policy_chosen_logps,policy_rejected_logps,policy_chosen_logits,policy_rejected_logits,)\n             = self.concatenated_forward(model, batch, reference=False)\n        if \"reference_chosen_logps\" in batch and \"reference_rejected_logps\" in batch:\n            reference_chosen_logps = batch[\"reference_chosen_logps\"]\n            reference_rejected_logps = batch[\"reference_rejected_logps\"]\n        else:\n            with torch.no_grad():\n                (reference_chosen_logps,reference_rejected_logps,_,_,)\n                     = self.concatenated_forward(self.model, batch, reference=True)\n        losses, chosen_rewards, rejected_rewards = self.dpo_loss(\n            policy_chosen_logps,\n            policy_rejected_logps,\n            reference_chosen_logps,\n            reference_rejected_logps,\n        )\n        reward_accuracies = (chosen_rewards > rejected_rewards).float()\n        prefix = \"eval_\" if train_eval == \"eval\" else \"\"\n        metrics[f\"{prefix}rewards/chosen\"] = chosen_rewards.mean().cpu()\n        metrics[f\"{prefix}rewards/rejected\"] = rejected_rewards.mean().cpu()\n        metrics[f\"{prefix}rewards/accuracies\"] = reward_accuracies.mean().cpu()\n        metrics[f\"{prefix}rewards/margins\"] = (chosen_rewards - rejected_rewards).mean().cpu()\n        metrics[f\"{prefix}logps/rejected\"] = policy_rejected_logps.detach().mean().cpu()\n        metrics[f\"{prefix}logps/chosen\"] = policy_chosen_logps.detach().mean().cpu()\n        metrics[f\"{prefix}logits/rejected\"] = policy_rejected_logits.detach().mean().cpu()\n        metrics[f\"{prefix}logits/chosen\"] = policy_chosen_logits.detach().mean().cpu()\n        return losses.mean(), metrics",
    "Experiment Result": "{\n  \"method_name\": \"LoReFT\",\n  \"model_initialization\": {\n    \"model_name_or_path\": \"yahma/llama-7b-hf\",\n    \"torch_dtype\": \"bfloat16\",\n    \"device_map\": \"cuda\" (if available)\n  },\n  \"tokenizer_configuration\": {\n    \"model_max_length\": \"512\" (or 2048 for DPO/Reward),\n    \"padding_side\": \"right\",\n    \"pad_token\": \"tokenizer.unk_token\" (or added '[PAD]' for Llama3)\n  },\n  \"intervention_parameters\": {\n    \"intervention_type\": \"LoreftIntervention\",\n    \"layers\": \"all\" (or specific layers like '2;10;18;26' or '18;28'),\n    \"position\": \"f1+l1\" (or 'last', 'f1'),\n    \"rank\": \"low_rank_dimension\" (default 1 in Alpaca/Reward, 4 in DPO, 8 in LoReFT example),\n    \"share_weights\": \"False\" (by default),\n    \"dropout\": \"0.00\" (by default),\n    \"act_fn\": \"None\" (linear activation by default),\n    \"add_bias\": \"False\" (by default)\n  },\n  \"data_loading\": {\n    \"data_path\": \"alpaca\" (or 'TruthfulQA/TruthfulQA.csv', 'llm-blender/Unified-Feedback'),\n    \"data_split\": \"train\" (or 'val', 'test', 'eval'),\n    \"max_n_train_example\": \"None\" (by default),\n    \"max_n_eval_example\": \"None\" (by default)\n  },\n  \"training_arguments\": {\n    \"epochs\": \"1\" (or 3 for DPO),\n    \"per_device_train_batch_size\": \"4\" (or 10 for DPO),\n    \"per_device_eval_batch_size\": \"4\",\n    \"gradient_accumulation_steps\": \"4\",\n    \"learning_rate\": \"5e-3\" (or 1e-3 for DPO),\n    \"lr_scheduler_type\": \"linear\",\n    \"warmup_ratio\": \"0.00\",\n    \"weight_decay\": \"0.00\",\n    \"logging_steps\": \"1\" (or 10, 40)\n  },\n  \"task_specific_settings\": {\n    \"task\": \"alpaca\" (or 'dpo', 'reward', 'glue', 'gsm8k', 'commonsense', etc.),\n    \"metric_for_best_model\": \"accuracy\" (for GLUE, otherwise not used),\n    \"problem_type\": \"regression\" (for 1 label), \"single_label_classification\" (for >1 label, long/int labels), \"multi_label_classification\" (for >1 label, float/bool labels)\n  },\n  \"dpo_specific_settings\": {\n    \"beta\": \"0.1\",\n    \"max_length\": \"256\",\n    \"max_prompt_length\": \"128\"\n  },\n  \"reward_model_specific_settings\": {\n    \"num_labels\": \"1\",\n    \"loss_function\": \"-torch.nn.functional.logsigmoid(rewards_chosen - rewards_rejected).mean()\"\n  },\n  \"generation_arguments\": {\n    \"greedy_decoding\": \"False\" (by default),\n    \"temperature\": \"None\" (or e.g. 0.1, 0.3, 0.8),\n    \"top_p\": \"None\" (or e.g. 0.75, 0.95),\n    \"top_k\": \"None\" (or e.g. 40),\n    \"num_beams\": \"1\" (or 4 for certain tasks/settings)\n  }\n}"
}{
    "Title": "SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors",
    "Main Contributions": "The paper introduces SVFT (Singular Vectors guided Fine-Tuning), a novel parameter-efficient fine-tuning (PEFT) method that addresses the performance gap and parameter efficiency limitations of existing methods like LoRA. SVFT fundamentally differs by making the weight update structure dependent on the specific pre-trained weight matrix, adapting it with a sparse weighted combination of its own singular vectors. The method recovers up to 96% of full fine-tuning performance while training only 0.006 to 0.25% of parameters, significantly outperforming existing PEFT methods that typically recover up to 85% performance using 0.03 to 0.8% of parameters. The paper also introduces four variants for parameterizing weight updates (Plain, Random, Banded, and Top-k) and theoretically demonstrates that SVFT can induce higher-rank perturbations for a fixed parameter budget compared to prior techniques.",
    "Methodology": "SVFT operates by first computing the Singular Value Decomposition (SVD) of a pre-trained weight matrix W0 = UΣV^T. The weight update, ∆W, is then parameterized as UMV^T, where U and V are fixed (frozen) singular vectors, and M is a sparse trainable matrix with a pre-determined and fixed sparsity pattern. The forward pass becomes h = U(Σ + M)V^T x. Four choices for the sparsity pattern of M are explored: Plain (SVFTP), where M is diagonal, adapting only singular values; Banded (SVFTBd), where M is a banded matrix capturing local interactions; Random (SVFTRd), where k elements are randomly selected to be learnable; and Top-k (SVFTTd), where the top-k elements are chosen based on the alignment of left and right singular vectors. SVFT's algebraic structure allows it to induce high-rank perturbations in a constrained subspace efficiently, distinguishing it from LoRA and VeRA by using shared singular vectors across multiple rank-one updates.",
    "Experimental Setup": "The research conducts extensive experiments on various language and vision benchmarks. For language tasks, it adapts encoder-only (DeBERTaV3base) and decoder-only models (Gemma-2B/7B, LLaMA-3-8B). Natural Language Generation (NLG) tasks include mathematical reasoning (GSM-8K and MATH, fine-tuned on MetaMathQA-40K) and 8 commonsense reasoning benchmarks (BoolQ, PIQA, SIQA, HellaSwag, Winogrande, ARC-easy/challenge, OpenBookQA). Natural Language Understanding (NLU) uses the GLUE benchmark. Vision tasks involve vision transformers (ViT-B/16 and ViT-L/16) on classification benchmarks: CIFAR-100, Food101, RESISC45, and Flowers102, fine-tuned on 10 samples per class. Baselines for comparison include Full Fine-Tuning (FT), LoRA, DoRA, BOFT, and VeRA. Performance is primarily measured by accuracy, Matthew's correlation for CoLA, and Pearson correlation for STS-B.",
    "Limitations": "Despite its efficiency, SVFT incurs additional GPU memory usage compared to methods like LoRA. This is due to the necessity of computing the Singular Value Decomposition (SVD) and storing both the left and right singular vectors of the pre-trained weights. Although its memory consumption is still lower than BOFT, it is roughly double that of LoRA. The authors partially mitigate this through system-level optimizations such as mixed-precision weights (e.g., bfloat16).",
    "Future Research Directions": "Future research directions include further exploring memory-reduction techniques, such as quantization, to address the increased GPU memory usage. Another key area is to develop principled methods for generating sparsity patterns for the trainable matrix M, which could potentially lead to further performance improvements beyond the current simple design choices. Optimizing the sparsity pattern of M, including efficient learned-sparsity methods, is also considered a promising avenue.",
    "Experiment Code": "import time\nimport math\n\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_sparse import SparseTensor, transpose\n\n\ndef create_orthonormal_matrix(A):\n    # returns an orthonormal matrix (square) of size (min(A.shape), min(A.shape))\n    Q, R = torch.qr(A)\n    return Q\n\n\ndef get_target_modules_list(model, target_modules):\n    target_names = []\n    for n, _ in model.named_modules():\n        if any(t in n for t in target_modules):\n            target_names.append(n)\n    return target_names\n\n\ndef replace_svft_with_fused_linear(model, target_modules_list):\n    print(\"Replacing SVFT layers with new Linear layers\")\n\n    # filter out svft layer\n    target_modules_list = [l for l in target_modules_list if \"svft_layer\" not in l]\n\n    for target_path in tqdm(reversed(target_modules_list), total=len(target_modules_list)):\n        parent_path = target_path[: target_path.rfind(\".\")] if \".\" in target_path else \"\"\n        target_name = target_path.split(\".\")[-1]\n        parent = model.get_submodule(parent_path) if parent_path else model\n        target = model.get_submodule(target_path)\n        in_dim = target.svft_layer.v.shape[1]\n        out_dim = target.svft_layer.u.shape[0]\n        if target.bias is None:\n            lin = torch.nn.Linear(in_dim, out_dim, bias=False)\n        else:\n            lin = torch.nn.Linear(in_dim, out_dim, bias=True)\n            lin.bias.data = target.bias.data\n        lin.weight.data = target.merge_and_unload()\n        parent.__setattr__(target_name, lin)\n\n\ndef create_and_replace_modules(model, target_modules_list, create_fn):\n    print(\"Replacing Linear layers with SVFT layers\")\n\n    for target_path in tqdm(reversed(target_modules_list), total=len(target_modules_list)):\n        parent_path = target_path[: target_path.rfind(\".\")] if \".\" in target_path else \"\"\n        target_name = target_path.split(\".\")[-1]\n        parent = model.get_submodule(parent_path) if parent_path else model\n        target = model.get_submodule(target_path)\n        parent.__setattr__(target_name, create_fn(target))\n\n\nclass SVFTLayer(nn.Module):\n    def __init__(self, u, s, v, off_diag, pattern=\"banded\", rank=None, fill_orthonormal=False):\n\n        \"\"\"\n        @inputs:\n            u: torch.Tensor. Left singular vectors of pre-trained weight matrix\n            s: torch.Tensor. Singular values of pre-trained weight matrix\n            v: torch.Tensor. Right singular vectors of pre-trained weight matrix\n            off_diag: int. Total off-diagonals to be used to populate matrix M (as referred in main paper)\n            pattern: str. Choices: \"banded\", \"random\", \"top_k\". Using \"banded\" with off_diag=1 simulates SVFT-plain\n            rank: int. Constraints how many singular vectors and values to use.\n            fill_orthonormal: bool. To determine if random orthonormal basis should be used\n        \"\"\"\n\n        super().__init__()\n\n        self.off_diag = off_diag\n        rank = s.shape[0] if rank is None else min(s.shape[0], rank)\n        self.n = rank\n        diff_rank = s.shape[0] - rank\n\n        if fill_orthonormal:\n            Q_u = torch.randn_like(u).to(s.device)\n            torch.nn.init.orthogonal_(Q_u)\n            Q_v = torch.randn_like(v).to(s.device)\n            torch.nn.init.orthogonal_(Q_v)\n\n            u = torch.cat([u[:, :rank], Q_u[:, :diff_rank]], dim=1)\n            v = torch.cat([v[:rank, :], Q_v[:diff_rank, :]], dim=0)\n            s = torch.cat([s[:rank], torch.zeros(diff_rank).to(s.device)], dim=0)\n            self.n = s.shape[0]\n\n        else:\n            s = s[:rank]\n            u = u[:, :rank]\n            v = v[:rank, :]\n\n        self.u = nn.Parameter(u.clone().detach().contiguous(), requires_grad=False)\n\n        s_pre = s.cpu().detach().clone().contiguous()\n        self.s_pre_edge_index = torch.sparse.spdiags(s_pre, torch.LongTensor([0]), (self.n, self.n)).coalesce().indices()\n        self.s_pre = nn.Parameter(s_pre, requires_grad=False)\n        \n        if pattern==\"banded\":  \n            diags = 2*self.off_diag + 1\n            offsets_positive = torch.arange(0, self.off_diag+1)\n            offsets_negative = torch.arange(-1, -self.off_diag-1, -1)\n            self.offsets  = torch.cat([offsets_positive, offsets_negative])\n            self.s_edge_index = torch.sparse.spdiags(torch.randn([diags, self.n]), self.offsets, (self.n, self.n)).coalesce().indices()\n            self.s = torch.nn.Parameter(torch.zeros(self.s_edge_index.shape[1]), requires_grad=True)\n\n        elif pattern==\"random\":\n            print(\"Random pattern\")\n            k = self.n*(2*self.off_diag+1) - self.off_diag*(self.off_diag+1)\n            rows = torch.randint(0, self.n, (k,))\n            cols = torch.randint(0, self.n, (k,))\n            self.s_edge_index = torch.stack([rows, cols])\n            self.s = torch.nn.Parameter(torch.zeros(k), requires_grad=True)\n\n        elif pattern==\"top_k\":\n\n            if u.shape == v.shape:\n                coeffs = u@v.T\n            else:\n                coeffs = u if u.shape[0]==u.shape[1] else v\n\n            k = self.n*(2*self.off_diag+1) - self.off_diag*(self.off_diag+1)\n            # Flatten the tensor to 1D\n            flattened_tensor = coeffs.contiguous().view(-1)\n            _, top_indices_flat = torch.topk(flattened_tensor, k)\n            num_rows, num_cols = coeffs.size()\n            rows = top_indices_flat // num_cols\n            cols = top_indices_flat % num_cols\n            self.s_edge_index = torch.stack([rows, cols])\n            self.s = torch.nn.Parameter(torch.zeros(k), requires_grad=True)\n       \n        torch.nn.init.kaiming_normal_(self.s[None, :])\n        self.s.squeeze()\n\n        self.register_buffer('s_pre_row', self.s_pre_edge_index[0])\n        self.register_buffer('s_pre_col', self.s_pre_edge_index[1])\n        self.register_buffer('s_row', self.s_edge_index[0])\n        self.register_buffer('s_col', self.s_edge_index[1])\n\n        self.gate = nn.Parameter(torch.tensor([0.], dtype=torch.float32), requires_grad=True)\n\n        self.v = nn.Parameter(v.clone().detach().contiguous(), requires_grad=False) \n\n\n    def forward(self, x):\n        x  = x @ self.get_weights() \n        return x\n\n\n    def get_weights(self):\n        s = SparseTensor(row=self.s_row, col=self.s_col, value=self.s*F.sigmoid(self.gate))\n        s_pre = SparseTensor(row=self.s_pre_row, col=self.s_pre_col, value=self.s_pre)\n        del_s = s_pre + s\n        weight = (del_s @ self.v).T\n        weight = weight @ self.u.T\n        return weight\n    \n\n    def merge_and_unload(self):\n        return self.get_weights().T.contiguous()\n\n   \nclass LinearWithSVFT(nn.Module):\n\n    def __init__(self, linear, off_diag, pattern=\"banded\", rank=None, fill_orthonormal=False):\n        \"\"\"\n        @inputs:\n                linear: torch.Tensor. Linear Layer that has to adapted\n                off_diag: int. total number off diagonals to be used if pattern is 'banded' \n                          for remaining patterns, equivalent number of learnable parameters are learnt\n                rank: SVD rank \n                fill_orthonormal: bool. To determine if random orthonormal basis should be used\n        \"\"\"\n        \n        super().__init__()\n\n        self.bias = linear.bias\n\n        # since linear.weight is on GPU, computing SVD will be significantly faster\n        svd = torch.linalg.svd(linear.weight, full_matrices=False)\n\n        self.svft_layer = SVFTLayer(svd[0], \n                                    svd[1], \n                                    svd[2], \n                                    off_diag=off_diag, \n                                    pattern=pattern, \n                                    rank=rank, \n                                    fill_orthonormal=fill_orthonormal)\n\n    def forward(self, x):\n        if self.bias is not None:\n            return self.svft_layer(x) + self.bias\n\n        else:\n            return self.svft_layer(x)\n\n    def merge_and_unload(self):\n        return self.svft_layer.merge_and_unload()\n\n\ndef freeze_model(model, exclude_list = None):\n    ''' Freeze all parameters of the model '''\n    if exclude_list is None:\n        exclude_list = []\n\n    for n, p in model.named_parameters():\n        if not any(e in n for e in exclude_list):\n            p.requires_grad = False",
    "Experiment Result": "The SVFT (Singular Value Fine-Tuning) method adapts pre-trained weight matrices by leveraging their Singular Value Decomposition (SVD). A weight matrix W0 = UΣV^T is updated by parameterizing the change ∆W as UMV^T. In this formulation, U and V are fixed (frozen) singular vectors, and M is a sparse trainable matrix. The forward pass is computed as h = U(Σ + M)V^T x.\n\nKey experimental settings for SVFT include:\n-   **pattern**: Specifies the sparsity pattern of the trainable matrix M. Choices are:\n    -   \"banded\" (SVFTBd): M is a banded matrix, capturing local interactions. \"Plain\" SVFT (SVFTP), where M is diagonal, can be simulated using \"banded\" with `off_diag=0` or `1` (depending on exact implementation).\n    -   \"random\" (SVFTRd): `k` elements of M are randomly selected to be learnable.\n    -   \"top_k\" (SVFTTd): `k` elements of M are chosen based on the alignment of left and right singular vectors.\n-   **off_diag**: An integer parameter that controls the complexity or sparsity of M. For \"banded\" pattern, it directly defines the number of off-diagonal blocks. For \"random\" and \"top_k\" patterns, it contributes to determining the total number of `k` learnable elements in M.\n-   **rank**: An optional integer specifying the rank for truncated SVD. If provided, only the top `rank` singular values and vectors are used, constraining the subspace for perturbations.\n-   **fill_orthonormal**: A boolean flag (defaulting to False) that, when True, initializes the additional singular vectors from a random orthonormal basis if a truncated rank is used and the effective rank is less than the full intrinsic rank.\n-   **target_modules**: A list of strings indicating the names of the linear layers in the base model to which the SVFT adaptation is applied. Common targets include attention projection layers (e.g., `q_proj`, `v_proj`, `k_proj`, `o_proj`, `query`, `key`, `value`) and feed-forward network layers (e.g., `up_proj`, `down_proj`, `gate_proj`).\n-   **gate**: A trainable scalar parameter that is applied as a sigmoid activation to scale the magnitude of the learned sparse matrix M, thereby controlling its influence on the original singular values."
}{
    "Title": "Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning",
    "Main Contributions": "The paper addresses the memory inefficiency of existing parameter-efficient fine-tuning (PEFT) methods, which, despite reducing trainable parameters, still require substantial activation memory. The key finding is the \"starting point hypothesis,\" emphasizing the importance of preserving the pre-trained model's initial state when introducing new parameters. Based on this, the authors propose Memory-Efficient Fine-Tuning (MEFT), a novel approach that modifies pre-trained language models (PLMs) to be reversible by inserting adapters, thereby eliminating the need to cache intermediate activations. MEFT significantly reduces activation memory by up to 84% compared to full fine-tuning, with a negligible number of trainable parameters, while maintaining comparable performance on various NLP tasks (GLUE, question-answering) and showing similar effectiveness in image classification.",
    "Methodology": "MEFT leverages the principle of reversible neural networks, where intermediate activations are recomputed during backpropagation instead of being stored, reducing memory footprint to O(1). The core design adheres to the \"starting point hypothesis,\" which dictates that newly added adapter parameters must be initialized such that the modified PLM layer's output closely matches the original PLM layer's output at the beginning of training. Three MEFT architectures (MEFT1, MEFT2, MEFT3) are proposed, each inserting adapters into the PLM in different configurations (e.g., PLM layer as F, adapter as G; adapter as F, PLM layer as G; attention block as F, MLP block as G). These methods carefully set scaling factors (λ and β, often to 0.1) and, for MEFT1 and MEFT2, involve switching the order of outputs between reversible layers to preserve representation continuity. For deep models, a hybrid approach combines vanilla (activation caching) and reversible layers, or freezes shallow layers. For sequence-to-sequence tasks, a scaling factor γ (default 0.1) is introduced for the final output to maintain continuity for the pre-trained output layer.",
    "Experimental Setup": "MEFT was evaluated on a comprehensive set of tasks and models. For sequence representation, the GLUE benchmark (RTE, MRPC, STS-B, CoLA, SST-2, QNLI, QQP, MNLI) was used with BERTbase, RoBERTalarge, and BARTlarge encoder models. For sequence-to-sequence, five question-answering tasks (OpenBookQA, PIQA, ARC-E, ARC-C, SciQ) were tested with OPT 1.3B and OPT6.7B. An image classification task (SVHN) with ViT was also included. Evaluation metrics included accuracy, Pearson correlation, and Matthews correlation. Baselines comprised full fine-tuning, various PEFT methods (AdapterH, AdapterP, Prefix-Tuning, LoRA, MAM, AutoPEFT), and memory-efficient baselines (Y-Tuning, LST). Experiments were conducted on a single NVIDIA RTX A6000 GPU with 48GB memory using the Transformers framework. Training involved grid searches for hyperparameters (learning rates, batch sizes, epochs), Adam optimizer, and mixed precision (FP16) training, with some FP32 comparisons. Further comparisons were made against gradient checkpointing, QLoRA, and by combining MEFT with ZeRO stage 3.",
    "Limitations": "The study's main limitations include evaluation on a limited number of tasks and lack of experiments on encoder-decoder models, primarily due to computational resource constraints. MEFT also exhibits lower performance when trained in FP16 and on very deep models, attributed to increased reconstruction errors from numerical instability in FP16 and error accumulation over many reversible layers. While MEFT reduces activation memory, for larger models like OPT1.3B and OPT6.7B, the peak memory footprint is still dominated by model parameters, requiring additional techniques like FP16/INT8 model loading or ZeRO for further reduction. Additionally, the recomputation of activations in MEFT leads to slightly increased training time, approximately twice that of PEFT methods that cache activations.",
    "Future Research Directions": "Future work includes applying MEFT to other domains such as computer vision and automatic speech recognition. There is also interest in extending MEFT to work with other bigger backbone models, like LLAMA, for more sequence-to-sequence tasks and exploring its transferability to different model architectures.",
    "Experiment Code": "class Adapter(nn.Module):    def __init__(self, config, layernorm=False):        super().__init__()        self.dense1 = nn.Linear(config.hidden_size, config.adapter_bottleneck_dim)        self.dense2 = nn.Linear(config.adapter_bottleneck_dim, config.hidden_size)        self.dropout = nn.Dropout(config.hidden_dropout_prob)        if isinstance(config.hidden_act, str):            self.act_fn = ACT2FN[config.hidden_act]        else:            self.act_fn = config.hidden_act        if layernorm:            self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)        else:            self.LayerNorm = None    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:        if self.LayerNorm is not None:            hidden_states = self.LayerNorm(hidden_states)        hidden_states = self.dense1(hidden_states)        hidden_states = self.act_fn(hidden_states)        hidden_states = self.dropout(hidden_states)        hidden_states = self.dense2(hidden_states)        return hidden_statesclass RevBertSelfOutput(BertSelfOutput):    def __init__(self, config):        super().__init__(config)        if config.f_arch == \"attn\":            self.attn_adapter = Adapter(config)        else:            self.attn_adapter = None    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:        hidden_states = self.dense(hidden_states)        hidden_states = self.dropout(hidden_states)        if self.attn_adapter is not None: # For MEFT3            hidden_states = hidden_states + self.attn_adapter(hidden_states)        hidden_states = self.LayerNorm(hidden_states + input_tensor)        return hidden_statesclass RevBertOutput(BertOutput):    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor, adapter_change=None) -> torch.Tensor:        hidden_states = self.dense(hidden_states)        hidden_states = self.dropout(hidden_states)        # For MEFT1 and MEFT2: inserting an adapter in parallel to two consecutive feed-forward layers        if adapter_change is not None:            hidden_states = hidden_states + adapter_change        hidden_states = self.LayerNorm(hidden_states + input_tensor)        return hidden_statesclass RevBertLayer(BertLayer):    def __init__(self, config):        super().__init__(config)        self.output = RevBertOutput(config)        self.ffn_adapter = Adapter(config)        if config.f_arch == \"attn\":  # For MEFT3: insert an adapter to the attention block            self.rev_adapter = None            self.attention = RevBertAttention(config)        else:  # For MEFT1 and MEFT2            self.rev_adapter = Adapter(config, layernorm=config.layernorm_in_adapter)        self.x1_factor = config.x1_factor  # by default, lambda = 0.1        self.x2_factor = config.x2_factor  # by default, beta = 0.1        self.f_arch = config.f_arch  # What is the choice for the F architecture        if config.f_arch == \"layer\":  # MEFT1            self.F = self.forward_layer            self.G = self.forward_adapter        elif config.f_arch == \"adapter\":  # MEFT2            self.F = self.forward_adapter            self.G = self.forward_layer        elif config.f_arch == \"attn\":  # MEFT3            self.F = self.forward_attention            self.G = self.forward_mlp        self.seeds = {}    def set_seed(self, key):        if hasattr(torch.cuda, \"default_generators\") and len(torch.cuda.default_generators) > 0:            device_idx = torch.cuda.current_device()            seed = torch.cuda.default_generators[device_idx].seed()        else:            seed = int(torch.seed() % sys.maxsize)        self.seeds[key] = seed        torch.manual_seed(seed)    def forward(        self,        hidden_states: torch.Tensor,        attention_mask: Optional[torch.FloatTensor] = None,        head_mask: Optional[torch.FloatTensor] = None,        encoder_hidden_states: Optional[torch.FloatTensor] = None,        encoder_attention_mask: Optional[torch.FloatTensor] = None,        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,        output_attentions: Optional[bool] = False,    ) -> Tuple[torch.Tensor]:        x1, x2 = torch.chunk(hidden_states, 2, dim=-1)        if self.training:            self.set_seed(\"F\")        f_outputs = self.F(            x2,            attention_mask,            head_mask,            encoder_hidden_states,            encoder_attention_mask,            past_key_value,            output_attentions        )        if isinstance(f_outputs, tuple):            f_x2 = f_outputs[0]            outputs = f_outputs[1:]        else:            f_x2 = f_outputs        y1 = self.x1_factor * x1 + f_x2        if self.training:            self.set_seed(\"G\")        g_outputs = self.G(            y1,            attention_mask,            head_mask,            encoder_hidden_states,            encoder_attention_mask,            past_key_value,            output_attentions        )        if isinstance(g_outputs, tuple):            g_y1 = g_outputs[0]            outputs = g_outputs[1:]        else:            g_y1 = g_outputs        y2 = self.x2_factor * x2 + g_y1        if self.f_arch == \"attn\":            y = torch.cat([y1, y2], dim=-1)  # Don't switch for MEFT3        else:            y = torch.cat([y2, y1], dim=-1)  # Switch for MEFT1 and MEFT2        outputs = (y,) + outputs        return outputs    def backward_pass(        self,        y,        dy,        attention_mask,        head_mask,        encoder_hidden_states,        encoder_attention_mask,        past_key_value    ):        assert self.training, (            \"If you want to train `ReversibleModel` and its variations, make sure to use `model.train()` to put the\"            \" model into training mode.\"        )        if self.f_arch == \"attn\":            y1, y2 = torch.chunk(y, 2, dim=-1)  # Don't Switch for MEFT3            dy1, dy2 = torch.chunk(dy, 2, dim=-1)        else:            y2, y1 = torch.chunk(y, 2, dim=-1)  # Swich for MEFT1 and MEFT2            dy2, dy1 = torch.chunk(dy, 2, dim=-1)        with torch.enable_grad():            y1.requires_grad = True            torch.manual_seed(self.seeds[\"G\"])            g_outputs = self.G(                y1,                attention_mask=attention_mask,                head_mask=head_mask,                encoder_hidden_states=encoder_hidden_states,                encoder_attention_mask=encoder_attention_mask,                past_key_value=past_key_value,                output_attentions=False            )            if isinstance(g_outputs, tuple):                g_y1 = g_outputs[0]            else:                g_y1 = g_outputs            g_y1.backward(dy2, retain_graph=True)        with torch.no_grad():            x2 = (y2 - g_y1) / self.x2_factor            del g_y1, y2            dy1 += y1.grad            y1.grad = None        with torch.enable_grad():            x2.requires_grad = True            torch.manual_seed(self.seeds[\"F\"])            f_outputs = self.F(                x2,                attention_mask=attention_mask,                head_mask=head_mask,                encoder_hidden_states=encoder_hidden_states,                encoder_attention_mask=encoder_attention_mask,                past_key_value=past_key_value,                output_attentions=False            )            if isinstance(f_outputs, tuple):                f_x2 = f_outputs[0]            else:                f_x2 = f_outputs            f_x2.backward(dy1, retain_graph=False)        with torch.no_grad():            x1 = (y1 - f_x2) / self.x1_factor            del f_x2, y1            dy2 *= self.x2_factor            dy2 += x2.grad            x2.grad = None            dy1 *= self.x1_factor            x2 = x2.detach()        return torch.cat([x1, x2], dim=-1), torch.cat([dy1, dy2], dim=-1)    def forward_adapter(        self,        hidden_states: torch.Tensor,        attention_mask: Optional[torch.FloatTensor] = None,        head_mask: Optional[torch.FloatTensor] = None,        encoder_hidden_states: Optional[torch.FloatTensor] = None,        encoder_attention_mask: Optional[torch.FloatTensor] = None,        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,        output_attentions: Optional[bool] = False,    ):        return self.rev_adapter(hidden_states)    def forward_layer(        self,        hidden_states: torch.Tensor,        attention_mask: Optional[torch.FloatTensor] = None,        head_mask: Optional[torch.FloatTensor] = None,        encoder_hidden_states: Optional[torch.FloatTensor] = None,        encoder_attention_mask: Optional[torch.FloatTensor] = None,        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,        output_attentions: Optional[bool] = False,    ) -> Tuple[torch.Tensor]:        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None        self_attention_outputs = self.attention(            hidden_states,            attention_mask,            head_mask,            output_attentions=output_attentions,            past_key_value=self_attn_past_key_value,        )        attention_output = self_attention_outputs[0]        if self.is_decoder:            outputs = self_attention_outputs[1:-1]            present_key_value = self_attention_outputs[-1]        else:            outputs = self_attention_outputs[1:]        cross_attn_present_key_value = None        if self.is_decoder and encoder_hidden_states is not None:            if not hasattr(self, \"crossattention\"):                raise ValueError(                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"                    \" by setting `config.add_cross_attention=True`\"                )            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None            cross_attention_outputs = self.crossattention(                attention_output,                attention_mask,                head_mask,                encoder_hidden_states,                encoder_attention_mask,                cross_attn_past_key_value,                output_attentions,            )            attention_output = cross_attention_outputs[0]            outputs = outputs + cross_attention_outputs[1:-1]            cross_attn_present_key_value = cross_attention_outputs[-1]            present_key_value = present_key_value + cross_attn_present_key_value        layer_output = apply_chunking_to_forward(            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output        )        outputs = (layer_output,) + outputs        if self.is_decoder:            outputs = outputs + (present_key_value,)        return outputs    def forward_attention(        self,        hidden_states: torch.Tensor,        attention_mask: Optional[torch.FloatTensor] = None,        head_mask: Optional[torch.FloatTensor] = None,        encoder_hidden_states: Optional[torch.FloatTensor] = None,        encoder_attention_mask: Optional[torch.FloatTensor] = None,        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,        output_attentions: Optional[bool] = False,    ):        self_attention_outputs = self.attention(            hidden_states,            attention_mask,            head_mask,            output_attentions=output_attentions,            past_key_value=None,        )        return self_attention_outputs    def forward_mlp(        self,        hidden_states: torch.Tensor,        attention_mask: Optional[torch.FloatTensor] = None,        head_mask: Optional[torch.FloatTensor] = None,        encoder_hidden_states: Optional[torch.FloatTensor] = None,        encoder_attention_mask: Optional[torch.FloatTensor] = None,        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,        output_attentions: Optional[bool] = False,    ):        hidden_states = apply_chunking_to_forward(            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, hidden_states        )        return hidden_states    def feed_forward_chunk(self, attention_output):        if self.ffn_adapter is not None:            adapter_change = self.ffn_adapter(attention_output)        else:            adapter_change = None        intermediate_output = self.intermediate(attention_output)        layer_output = self.output(intermediate_output, attention_output, adapter_change=adapter_change)        return layer_outputclass RevBackProp(Function):    @staticmethod    def forward(        ctx,        hidden_states,        layers,        attention_mask,        layer_head_mask,        encoder_hidden_states,        encoder_attention_mask,        past_key_value,        output_attentions,    ):        for i, layer_module in enumerate(layers):            layer_outputs = layer_module(                hidden_states,                attention_mask,                layer_head_mask,                encoder_hidden_states,                encoder_attention_mask,                past_key_value,                output_attentions,            )            hidden_states = layer_outputs[0]        ctx.save_for_backward(hidden_states.detach())        ctx.layers = layers        ctx.attention_mask = attention_mask        return hidden_states    def backward(ctx, dy):        y, = ctx.saved_tensors        layers = ctx.layers        attention_mask = ctx.attention_mask        for i, layer_module in enumerate(layers[::-1]):            y, dy = layer_module.backward_pass(                y,                dy,                attention_mask=attention_mask,                head_mask=None,                encoder_hidden_states=None,                encoder_attention_mask=None,                past_key_value=None            )        return dy, None, None, None, None, None, None, Noneclass RevBertEncoder(nn.Module):    def __init__(self, config):        super().__init__()        self.config = config        self.layer = nn.ModuleList([RevBertLayer(config) for _ in range(config.num_hidden_layers)])        self.gradient_checkpointing = False        self.num_rev_layers = config.num_rev_layers        assert self.num_rev_layers <= config.num_hidden_layers    def vanilla_backward(        hidden_states,        layers,        attention_mask    ):        for i, layer_module in enumerate(layers):            layer_outputs = layer_module(                hidden_states,                attention_mask=attention_mask,                head_mask=None,                encoder_hidden_states=None,                encoder_attention_mask=None,                past_key_value=None,                output_attentions=False,            )            hidden_states = layer_outputs[0]        return hidden_states    def forward(        self,        hidden_states: torch.Tensor,        attention_mask: Optional[torch.FloatTensor] = None,        head_mask: Optional[torch.FloatTensor] = None,        encoder_hidden_states: Optional[torch.FloatTensor] = None,        encoder_attention_mask: Optional[torch.FloatTensor] = None,        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,        use_cache: Optional[bool] = None,        output_attentions: Optional[bool] = False,        output_hidden_states: Optional[bool] = False,        return_dict: Optional[bool] = True,    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:        hidden_states = torch.cat([hidden_states, hidden_states], dim=-1)        layers_for_reverse_backward = self.layer[:self.num_rev_layers]        layers_for_vanilla_backward = self.layer[self.num_rev_layers:]        if len(layers_for_reverse_backward) == 0:            executing_fn = RevBertEncoder.vanilla_backward            hidden_states = executing_fn(                hidden_states,                layers_for_vanilla_backward,                attention_mask            )        elif len(layers_for_reverse_backward) == self.config.num_hidden_layers:            executing_fn = RevBackProp.apply            hidden_states = executing_fn(                hidden_states,                layers_for_reverse_backward,                attention_mask,                None,                None,                None,                None,                False            )        else:            lower_executing_fn = RevBackProp.apply            hidden_states = lower_executing_fn(                hidden_states,                layers_for_reverse_backward,                attention_mask,                None,                None,                None,                None,                False            )            higher_executing_fn = RevBertEncoder.vanilla_backward            hidden_states = higher_executing_fn(                hidden_states,                layers_for_vanilla_backward,                attention_mask            )        x1, x2 = torch.chunk(hidden_states, 2, dim=-1)        hidden_states = (x1 + x2) / 2.        return BaseModelOutputWithPastAndCrossAttentions(            last_hidden_state=hidden_states,            past_key_values=None,            hidden_states=None,            attentions=None,            cross_attentions=None,        )class ModelArguments:    model_name_or_path: str = field(        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}    )    config_name: Optional[str] = field(        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}    )    tokenizer_name: Optional[str] = field(        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}    )    cache_dir: Optional[str] = field(        default=None,        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},    )    use_fast_tokenizer: bool = field(        default=True,        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},    )    model_revision: str = field(        default=\"main\",        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},    )    use_auth_token: bool = field(        default=False,        metadata={            \"help\": (                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"                \"with private models).\"            )        },    )    ignore_mismatched_sizes: bool = field(        default=False,        metadata={\"help\": \"Will enable to load a pretrained model whose head dimensions are different.\"},    )    ## add args for adapter    adapter_bottleneck_dim: int = field(        default=0,        metadata={\"help\": \"bottleneck dimension for adapter. 0 means no adapter\"},    )    layernorm_in_adapter: bool = field(        default=False,        metadata={\"help\": \"whether add layernorm in the adapter for G\"},    )    num_rev_layers: int = field(        default=0,        metadata={\"help\": \"number of reversible layers, when it's 0, it means we use vanilla backward\"},    )    x1_factor: float = field(        default=1,        metadata={\"help\": \"factor for x1\"},    )    x2_factor: float = field(        default=1,        metadata={\"help\": \"factor for x2\"},    )    f_arch: ChoiceEnum([\"layer\", \"adapter\", \"attn\"]) = field(        default=\"layer\",        metadata={\"help\": \"what is the architecture for F, choices=[layer, adapter, attn]\"}    )    freeze_irreversible_layers: bool = field(        default=False,        metadata={\"help\": \"if true, freeze the shallower irreversible layers\"}    )def main():    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))    else:        model_args, data_args, training_args = parser.parse_args_into_dataclasses()    send_example_telemetry(\"run_glue\", model_args, data_args)    logging.basicConfig(        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",        datefmt=\"%m/%d/%Y %H:%M:%S\",        handlers=[logging.StreamHandler(sys.stdout)],    )    if training_args.should_log:        transformers.utils.logging.set_verbosity_info()    log_level = training_args.get_process_log_level()    logger.setLevel(log_level)    datasets.utils.logging.set_verbosity(log_level)    transformers.utils.logging.set_verbosity(log_level)    transformers.utils.logging.enable_default_handler()    transformers.utils.logging.enable_explicit_format()    logger.warning(        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"    )    logger.info(f\"Training/evaluation parameters {training_args}\")    last_checkpoint = None    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:        last_checkpoint = get_last_checkpoint(training_args.output_dir)        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:            raise ValueError(                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"                \"Use --overwrite_output_dir to overcome.\"            )        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:            logger.info(                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"            )    set_seed(training_args.seed)    if data_args.task_name is not None:        is_regression = data_args.task_name == \"stsb\"        if not is_regression:            label_list = raw_datasets[\"train\"].features[\"label\"].names            num_labels = len(label_list)        else:            num_labels = 1    else:        is_regression = raw_datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]        if is_regression:            num_labels = 1        else:            label_list = raw_datasets[\"train\"].unique(\"label\")            label_list.sort()            num_labels = len(label_list)    config = AutoConfig.from_pretrained(        model_args.config_name if model_args.config_name else model_args.model_name_or_path,        num_labels=num_labels,        finetuning_task=data_args.task_name,        cache_dir=model_args.cache_dir,        revision=model_args.model_revision,        use_auth_token=True if model_args.use_auth_token else None,    )    config.adapter_bottleneck_dim = model_args.adapter_bottleneck_dim    config.layernorm_in_adapter = model_args.layernorm_in_adapter    config.num_rev_layers = model_args.num_rev_layers    config.x1_factor = model_args.x1_factor    config.x2_factor = model_args.x2_factor    config.f_arch = model_args.f_arch    config.freeze_irreversible_layers = model_args.freeze_irreversible_layers    tokenizer = AutoTokenizer.from_pretrained(        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,        cache_dir=model_args.cache_dir,        use_fast=model_args.use_fast_tokenizer,        revision=model_args.model_revision,        use_auth_token=True if model_args.use_auth_token else None,    )    sequence_classification_model = RevBertForSequenceClassification    model = sequence_classification_model.from_pretrained(        model_args.model_name_or_path,        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),        config=config,        cache_dir=model_args.cache_dir,        revision=model_args.model_revision,        use_auth_token=True if model_args.use_auth_token else None,        ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,    )    logger.info(model)    logger.info(f\"Total num of parameters: {sum(p.numel() for p in model.parameters())}\")    if model_args.adapter_bottleneck_dim > 0:        for param in model.parameters():            param.requires_grad = False        non_freeze_sets = [\"adapter\", \"classifier\"]        if model_args.freeze_irreversible_layers:            non_freeze_sets.append(f\"encoder.layer.{config.num_hidden_layers - model_args.num_rev_layers - 1}.\"                                   f\"output.LayerNorm\")        else:            non_freeze_sets.append(\"embeddings.LayerNorm\")        for key in non_freeze_sets:            for n, p in model.named_parameters():                if key in n:                    p.requires_grad = True    if data_args.pad_to_max_length:        padding = \"max_length\"    else:        padding = False    label_to_id = None    if (        model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id        and data_args.task_name is not None        and not is_regression    ):        label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}        if sorted(label_name_to_id.keys()) == sorted(label_list):            label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}        else:            logger.warning(                \"Your model seems to have been trained with labels, but they don't match the dataset: \",                f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels: {sorted(label_list)}.\"                \"\\nIgnoring the model labels as a result.\",            )    elif data_args.task_name is None and not is_regression:        label_to_id = {v: i for i, v in enumerate(label_list)}    if label_to_id is not None:        model.config.label2id = label_to_id        model.config.id2label = {id: label for label, id in config.label2id.items()}    elif data_args.task_name is not None and not is_regression:        model.config.label2id = {l: i for i, l in enumerate(label_list)}        model.config.id2label = {id: label for label, id in config.label2id.items()}    max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)    def preprocess_function(examples):        args = (            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])        )        result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)        if label_to_id is not None and \"label\" in examples:            result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]        return result    with training_args.main_process_first(desc=\"dataset map pre-processing\"):        raw_datasets = raw_datasets.map(            preprocess_function,            batched=True,            load_from_cache_file=not data_args.overwrite_cache,            desc=\"Running tokenizer on dataset\",        )    if training_args.do_train:        if \"train\" not in raw_datasets:            raise ValueError(\"--do_train requires a train dataset\")        train_dataset = raw_datasets[\"train\"]        if data_args.max_train_samples is not None:            max_train_samples = min(len(train_dataset), data_args.max_train_samples)            train_dataset = train_dataset.select(range(max_train_samples))    if training_args.do_eval:        if \"validation\" not in raw_datasets and \"validation_matched\" not in raw_datasets:            raise ValueError(\"--do_eval requires a validation dataset\")        eval_dataset = raw_datasets[\"validation_matched\" if data_args.task_name == \"mnli\" else \"validation\"]        if data_args.max_eval_samples is not None:            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)            eval_dataset = eval_dataset.select(range(max_eval_samples))    if training_args.do_predict or data_args.task_name is not None or data_args.test_file is not None:        if \"test\" not in raw_datasets and \"test_matched\" not in raw_datasets:            raise ValueError(\"--do_predict requires a test dataset\")        predict_dataset = raw_datasets[\"test_matched\" if data_args.task_name == \"mnli\" else \"test\"]        if data_args.max_predict_samples is not None:            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)            predict_dataset = predict_dataset.select(range(max_predict_samples))    if training_args.do_train:        for index in random.sample(range(len(train_dataset)), 3):            logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")    if data_args.task_name is not None:        metric = evaluate.load(\"glue\", data_args.task_name)    else:        metric = evaluate.load(\"accuracy\")    def compute_metrics(p: EvalPrediction):        preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions        preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)        if data_args.task_name is not None:            result = metric.compute(predictions=preds, references=p.label_ids)            if len(result) > 1:                result[\"combined_score\"] = np.mean(list(result.values())).item()            return result        elif is_regression:            return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}        else:            return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}    if data_args.pad_to_max_length:        data_collator = default_data_collator    elif training_args.fp16:        data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)    else:        data_collator = None    training_args.model_name_or_path = model_args.model_name_or_path    if model_args.freeze_irreversible_layers:        training_args.start_layer = config.num_hidden_layers - model_args.num_rev_layers - 1    else:        training_args.start_layer = -1    trainer = CustomTrainer(        model=model,        args=training_args,        train_dataset=train_dataset if training_args.do_train else None,        eval_dataset=eval_dataset if training_args.do_eval else None,        compute_metrics=compute_metrics,        tokenizer=tokenizer,        data_collator=data_collator,        callbacks=[EarlyStoppingCallback(early_stopping_patience=8)]    )    if training_args.do_train:        checkpoint = None        if training_args.resume_from_checkpoint is not None:            checkpoint = training_args.resume_from_checkpoint        elif last_checkpoint is not None:            checkpoint = last_checkpoint        train_result = trainer.train(resume_from_checkpoint=checkpoint)        metrics = train_result.metrics        max_train_samples = (            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)        )        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))        metrics[\"peak mem (G)\"] = torch.cuda.max_memory_allocated() / (1024 * 1024 * 1000)        metrics[\"activation mem (G)\"] = (torch.cuda.max_memory_allocated() - torch.cuda.memory_allocated()) / (1024 * 1024 * 1000)        trainer.save_model()        trainer.log_metrics(\"train\", metrics)        trainer.save_metrics(\"train\", metrics)        trainer.save_state()    if training_args.do_eval:        logger.info(\"*** Evaluate ***\")        tasks = [data_args.task_name]        eval_datasets = [eval_dataset]        if data_args.task_name == \"mnli\":            tasks.append(\"mnli-mm\")            valid_mm_dataset = raw_datasets[\"validation_mismatched\"]            if data_args.max_eval_samples is not None:                max_eval_samples = min(len(valid_mm_dataset), data_args.max_eval_samples)                valid_mm_dataset = valid_mm_dataset.select(range(max_eval_samples))            eval_datasets.append(valid_mm_dataset)            combined = {}        for eval_dataset, task in zip(eval_datasets, tasks):            metrics = trainer.evaluate(eval_dataset=eval_dataset)            max_eval_samples = (                data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)            )            metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))            if task == \"mnli-mm\":                metrics = {k + \"_mm\": v for k, v in metrics.items()}            if task is not None and \"mnli\" in task:                combined.update(metrics)            metrics[\"peak mem(G)\"] = torch.cuda.max_memory_allocated() / (1024 * 1024 * 1000)            trainer.log_metrics(\"eval\", metrics)            trainer.save_metrics(\"eval\", combined if task is not None and \"mnli\" in task else metrics)    if training_args.do_predict:        logger.info(\"*** Predict ***\")        tasks = [data_args.task_name]        predict_datasets = [predict_dataset]        if data_args.task_name == \"mnli\":            tasks.append(\"mnli-mm\")            predict_datasets.append(raw_datasets[\"test_mismatched\"])        for predict_dataset, task in zip(predict_datasets, tasks):            predict_dataset = predict_dataset.remove_columns(\"label\")            predictions = trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions            predictions = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)            output_predict_file = os.path.join(training_args.output_dir, f\"predict_results_{task}.txt\")            if trainer.is_world_process_zero():                with open(output_predict_file, \"w\") as writer:                    logger.info(f\"***** Predict results {task} *****\")                    writer.write(\"index\\tprediction\\n\")                    for index, item in enumerate(predictions):                        if is_regression:                            writer.write(f\"{index}\\t{item:3.3f}\\n\")                        else:                            item = label_list[item]                            writer.write(f\"{index}\\t{item}\\n\")    kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"text-classification\"}    if data_args.task_name is not None:        kwargs[\"language\"] = \"en\"        kwargs[\"dataset_tags\"] = \"glue\"        kwargs[\"dataset_args\"] = data_args.task_name        kwargs[\"dataset\"] = f\"GLUE {data_args.task_name.upper()}\"    if training_args.push_to_hub:        trainer.push_to_hub(**kwargs)    else:        trainer.create_model_card(**kwargs)def _mp_fn(index):    main()if __name__ == \"__main__\":    main()class CustomTrainer(Trainer):    def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:        model.train()        inputs = self._prepare_inputs(inputs)        if is_sagemaker_mp_enabled():            loss_mb = smp_forward_backward(model, inputs, self.args.gradient_accumulation_steps)            return loss_mb.reduce_mean().detach().to(self.args.device)        with self.compute_loss_context_manager():            loss = self.compute_loss(model, inputs)        if self.args.n_gpu > 1:            loss = loss.mean()        if self.args.gradient_accumulation_steps > 1 and not self.deepspeed:            loss = loss / self.args.gradient_accumulation_steps        if self.do_grad_scaling:            self.scaler.scale(loss).backward()        elif self.use_apex:            with amp.scale_loss(loss, self.optimizer) as scaled_loss:                scaled_loss.backward()        elif self.deepspeed:            loss = self.deepspeed.backward(loss)        else:            loss.backward()        if self.args.start_layer == -1:            model.bert.embeddings.LayerNorm.bias.grad = None            model.bert.embeddings.LayerNorm.weight.grad = None        else:            model.bert.encoder.layer[self.args.start_layer].output.LayerNorm.bias.grad = None            model.bert.encoder.layer[self.args.start_layer].output.LayerNorm.weight.grad = None        return loss.detach()",
    "Experiment Result": "MEFT (Memory-Efficient Fine-Tuning) is implemented using reversible neural network principles to achieve O(1) memory footprint during backpropagation by recomputing intermediate activations. The core method involves splitting hidden states into two parts (x1, x2), applying two functions (F and G), and combining them (y1, y2). A custom `RevBackProp` autograd function handles the reversible backward pass. \n\nThree MEFT architectures are supported via the `f_arch` configuration parameter:\n1.  **MEFT1 (`f_arch=\"layer\"`):** F is the PLM layer (`forward_layer`), and G is an adapter (`forward_adapter`). The outputs are switched (concatenated as [y2, y1]). Adapters are inserted in parallel within the feed-forward chunk (`ffn_adapter`) and in parallel to the reversible layer (`rev_adapter`).\n2.  **MEFT2 (`f_arch=\"adapter\"`):** F is an adapter (`forward_adapter`), and G is the PLM layer (`forward_layer`). The outputs are also switched (concatenated as [y2, y1]). Adapter insertion is similar to MEFT1.\n3.  **MEFT3 (`f_arch=\"attn\"`):** F is the attention block (`forward_attention`), and G is the MLP block (`forward_mlp`). Outputs are not switched (concatenated as [y1, y2]). An adapter (`attn_adapter`) is inserted into the output of the attention block within `RevBertSelfOutput`.\n\nKey experimental settings and features:\n-   **Scaling Factors:** `x1_factor` (lambda) and `x2_factor` (beta) are applied during the forward pass (e.g., `y1 = x1_factor * x1 + f_x2`, `y2 = x2_factor * x2 + g_y1`). These are configurable via `ModelArguments` and default to 1, but typical values are 0.1 as per comments.\n-   **Hybrid Reversible/Vanilla Layers:** The `RevBertEncoder` supports using a subset of layers as reversible (`num_rev_layers`) and the remaining layers as vanilla (standard Transformer layers with activation caching). This allows for a flexible memory-performance trade-off.\n-   **Starting Point Hypothesis & Parameter Freezing:** When adapters are used (`adapter_bottleneck_dim > 0`), all pre-trained model parameters are initially frozen. Only adapter parameters and the classifier head are unfrozen. Additionally, to support the starting point hypothesis and enable gradient flow without updating certain non-adapter parameters:\n    -   If `freeze_irreversible_layers` is `True`, the `LayerNorm` of the last irreversible layer is unfrozen.\n    -   Otherwise, the `embeddings.LayerNorm` is unfrozen.\n    -   In `CustomTrainer`, after the backward pass, the gradients of these specific unfrozen `LayerNorm` parameters (`bias.grad` and `weight.grad`) are explicitly set to `None` to prevent their update while still allowing gradients to pass through.\n-   **Adapter Module:** The `Adapter` class defines a bottleneck structure with two dense layers, an activation function, and dropout. It can optionally include a `LayerNorm` (`layernorm_in_adapter`).\n-   **Configuration:** Parameters like `adapter_bottleneck_dim`, `layernorm_in_adapter`, `num_rev_layers`, `x1_factor`, `x2_factor`, `f_arch`, and `freeze_irreversible_layers` are parsed from command-line arguments in `run_glue.py` and passed to the model's configuration."
}{
    "Title": "The Expressive Power of Low-Rank Adaptation",
    "Main Contributions": "This paper theoretically analyzes the expressive power of Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method. For fully connected neural networks (FNNs), it proves that LoRA can adapt any model to accurately represent a smaller target model if the LoRA-rank is sufficiently high (rank >= (width of f) * depth of f / depth of f). It quantifies the approximation error when the LoRA-rank is below this threshold. For Transformer networks (TFNs), it shows that any model can be adapted to a target model of the same size with rank-(embedding size / 2) LoRA adapters applied to attention weight matrices. The study provides theoretical insights on hyperparameter tuning and algorithm development for LoRA, which are empirically validated. It also demonstrates LoRA's superiority over tuning final layers for randomly generated networks and highlights the importance of updating bias parameters.",
    "Methodology": "The research employs a theoretical analysis of LoRA's expressive power, focusing on its ability to enable a frozen model to match a target model's functionality. It starts with a warm-up on linear models to establish core matrix approximation results, extending the Eckart-Young-Mirsky theorem to a product of matrices under low-rank constraints. For FNNs, the methodology involves linearizing the first L-1 layers by activating all ReLUs with large bias vectors and applying the linear model approximation results. For multi-layer FNNs, it uses model partition (uniform and general schemes) where each sub-model approximates a layer of the target FNN. For TFNs, the analysis manages non-linearities (softmax and ReLU) by segmenting transformer blocks and aligning outputs before these functions, focusing on adapting self-attention layers. All results rely on mild non-singularity assumptions of weight matrices, which are proven to hold for randomly generated matrices with high probability.",
    "Experimental Setup": "Experiments are conducted on both synthetic and real datasets. For synthetic validation, linear models, FNNs, and TFNs with a dimensionality D=16 are used, exploring different depths (e.g., L=1/L=2, L=2/L=4 for FNNs; L=1, L=2 for TFNs). Two variants of frozen models are tested: 'Random' (weights initialized with Xavier uniform or standard Gaussian distribution) and 'Pretrained' (frozen model partially updated via gradient descent to be closer to the target). The primary metric for approximation error is Mean Squared Error (MSE), with comparisons against a gradient update method (Adam optimizer with tuned learning rate/weight decay). Additional experiments include comparing LoRA with final layer tuning, investigating the benefits of tuning biases, visualizing training curves, assessing generalization performance (on varying training sample sizes), and evaluating binary and multi-class classification tasks (using cross-entropy and accuracy). For real-world validation, LoRA's performance is evaluated on the GLUE benchmark using RoBERTa-base (110M parameters) and RoBERTa-large (340M parameters), reporting specific task metrics.",
    "Limitations": "The current theoretical study focuses solely on the expressive power of LoRA, explicitly excluding optimization and generalization properties (though generalization is empirically explored in the appendix). The construction of LoRA adapters presented in the proofs, while theoretically sound for exact approximation, is observed to be suboptimal compared to gradient-based methods in some empirical settings, particularly for FNNs at low ranks and TFNs. Due to analytical complexity, approximation errors for TFNs are not quantified when LoRA-ranks are lower than required for exact matching. For TFNs, the analysis simplifies the architecture by assuming identical embedding size and depth for target and frozen models, and omitting skip connections and layer norms. The theoretical framework does not incorporate any training process or dynamics. Empirically, the generalization gap (test MSE - train MSE) did not show a clear pattern with increasing LoRA ranks, suggesting further investigation is needed. The suboptimality of current optimization algorithms for LoRA is also noted.",
    "Future Research Directions": "Future research directions include devising more parameter-efficient schemes for constructing LoRA adapters to achieve tighter approximation error bounds. For TFNs, quantifying approximation errors when LoRA-ranks are below the required threshold is an open challenge. Exploring the expressive power of LoRA under more general TFN architectural settings, such as varying embedding sizes, depths, and including skip connections and layer norms, is also suggested. Investigating gradient-based optimization algorithms to understand how efficiently LoRA can be optimized is another avenue. Finally, theoretical questions regarding LoRA's generalization capabilities to unseen data remain unresolved and warrant further study.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning",
    "Main Contributions": "The paper addresses matrix estimation problems in reinforcement learning (RL) with low-rank structure, focusing on achieving low entry-wise error while accommodating inherent data correlations (e.g., Markovian data in MDPs). It introduces three matrix estimation problems (low-rank bandits, low-rank MDPs with generative model, and low-rank MDPs with forward model) and demonstrates that simple spectral-based estimation methods efficiently recover singular subspaces with nearly-minimal entry-wise error. The authors develop and combine leave-one-out arguments and Poisson approximation techniques to handle data correlations. These results are applied to devise a regret-minimization algorithm for low-rank bandits, yielding state-of-the-art performance guarantees (regret scales as O((m+n)log^3(T) * delta_bar / delta_min^2)), and a best policy identification algorithm for reward-free low-rank MDPs, achieving minimax optimal sample complexity (O(nA/epsilon^2) up to logarithmic factors).",
    "Methodology": "The core methodology involves spectral-based matrix estimation. For all problems, an empirical matrix (~M) is constructed from observed data, and the final estimate (^M) is obtained as its best rank-r approximation via spectral decomposition. To address inherent data correlations, particularly in Markovian settings (MDPs), the authors develop and combine advanced theoretical tools: leave-one-out arguments for singular subspace recovery and Poisson approximation techniques. This allows for rigorous analysis even when data entries are not independent. For low-rank bandits, the SME-AE (Successive Matrix Estimation and Arm Elimination) algorithm is proposed, which iteratively samples entries, estimates the reward matrix, and prunes candidate arms. For reward-free low-rank MDPs, a two-phase approach is used: (1) model estimation by collecting trajectories for each action and applying the spectral decomposition method, and (2) a planning phase to compute the optimal policy based on the estimated model.",
    "Experimental Setup": "The research is primarily theoretical, establishing performance guarantees through rigorous mathematical analysis rather than empirical experiments with specific datasets. The 'experimental setup' refers to the data generation models for which the theoretical bounds are derived: (1) **Model I: Reward matrices in low-rank bandits**, where arms are randomly selected, and noisy rewards are observed. (2) **Model II(a): Transition matrices in low-rank MDPs under a generative model**, where states are sampled from a distribution, and next states are sampled from the transition kernel. (3) **Model II(b): Transition matrices in low-rank MDPs under a forward model**, where a single trajectory of the Markov chain is observed. Performance is validated by theoretical bounds on singular subspace recovery (e.g., 2->infinity norm) and matrix entry-wise error (e.g., 1->infinity and infinity norms), along with regret guarantees for bandit algorithms and sample complexity for MDP policy identification.",
    "Limitations": "A notable limitation is that the cubic dependence in log^3(T) in the regret upper bound for low-rank bandits is an artifact of the Poisson approximation used in the proof techniques for entry-wise guarantees. The minimax optimal sample complexity for low-rank MDPs is specifically proven 'at least when the frequency matrices {Ma}a∈A are homogeneous,' implying less general or tighter bounds for heterogeneous cases are not explicitly provided. For the forward model in MDPs, selecting the data splitting parameter 'τ' requires prior knowledge or an estimation of the Markov chain's mixing time, which is a prerequisite for the guarantees to hold. Furthermore, while the proposed methods are computationally efficient and do not rely on strong computational oracles (unlike some related RL algorithms), they do not directly address all assumptions required by other matrix estimation methods (e.g., access to anchor rows/columns) nor is it clear how those methods would extend to dependent noise or subspace recovery in the 2->infinity norm.",
    "Future Research Directions": "The authors suggest several future applications and extensions for their low-rank matrix estimation results: (i) to reward-free RL in episodic MDPs, leveraging the independence across episodes; (ii) to offline RL scenarios where data consists of a single trajectory generated under a given behavior policy, enabling learning of individual transition matrices; (iii) to traditional RL settings where the reward function R needs to be learned, positioning it between the inference problems of Models I and II; (iv) to model-free RL by directly learning the Q-function, similar to [58] under a generative model; and (v) to low-rank RL problems with continuous state spaces, by combining their methods with appropriate discretization of the state space if transition probabilities are smooth.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Low-rank Optimal Transport: Approximation, Statistics and Debiasing",
    "Main Contributions": "This paper advances the theoretical understanding and practical application of low-rank factorizations in Optimal Transport (OT). Key contributions include deriving the rate of convergence of low-rank OT (LOT) to true OT based on the non-negative rank, providing a dimension-independent O(sqrt(1/n)) statistical error upper-bound for LOT's plug-in estimator, introducing a debiased LOT (DLOTr,c) that is non-negative, metrizes weak convergence, and interpolates between MMD and OT, establishing links between low-rank bias and generalized clustering methods, and proposing practical strategies for adaptive step-size tuning and improved initialization for the LOT algorithm.",
    "Methodology": "The core methodology involves constraining the discrete OT problem to couplings with a low-nonnegative rank (LOTr,c), solved using a mirror descent scheme with Dykstra's Algorithm. A debiased version (DLOTr,c) is introduced to address the non-zero bias of LOTr,c(µ,µ). Statistical properties are analyzed using a plug-in estimator, with convergence rates and consistency proofs based on techniques like McDiarmid’s inequality. The paper also reformulates LOT's internal bias as a generalized k-means clustering method for arbitrary metric spaces. Algorithmic enhancements include an adaptive step-size for the mirror descent (normalized by the squared dual-norm of the gradient) and novel initialization strategies based on k-means (for Euclidean spaces) or the generalized k-means (for general non-Euclidean spaces), aiming to avoid spurious local minima.",
    "Experimental Setup": "The research validates its findings using 3 synthetic problems and 1 real-world dataset. Experiments include illustrating statistical rates of DLOTr,c on a mixture of 10 anisotropic Gaussians (varying dimension d) using squared Euclidean distance, demonstrating gradient flows of DLOTr,c (vs. LOT) for transforming Gaussian or moon-shaped distributions to moon-shaped targets in 2D using 1000 samples and squared Euclidean distance, applying the generalized clustering method to 6 diverse scikit-learn datasets (1000 samples each) with squared Euclidean and shortest-path distances, and evaluating the effect of different initialization strategies (k-means, generalized k-means, rank-2, random) on the Newsgroup20 dataset (texts embedded in 50D, ~250 samples) by tracking LOT cost and stopping criterion over algebraic operations. All experiments were conducted on a MacBook Pro 2019 laptop.",
    "Limitations": "The computational cost of regularized OT methods, including entropic regularization, still scales quadratically in the number of observations. Theoretical properties of low-rank OT approaches are not as well-established as Sinkhorn's. While an upper-bound for statistical error is provided, a matching lower bound is not, thus a complete statistical complexity result is lacking. The constant Kr in the statistical error bound cannot be explicitly controlled in the general setting without additional assumptions. The LOTr,c optimization problem is non-convex, making it susceptible to spurious local minima, especially when a stopping criterion is used. The optimal step-size (γ) for the mirror descent can vary significantly between different problems, complicating hyperparameter tuning for fixed schedules, which the proposed adaptive method aims to alleviate.",
    "Future Research Directions": "Future research should focus on further investigating the empirical behavior of the LOT estimator, particularly in discovering suitable local minima for the non-convex optimization problem. Another direction is to explore improvements in the convergence of the Mirror Descent (MD) scheme by developing and testing other adaptive choices for step sizes beyond those proposed. Additionally, providing a lower bound that matches the current upper bound for the statistical complexity of LOT would complete its theoretical understanding.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Low-rank lottery tickets: finding efficient low-rank neural networks via matrix differential equations",
    "Main Contributions": "The paper introduces Dynamic Low-Rank Training (DLRT), a novel algorithm that finds and adapts efficient low-rank subnetworks (\"low-rank lottery tickets\") during the neural network training phase. It addresses high memory and computational demands by restricting weight matrices to a low-rank manifold and updating only their low-rank factors via techniques from dynamic model order reduction for matrix differential equations. DLRT dynamically adapts ranks, offers approximation and stability guarantees, significantly reduces training/evaluation costs, and achieves comparable accuracy to full-rank models.",
    "Methodology": "DLRT reinterprets neural network training as a continuous-time gradient flow (matrix ODE). Weight matrices are factorized (UkSkV⊤k) and their updates are derived using Dynamical Low-Rank Approximation (DLRA), specifically an \"unconventional KLS integrator\" with a rank-adaptive extension. The KLS algorithm performs parallel K-steps and L-steps for basis updates, followed by an S-step for singular value matrix updates. Rank adaptivity is achieved by augmenting bases and truncating singular values below a threshold (ϑ) using SVD. Gradient computations are optimized by operating directly on low-rank factors. Numerical integration uses Explicit Euler (SGD) or Adam. Convolutional kernels are reshaped into matrices for low-rank factorization.",
    "Experimental Setup": "Evaluations were conducted on fully-connected and convolutional networks (LeNet5, ResNet-50, AlexNet, VGG16) using PyTorch and TensorFlow. Datasets included MNIST, Cifar10, and ImageNet1K. Training used Adam or SGD optimizers (with momentum) with specified learning rates and batch sizes. Performance metrics included test accuracy, parameter compression ratio, and training/prediction times. Comparisons were made against full-rank baselines and other low-rank/pruning methods. Rank adaptation utilized a singular value threshold ϑ= τ∥Σ∥.",
    "Limitations": "DLRT's efficiency requires the inherent rank of weight matrices (rk) to be much smaller than their dimensions. Setting the singular value truncation threshold (ϑ) too low negates efficiency gains. The method primarily reduces model parameter and optimizer costs, but does not inherently reduce activation costs, requiring combination with techniques like micro-batching or checkpointing. The parameter ϑ introduces an additional hyperparameter needing manual tuning.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": "import torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch import float16   \n\nclass dlr_opt:\n\n    def __init__(self,NN,tau = 0.01,theta = 0.1,absolute = False,\n                KLS_optim = None,**kwargs):\n\n        \"\"\"\n        initializer for the dlr_opt (dynamical low rank optimizer) class.\n        INPUTS:\n        NN: neural network with custom layers, methods and attributes needed (look at Lenet5 for an example) \n        tau : learning rate (integration step)\n        theta : tolerance for singular values\n        absolute : flag variable, True if theta has to be interpreted as an absolute tolerance  \n        KLS_optim : Pytorch integrator to perform the integration step\n        \"\"\"\n\n        self.NN = NN\n        self.tau = tau\n        self.theta = theta\n        self.absolute = absolute\n        self.kw = dict(kwargs)\n        self.KLS_optim = KLS_optim\n\n        if self.KLS_optim is not None:\n\n            self.integrator = self.KLS_optim(self.NN.parameters(),lr = self.tau,**kwargs)\n\n        else:\n\n            self.integrator = torch.optim.SGD(self.NN.parameters(),lr = self.tau,**kwargs)\n\n\n    @torch.no_grad()\n    def K_postprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n                    \n                    U_hat = torch.hstack((l.K[:,:l.dynamic_rank],l.U[:,:l.dynamic_rank]))\n\n                    try:\n                        U_hat,_ = torch.linalg.qr(U_hat)\n                    except:\n                        U_hat,_ = np.linalg.qr(U_hat)\n                        U_hat = torch.tensor(U_hat)\n                    l.U_hat[:,:2*l.dynamic_rank] = U_hat\n                    l.M_hat[:2*l.dynamic_rank,:l.dynamic_rank] = l.U_hat[:,:2*l.dynamic_rank].T@l.U[:,:l.dynamic_rank]\n                \n                else:\n\n                    try:\n                        U_hat,_ = torch.linalg.qr(l.K)\n\n                    except:\n                        U_hat,_ = np.linalg.qr(U_hat)\n                        U_hat = torch.tensor(U_hat)\n                    l.M_hat.data = U_hat.T@l.U.data\n                    l.U.data = U_hat\n\n    @torch.no_grad()\n    def postprocess_step(self):\n        \n        self.K_postprocess_step()\n        self.L_postprocess_step()\n\n    @torch.no_grad()\n    def K_integration_step(self):\n        \n        self.zero_bias_grad()\n        self.integrator.step()\n\n    @torch.no_grad()\n    def zero_bias_grad(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'bias') and l.bias is not None:\n\n                l.bias.grad = None\n\n            if hasattr(l,'weight') and l.weight is not None:\n\n                l.weight.grad = None\n\n    @torch.no_grad()\n    def L_postprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    V_hat = torch.hstack((l.L[:,:l.dynamic_rank],l.V[:,:l.dynamic_rank]))\n                    try :\n                        V_hat,_ = torch.linalg.qr(V_hat)\n                    except:\n                        V_hat,_ = np.linalg.qr(V_hat.detach().numpy())\n                        V_hat= torch.tensor(V_hat)\n                    l.V_hat[:,:2*l.dynamic_rank] = V_hat\n                    l.N_hat[:2*l.dynamic_rank,:l.dynamic_rank] = l.V_hat[:,:2*l.dynamic_rank].T@l.V[:,:l.dynamic_rank]\n\n                else:\n\n                    try :\n                        V_hat,_ = torch.linalg.qr(l.L)\n                    except:\n                        V_hat,_ = np.linalg.qr(V_hat.detach().numpy())\n                        V_hat= torch.tensor(V_hat)\n                    l.N_hat.data = V_hat.T@l.V.data\n                    l.V.data = V_hat\n\n\n    \n    @torch.no_grad()\n    def L_integration_step(self):\n\n\n        self.integrator.step()\n        self.integrator.zero_grad()\n\n    @torch.no_grad()\n    def K_and_L_integration_step(self):\n        \n        self.zero_bias_grad()\n        self.integrator.step()\n\n    @torch.no_grad()\n    def S_preprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    s = l.M_hat[:2 * l.dynamic_rank, :l.dynamic_rank]@l.S_hat[: l.dynamic_rank, :l.dynamic_rank]@l.N_hat[:2 * l.dynamic_rank, :l.dynamic_rank].T\n                    l.S_hat[:2*l.dynamic_rank,:2*l.dynamic_rank] = s\n\n                else:\n\n                    s = l.M_hat@l.S_hat@l.N_hat.T\n                    l.S_hat.data = s\n\n\n\n    @torch.no_grad()\n    def K_preprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n                \n                    K = l.U[:,:l.dynamic_rank]@l.S_hat[:l.dynamic_rank,:l.dynamic_rank]\n                    l.K[:,:l.dynamic_rank] = K\n\n                else:\n\n                    K = l.U.data@l.S_hat\n                    l.K.data = K\n\n\n\n    @torch.no_grad()\n    def L_preprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    L = l.V[:,:l.dynamic_rank]@l.S_hat[:l.dynamic_rank,:l.dynamic_rank].T\n                    l.L[:,:l.dynamic_rank] = L\n\n                else:\n\n                    L = l.V.data@l.S_hat.T\n                    l.L.data = L\n\n\n    @torch.no_grad()\n    def S_postprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    # rank adaption\n\n                    s_small = torch.clone(l.S_hat[:2 * l.dynamic_rank, :2 * l.dynamic_rank])\n                    try:\n                        u2, d, v2 = torch.linalg.svd(s_small)\n                    except Exception as e:\n                        print(e)\n                        print(s_small)\n                        u2, d, v2 = np.linalg.svd(s_small)\n\n                    tmp = 0.0\n                    tol = self.theta * torch.linalg.norm(d) if not self.absolute else self.theta \n                    rmax = int(np.floor(d.shape[0] / 2))\n                    for j in range(0, 2 * rmax - 1):\n                        tmp = torch.linalg.norm(d[j:2 * rmax - 1])\n                        if tmp < tol:\n                            rmax = j\n                            break\n\n                    rmax = min([rmax, l.rmax])\n                    rmax = max([rmax, 2])\n\n                    l.S_hat[:rmax,:rmax] = torch.diag(d[:rmax])\n                    l.U[:, :rmax] = l.U_hat[:, :2 * l.dynamic_rank]@u2[:, :rmax]\n                    l.V[:,:rmax] =  l.V_hat[:,:2 * l.dynamic_rank]@(v2[:, :rmax])\n                    l.dynamic_rank = int(rmax)\n\n    \n    @torch.no_grad()\n    def S_integration_step(self):\n\n        self.integrator.step()\n        self.integrator.zero_grad()\n    \n\n    @torch.no_grad()\n    def preprocess_step(self):\n\n        self.K_preprocess_step()\n        self.L_preprocess_step()\n\n    @torch.no_grad()\n    def step(self,closure = None):\n\n        \"\"\"\n        optimizer step for the dlrt.\n        INPUTS:\n        closure : function to compute the loss and backpropagate a second time (Pytorch standard)\n        \"\"\"\n\n        # self.K_integration_step()\n        # self.L_integration_step()\n        self.K_and_L_integration_step()\n        self.K_postprocess_step()\n        self.L_postprocess_step()\n        self.S_preprocess_step()\n        self.zero_grad()\n        if closure is not None:\n            with torch.set_grad_enabled(True):\n                loss = closure()\n                loss.backward()\n        self.S_integration_step()\n        self.S_postprocess_step()\n    \n    @torch.no_grad()\n    def zero_grad(self):\n        for p in self.NN.parameters():\n            if p.requires_grad:\n                p.grad = None\n\n\n    @torch.no_grad()\n    def activate_S_fine_tuning(self):\n\n        params = []\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                l.K.requires_grad = False\n                l.L.requires_grad = False\n                l.S_hat = torch.nn.Parameter(l.S_hat[:l.dynamic_rank,:l.dynamic_rank])\n                l.fixed = True\n                l.U = torch.nn.Parameter(l.U[:,:l.dynamic_rank],requires_grad = False)\n                l.V = torch.nn.Parameter(l.V[:,:l.dynamic_rank],requires_grad = False)\n                l.step = 'S'\n                params.append(l.S_hat)\n        params = torch.nn.ParameterList(params)\n        self.integrator = self.KLS_optim(params,lr = self.tau,**self.kw)\n\n\n    @torch.no_grad()\n    def S_finetune_step(self):\n\n        self.integrator.step()\n\n\n# imports \nimport math\nimport warnings\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=Warning)\n\n# low rank convolution class \n\nclass Conv2d_lr(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1,bias = True,step = 'K',rank = None,\n    fixed = False,dtype = None,device = None,load_weights = None,full_rank_construct = False)->None:\n\n        \"\"\"  \n        Initializer for the convolutional low rank layer (filterwise), extention of the classical Pytorch's convolutional layer.\n        INPUTS:\n        in_channels: number of input channels (Pytorch's standard)\n        out_channels: number of output channels (Pytorch's standard)\n        kernel_size : kernel_size for the convolutional filter (Pytorch's standard)\n        dilation : dilation of the convolution (Pytorch's standard)\n        padding : padding of the convolution (Pytorch's standard)\n        stride : stride of the filter (Pytorch's standard)\n        bias  : flag variable for the bias to be included (Pytorch's standard)\n        step : string variable ('K','L' or 'S') for which forward phase to use\n        rank : rank variable, None if the layer has to be treated as a classical Pytorch Linear layer (with weight and bias). If\n                it is an int then it's either the starting rank for adaptive or the fixed rank for the layer.\n        fixed : flag variable, True if the rank has to be fixed (KLS training on this layer)\n        load_weights : variables to load (Pytorch standard, to finish)\n        dtype : Type of the tensors (Pytorch standard, to finish)\n        \"\"\"\n            \n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super(Conv2d_lr, self).__init__()\n\n        self.kernel_size = [kernel_size, kernel_size] if isinstance(kernel_size,int) else kernel_size\n        self.kernel_size_number = kernel_size * kernel_size\n        self.out_channels = out_channels\n        self.dilation = dilation if type(dilation)==tuple else (dilation, dilation)\n        self.padding = padding if type(padding) == tuple else(padding, padding)\n        self.stride = (stride if type(stride)==tuple else (stride, stride))\n        self.in_channels = in_channels\n        self.rank = rank\n        self.device = device\n        self.dtype = dtype\n        self.fixed = fixed\n        self.load_weights = load_weights\n        self.weight = torch.nn.Parameter(torch.empty(tuple([self.out_channels, self.in_channels] +self.kernel_size),**factory_kwargs),requires_grad = True)\n        self.lr = True if self.rank!=None else False\n        self.rmax = int(min([self.out_channels, self.in_channels*self.kernel_size_number]) / 2)\n        self.full_rank_construct = full_rank_construct\n        if not self.fixed:\n            self.rank = None if rank == None else min([rank,self.rmax])\n        else:\n            self.rank = min([rank,self.out_channels,self.in_channels*self.kernel_size_number])\n        self.dynamic_rank = self.rank\n        self.step = step\n\n        if bias:\n            self.bias = torch.nn.Parameter(torch.empty(self.out_channels,**factory_kwargs))\n        else:\n            self.bias = torch.nn.Parameter(torch.zeros(self.out_channels,**factory_kwargs))\n\n        self.reset_parameters()\n    \n        # Weights and Bias initialization\n        if self.load_weights == None:\n            self.reset_parameters()\n        else:\n            param,b = self.load_weights\n            self.bias = torch.nn.Parameter(b)\n            self.weight = torch.nn.Parameter(param,requires_grad = True)\n\n        if self.lr and not self.full_rank_construct:\n\n            if not self.fixed:\n\n                n,m = self.out_channels,self.in_channels*self.kernel_size_number\n\n                _,s_ordered,_ = torch.linalg.svd(torch.diag(torch.abs(torch.randn(2*self.rmax))))\n                U = torch.randn(n,self.rmax)\n                V = torch.randn(m,self.rmax)\n                U,_,_ = torch.linalg.svd(U)\n                V,_,_ = torch.linalg.svd(V)\n                self.U = torch.nn.Parameter(U.to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(s_ordered).to(device))                                       \n                self.V = torch.nn.Parameter(V.to(device),requires_grad=False) \n                self.U_hat = torch.nn.Parameter( torch.randn(n,2*self.rmax).to(device) ,requires_grad = False)\n                self.V_hat = torch.nn.Parameter(torch.randn(m,2*self.rmax).to(device) ,requires_grad = False)\n                self.K = torch.nn.Parameter(torch.randn(n,self.rmax).to(device))\n                self.L = torch.nn.Parameter(torch.randn(m,self.rmax).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.S = torch.nn.Parameter(torch.randn(self.rmax,self.rmax).to(device),requires_grad = False)\n                self.weight = None\n                self.id = id(self.K)\n\n            else:\n\n                n,m = self.out_channels,self.in_channels*self.kernel_size_number\n\n                _,s_ordered,_ = torch.linalg.svd(torch.diag(torch.abs(torch.randn(self.rank))))\n                U = torch.randn(n,self.rank)\n                V = torch.randn(m,self.rank)\n                U,_,_ = torch.linalg.svd(U)\n                V,_,_ = torch.linalg.svd(V)\n                self.U = torch.nn.Parameter(U[:,:self.rank].to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(s_ordered).to(device))                                       \n                self.V = torch.nn.Parameter(V[:,:self.rank].to(device),requires_grad=False)\n                self.K = torch.nn.Parameter(torch.randn(n,self.rank).to(device))\n                self.L = torch.nn.Parameter(torch.randn(m,self.rank).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(self.rank,self.rank).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(self.rank,self.rank).to(device) ,requires_grad = False)\n                self.weight = None\n\n    def switch_lowrank(self):\n        \n        w,b = self.weight,self.bias\n        device = self.device\n        if not self.fixed:\n            self.rank = None if self.rank == None else min([self.rank,self.rmax])\n        else:\n            self.rank = min([self.rank,self.out_channels,self.in_channels*self.kernel_size_number])\n        self.dynamic_rank = self.rank\n\n        self.bias = b\n\n        if self.lr:\n\n            if not self.fixed:\n\n                n,m = self.out_channels,self.in_channels*self.kernel_size_number\n\n                U_load,S_load,V_load = torch.linalg.svd(w.view(n,m))\n                V_load = V_load.T\n                r = len(S_load)\n                _,s_ordered,_ = torch.linalg.svd(torch.diag(torch.abs(torch.randn(2*self.rmax-r))))\n                s_ordered = torch.tensor(torch.cat([S_load,s_ordered.to(device)])).to(device)\n                self.U = torch.nn.Parameter(U_load.to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(s_ordered).to(device))                                       \n                self.V = torch.nn.Parameter(V_load.to(device),requires_grad=False)\n                self.U_hat = torch.nn.Parameter( torch.randn(n,2*self.rmax).to(device) ,requires_grad = False)\n                self.V_hat = torch.nn.Parameter(torch.randn(m,2*self.rmax).to(device) ,requires_grad = False)\n                self.K = torch.nn.Parameter(torch.randn(n,self.rmax).to(device))\n                self.L = torch.nn.Parameter(torch.randn(m,self.rmax).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(r,r).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(r,r).to(device) ,requires_grad = False)\n                self.weight = None\n                self.id = id(self.K)\n            else:\n                n,m = self.out_channels,self.in_channels*self.kernel_size_number\n\n                U_load,S_load,V_load = torch.linalg.svd(w.view(n,m))\n                V_load = V_load.T\n                r = self.rank\n                self.U = torch.nn.Parameter(U_load[:,:r].to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(S_load[:r]).to(device))                                       \n                self.V = torch.nn.Parameter(V_load[:,:r].to(device),requires_grad=False)\n                self.K = torch.nn.Parameter(torch.randn(n,r).to(device))\n                self.L = torch.nn.Parameter(torch.randn(m,r).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.weight = None\n                self.id = id(self.K)\n\n\n\n    def reset_parameters(self) -> None:\n        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n         # for testing\n        # self.original_weight = Parameter(self.weight.reshape(self.original_shape))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            if fan_in != 0:\n                bound = 1 / math.sqrt(fan_in)\n                init.uniform_(self.bias, -bound, bound)  \n\n\n    def forward(self, input):\n\n        \"\"\"  \n        forward phase for the convolutional layer. It has to contain the three different\n        phases for the steps 'K','L' and 'S' in order to be optimizable using dlrt.\n\n        \"\"\"\n        \n        batch_size,_,_,_ = input.shape\n\n        if not self.lr:\n\n            return F.conv2d(input = input,weight = self.weight,bias = self.bias,stride = self.stride,\n                padding = self.padding,dilation = self.dilation)\n\n        else:\n\n            if self.step == 'K':\n\n                if not self.fixed:\n\n                    K,V = self.K[:,:self.dynamic_rank],self.V[:,:self.dynamic_rank] # Corrected from l.dynamic_rank to self.dynamic_rank\n\n                else:\n\n                    K,V = self.K,self.V\n\n                inp_unf = F.unfold(input,self.kernel_size,padding = self.padding,stride = self.stride).to(self.device)\n    \n                if self.bias is None:\n                    out_unf = (inp_unf.transpose(1, 2).matmul(V) )\n                    out_unf = (out_unf.matmul(K.t()) + self.bias).transpose(1, 2)\n                else:\n                    out_h = int(np.floor(((input.shape[2]+2*self.padding[0]-self.dilation[0]*(self.kernel_size[0]-1)-1)/self.stride[0])+1))\n                    out_w = int(np.floor(((input.shape[3]+2*self.padding[1]-self.dilation[1]*(self.kernel_size[1]-1)-1)/self.stride[1])+1))\n\n                    out_unf = (inp_unf.transpose(1, 2).matmul(V) )\n                    out_unf = (out_unf.matmul(K.t()) + self.bias).transpose(1, 2)\n    \n                return out_unf.view(batch_size, self.out_channels, out_h, out_w)\n\n            elif self.step =='L':\n\n                if not self.fixed:\n\n                    U,L = self.U[:,:self.dynamic_rank],self.L[:,:self.dynamic_rank]\n                \n                else:\n\n                    U,L = self.U,self.L\n\n                inp_unf = F.unfold(input,self.kernel_size,padding = self.padding,stride = self.stride).to(self.device)\n    \n                if self.bias is None:\n                    out_unf = (inp_unf.transpose(1, 2).matmul(L) )\n                    out_unf = (out_unf.matmul(U.t()) + self.bias).transpose(1, 2)\n                else:\n                    out_h = int(np.floor(((input.shape[2]+2*self.padding[0]-self.dilation[0]*(self.kernel_size[0]-1)-1)/self.stride[0])+1))\n                    out_w = int(np.floor(((input.shape[3]+2*self.padding[1]-self.dilation[1]*(self.kernel_size[1]-1)-1)/self.stride[1])+1))\n\n                    out_unf = (inp_unf.transpose(1, 2).matmul(L) )\n                    out_unf = (out_unf.matmul(U.t()) + self.bias).transpose(1, 2)\n    \n                return out_unf.view(batch_size, self.out_channels, out_h, out_w)\n            \n            elif self.step == 'S':\n\n                if not self.fixed:\n\n                    U_hat,S_hat,V_hat = self.U_hat[:,:2*self.dynamic_rank],self.S_hat[:2*self.dynamic_rank,:2*self.dynamic_rank],self.V_hat[:,:2*self.dynamic_rank]\n\n                else:\n\n                    U_hat,S_hat,V_hat = self.U,self.S_hat,self.V\n    \n                inp_unf = F.unfold(input,self.kernel_size,padding = self.padding,stride = self.stride).to(self.device)\n\n                if self.bias is None:\n                    out_unf = (inp_unf.transpose(1, 2).matmul(V_hat) )\n                    out_unf = (out_unf.matmul(S_hat.t()))\n                    out_unf = (out_unf.matmul(U_hat.t()) + self.bias).transpose(1, 2)\n                else:\n                    out_h = int(np.floor(((input.shape[2]+2*self.padding[0]-self.dilation[0]*(self.kernel_size[0]-1)-1)/self.stride[0])+1))\n                    out_w = int(np.floor(((input.shape[3]+2*self.padding[1]-self.dilation[1]*(self.kernel_size[1]-1)-1)/self.stride[1])+1))\n\n                    out_unf = (inp_unf.transpose(1, 2).matmul(V_hat) )\n                    out_unf = (out_unf.matmul(S_hat.t()))\n                    out_unf = (out_unf.matmul(U_hat.t()) + self.bias).transpose(1, 2)\n    \n                return out_unf.view(batch_size, self.out_channels, out_h, out_w)\n\n            else:\n\n                raise ValueError(f'incorrect step value {self.step}')\n\n\n# redefinition of the linear layer, adding decomposition attributes\n# to the weight object\n\nimport math       \nimport torch\nfrom torch import Tensor\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\n\nclass Linear(torch.nn.Module):\n    \n\n    __constants__ = ['in_features', 'out_features']\n    in_features: int\n    out_features: int\n    weight: Tensor\n\n    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n                 device=None, dtype=None,rank = None,fixed = False,load_weights = None,step = 'K',full_rank_construct = False) -> None:\n\n        \"\"\"  \n        initializer for the low rank linear layer, extention of the classical Pytorch's Linear\n        INPUTS:\n        in_features : number of inputs features (Pytorch standard)\n        out_features : number of output features (Pytorch standard)\n        bias : flag for the presence of bias (Pytorch standard)\n        device : device in where to put parameters\n        dtype : type of the tensors (Pytorch standard)\n        rank : rank variable, None if the layer has to be treated as a classical Pytorch Linear layer (with weight and bias). If\n                it is an int then it's either the starting rank for adaptive or the fixed rank for the layer.\n        fixed : flag variable, True if the rank has to be fixed (KLS training on this layer)\n        load_weights : variables to load (Pytorch standard, to finish)\n        step : flag variable ('K','L' or 'S') for which forward phase to use\n        \"\"\"\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super(Linear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = torch.nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n        self.rank = rank\n        self.device = device\n        self.load_weights = load_weights\n        self.fixed = fixed\n        self.lr = True if self.rank!=None else False\n        self.full_rank_construct = full_rank_construct\n        self.rmax = int(min([self.in_features, self.out_features]) / 2)\n        if not self.fixed:\n            self.rank = None if rank == None else min([rank,self.rmax])\n        else:\n            self.rank = min([rank,self.in_features,self.out_features])\n        self.dynamic_rank = self.rank\n        self.step = step\n\n        if bias:\n                self.bias = torch.nn.Parameter(torch.empty(out_features, **factory_kwargs))\n        else:\n                self.register_parameter('bias', None)\n\n        self.reset_parameters()\n\n            \n        if self.lr and not full_rank_construct:\n\n            if not self.fixed:   # initialization for dlrt adaptive\n                _,s_ordered,_ = torch.linalg.svd(torch.diag(torch.abs(torch.randn(2*self.rmax))))\n                U = torch.randn(self.out_features,self.rmax)\n                V = torch.randn(self.in_features,self.rmax)\n                U,_,_ = torch.linalg.svd(U)\n                V,_,_ = torch.linalg.svd(V)\n                self.U = torch.nn.Parameter(U.to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(s_ordered).to(device))                                          \n                self.V = torch.nn.Parameter(V.to(device),requires_grad=False)\n                self.U_hat = torch.nn.Parameter( torch.randn(self.out_features,2*self.rmax).to(device) ,requires_grad = False)\n                self.V_hat = torch.nn.Parameter(torch.randn(self.in_features,2*self.rmax).to(device) ,requires_grad = False)\n                self.K = torch.nn.Parameter(torch.randn(self.out_features,self.rmax).to(device))\n                self.L = torch.nn.Parameter(torch.randn(self.in_features,self.rmax).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.weight = None\n            else:     # initialization for dlrt fixed rank\n                _,s_ordered,_ = torch.linalg.svd(torch.diag(torch.abs(torch.randn(self.rank))))\n                U = torch.randn(self.out_features,self.rank)\n                V = torch.randn(self.in_features,self.rank)\n                U,_,_ = torch.linalg.svd(U)\n                V,_,_ = torch.linalg.svd(V)\n                self.U = torch.nn.Parameter(U[:,:self.rank].to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(s_ordered).to(device))                                          \n                self.V = torch.nn.Parameter(V[:,:self.rank].to(device),requires_grad=False)\n                self.K = torch.nn.Parameter(torch.randn(self.out_features,self.rank).to(device))\n                self.L = torch.nn.Parameter(torch.randn(self.in_features,self.rank).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(self.rank,self.rank).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(self.rank,self.rank).to(device) ,requires_grad = False)\n                self.weight = None\n\n    def switch_lowrank(self):\n        \n        w,b = self.weight,self.bias\n        device = self.device\n        if not self.fixed:\n            self.rank = None if self.rank == None else min([self.rank,self.rmax])\n        else:\n            self.rank = min([self.rank,self.out_features,self.in_features])\n\n        self.bias = b\n\n        if self.lr:\n\n            if not self.fixed:\n\n                n,m = self.out_features,self.in_features\n\n                U_load,S_load,V_load = torch.linalg.svd(w.view(n,m))\n                V_load = V_load.T\n                r = len(S_load)\n                _,s_ordered,_ = torch.linalg.svd(torch.diag(torch.abs(torch.randn(2*self.rmax-r))))\n                s_ordered = torch.tensor(torch.cat([S_load,s_ordered.to(device)])).to(device)\n                self.U = torch.nn.Parameter(U_load.to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(s_ordered).to(device))                                       \n                self.V = torch.nn.Parameter(V_load.to(device),requires_grad=False)\n                self.U_hat = torch.nn.Parameter( torch.randn(n,2*self.rmax).to(device) ,requires_grad = False)\n                self.V_hat = torch.nn.Parameter(torch.randn(m,2*self.rmax).to(device) ,requires_grad = False)\n                self.K = torch.nn.Parameter(torch.randn(n,self.rmax).to(device))\n                self.L = torch.nn.Parameter(torch.randn(m,self.rmax).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.weight = None\n                self.id = id(self.K)\n            else:\n\n                n,m = self.out_features,self.in_features\n\n                U_load,S_load,V_load = torch.linalg.svd(w.view(n,m))\n                V_load = V_load.T\n                r = self.rank\n                self.U = torch.nn.Parameter(U_load[:,:r].to(device) ,requires_grad=False)             \n                self.S_hat = torch.nn.Parameter(torch.diag(S_load[:r]).to(device))                                       \n                self.V = torch.nn.Parameter(V_load[:,:r].to(device),requires_grad=False)\n                self.K = torch.nn.Parameter(torch.randn(n,r).to(device))\n                self.L = torch.nn.Parameter(torch.randn(m,r).to(device))\n                self.N_hat = torch.nn.Parameter(torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.M_hat = torch.nn.Parameter( torch.randn(2*self.rmax,self.rmax).to(device) ,requires_grad = False)\n                self.weight = None\n                self.id = id(self.K)\n        \n\n\n    def reset_parameters(self) -> None:\n        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n        # https://github.com/pytorch/pytorch/issues/57109\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input: Tensor) -> Tensor:\n        \"\"\"  \n        forward phase for the layer (the backward is automatically created by Pytorch since only standard functions are used). To use dlrt\n        training the three kind of forward phases has to be included\n        INPUTS:\n        input: input tensor\n        \"\"\"\n        if not self.lr:\n\n            x = F.linear(input,self.weight,self.bias)\n\n        else : \n\n            if self.step == 'K':\n                if not self.fixed:\n                    K,V = self.K[:,:self.dynamic_rank],self.V[:,:self.dynamic_rank]\n                else:\n                    K,V = self.K,self.V\n                x = input.mm(V)\n                x = x.mm(K.T)\n                \n                if self.bias is not None:\n\n                    x = x+self.bias\n\n            elif self.step == 'L':\n                if not self.fixed:\n                    L,U = self.L[:,:self.dynamic_rank],self.U[:,:self.dynamic_rank]\n                else:\n                    L,U = self.L,self.U\n                x = input.mm(L)\n                x = x.mm(U.T)\n                if self.bias is not None:\n                    x = x+self.bias\n            \n            elif self.step == 'S':\n\n                if not self.fixed:\n\n                    S_hat,U_hat,V_hat = self.S_hat[:2*self.dynamic_rank,:2*self.dynamic_rank],self.U_hat[:,:2*self.dynamic_rank],self.V_hat[:,:2*self.dynamic_rank]\n\n                else:\n\n                    S_hat,U_hat,V_hat = self.S_hat,self.U,self.V\n\n                x = input.mm(V_hat)\n                x = x.mm(S_hat.T)\n                x = x.mm(U_hat.T)\n                if self.bias is not None:\n                    x = x+self.bias\n                    \n            else:\n\n                raise ValueError(f' incorrect step type {self.step}')\n            \n        return x \n\n\n# import custom layers\nimport sys,os\nsys.path.insert(1, os.path.join(sys.path[0], '..'))\nfrom optimizer_KLS.my_conv import Conv2d_lr\nfrom optimizer_KLS.Linear_layer_lr_new import Linear\nimport torch\n\nclass Lenet5(torch.nn.Module):\n    def __init__(self,device = 'cpu'):\n        \"\"\"  \n        initializer for Lenet5.\n        NEEDED ATTRIBUTES TO USE dlr_opt:\n        self.layer\n        NEEDED METHODS TO USE dlr_opt:\n        self.forward : standard forward of the NN\n        self.update_step : updates the step of all the low rank layers inside the neural net\n        self.populate_gradients : method used to populate the gradients inside the neural network in one unique function\n        \"\"\"\n        super(Lenet5, self).__init__()\n        self.device = device\n        self.layer = torch.nn.Sequential(\n            Conv2d_lr(in_channels = 1, out_channels = 20, kernel_size = 5, stride=1,rank = 20,device = self.device),  \n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size = 2, stride=2),\n            Conv2d_lr(in_channels = 20, out_channels = 50, kernel_size = 5, stride=1,rank = 50,device = self.device),  \n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size = 2, stride=2),\n            torch.nn.Flatten(),\n            Linear(800,out_features = 500,rank = 500,device = self.device),  \n            torch.nn.ReLU(),\n            Linear(500,out_features = 10,device = self.device)\n        )\n\n    def forward(self, x):\n        for layer in self.layer:\n            x = layer(x)\n        return x\n\n    def update_step(self,new_step = 'K'):\n        for l in self.layer:\n            if hasattr(l,'lr') and l.lr:\n                l.step = new_step\n\n    def populate_gradients(self,x,y,criterion,step = 'all'):\n\n        if step == 'all':\n        \n            self.update_step(new_step = 'K')\n            output = self.forward(x)\n            loss = criterion(output,y)\n            loss.backward() \n            self.update_step(new_step = 'L')\n            output = self.forward(x)\n            loss = criterion(output,y)\n            loss.backward()\n            return loss,output.detach()\n\n        else:\n            \n            self.update_step(new_step = step)\n            loss = criterion(self.forward(x),y)\n            return loss\n\n\nfrom tqdm import tqdm\nimport torch\nfrom torch import float16\nimport pandas as pd\n\ndef full_count_params(NN,count_bias = False,with_grads = False):\n\n    \"\"\" \n    Function that counts the total number of parameters needed for a full rank version of NN\n    INPUTS:\n    NN: neural network\n    count_bias : flag variable, True if the biases are to be included in the total or not\n\n    OUTPUTS:\n    total_params : total number of parameters in the full rank version of NN\n    \"\"\"\n\n    total_params = 0\n\n    for l in NN.layer:\n\n        n = str(l)\n\n        if 'Linear' in n:\n\n            total_params += 2*l.in_features*l.out_features if with_grads else l.in_features*l.out_features\n\n            if count_bias and l.bias is not None:\n\n                total_params += 2*len(l.bias) if with_grads else len(l.bias)\n\n        if 'Conv' in n:\n\n            total_params += 2*l.kernel_size_number*l.in_channels*l.out_channels if with_grads else l.kernel_size_number*l.in_channels*l.out_channels\n\n            if count_bias and l.bias is not None:\n\n                total_params += 2*len(l.bias) if with_grads else len(l.bias)\n\n    return total_params\n\n\n\n\ndef count_params(T,with_grads = False):\n\n    \"\"\" \n    function to count number of parameters inside a tensor\n    INPUT:1\n    T : torch.tensor or None\n    output:\n    number of parameters contained in T\n    \"\"\"\n\n    if len(T.shape)>1:\n\n        if with_grads:\n\n            return 2*int(torch.prod(torch.tensor(T.shape)))\n\n        else:\n\n            return int(torch.prod(torch.tensor(T.shape)))\n\n    elif T == None:\n\n        return 0\n\n    else:\n\n        if with_grads:\n\n            return 2*T.shape[0]\n        \n        else:\n\n            return T.shape[0]\n\n\ndef count_params_train(NN,count_bias = False,with_grads = False):\n\n    \"\"\" \n    function to count the parameters in the train phase\n    \n    INPUTS:\n    NN : neural network\n    count_bias : flag variable, True if the biases are to be included in the total or not\n    \"\"\"\n\n    total_params = 0\n\n    for l in NN.layer:\n\n        if hasattr(l,'lr') and l.lr:\n\n            if not l.fixed:\n\n                total_params += count_params(l.K[:,:l.dynamic_rank],with_grads)\n                total_params += count_params(l.L[:,:l.dynamic_rank],with_grads)\n                total_params += count_params(l.U[:,:l.dynamic_rank])\n                total_params += count_params(l.V[:,:l.dynamic_rank])\n                total_params += count_params(l.U_hat[:,:2*l.dynamic_rank])\n                total_params += count_params(l.V_hat[:,:2*l.dynamic_rank])\n                total_params += count_params(l.S_hat[:2*l.dynamic_rank,:2*l.dynamic_rank],with_grads)\n                total_params += count_params(l.M_hat[:2*l.dynamic_rank,:l.dynamic_rank])\n                total_params += count_params(l.N_hat[:2*l.dynamic_rank,:l.dynamic_rank])\n                if count_bias:\n                    total_params +=count_params(l.bias)\n\n            else:\n\n                total_params += count_params(l.K[:,:l.dynamic_rank],with_grads)\n                total_params += count_params(l.L[:,:l.dynamic_rank],with_grads)\n                total_params += count_params(l.U[:,:l.dynamic_rank])\n                total_params += count_params(l.V[:,:l.dynamic_rank])\n                total_params += count_params(l.S_hat[:2*l.dynamic_rank,:2*l.dynamic_rank],with_grads)\n                total_params += count_params(l.M_hat[:2*l.dynamic_rank,:l.dynamic_rank])\n                total_params += count_params(l.N_hat[:2*l.dynamic_rank,:l.dynamic_rank])\n                if count_bias:\n                    total_params +=count_params(l.bias)\n\n        else:\n\n            for n,p in l.named_parameters():\n\n                if 'bias' not in n:\n\n                    total_params += count_params(p,with_grads)   # add with grads\n\n                elif 'bias' in n and count_bias:\n\n                    total_params += count_params(p)\n\n    return total_params\n\n\ndef count_params_test(NN,count_bias = False):\n\n    \"\"\" \n    function to count the parameters in the test phase\n    \n    INPUTS:\n    NN : neural network\n    count_bias : flag variable, True if the biases are to be included in the total or not\n    \"\"\"\n\n    total_params = 0\n\n    for l in NN.layer:\n\n        if hasattr(l,'lr') and l.lr:\n\n            total_params += count_params(l.K[:,:l.dynamic_rank])\n            total_params += count_params(l.L[:,:l.dynamic_rank])\n            if count_bias:\n                total_params +=count_params(l.bias)\n\n        else:\n\n            for n,p in l.named_parameters():\n\n                if 'bias' not in n:\n\n                    total_params += count_params(p)\n\n                elif 'bias' in n and count_bias:\n\n                    total_params +=count_params(p)\n\n    return total_params\n\n\n\ndef accuracy(outputs,labels):\n\n    return torch.mean(torch.tensor(torch.argmax(outputs.detach(),axis = 1) == labels,dtype = float16))\n\n            \n\n\ndef train_dlrt(NN,optimizer,train_loader,validation_loader,test_loader,criterion,metric,epochs,\n                metric_name = 'accuracy',device = 'cpu',count_bias = False,path = None,fine_tune = False,scheduler = None):\n\n    \"\"\" \n    INPUTS:\n    NN : neural network with custom layers and methods to optimize with dlra\n    train/validation/test_loader : loader for datasets\n    criterion : loss function\n    metric : metric function\n    epochs : number of epochs to train\n    metric_name : name of the used metric\n    count_bias : flag variable if to count biases in params_count or not\n    path : path string for where to save the results\n\n    OUTPUTS:\n    running_data : Pandas dataframe with the results of the run\n    \"\"\"\n\n    running_data = pd.DataFrame(data = None,columns = ['epoch','theta','learning_rate','train_loss','train_'+metric_name+'(%)','validation_loss',\\\n                                                        'validation_'+metric_name+'(%)','test_'+metric_name+'(%)',\\\n                                                     'ranks','# effective parameters','cr_test (%)','# effective parameters train','cr_train (%)',\\\n                                                     '# effective parameters train with grads','cr_train_grads (%)'])\n\n    total_params_full = full_count_params(NN,count_bias)\n    total_params_full_grads = full_count_params(NN,count_bias,True)\n    #scheduler_rate = optimizer.scheduler_change_rate\n\n    file_name = path\n\n    if not fine_tune:\n\n        if path is not None:\n            file_name += '.csv'#'\\_running_data_'+str(optimizer.theta)+'.csv'\n\n        for epoch in tqdm(range(epochs)):\n\n            print(f'epoch {epoch}---------------------------------------------')\n            loss_hist = 0\n            acc_hist = 0\n            k = len(train_loader)\n\n            for i,data in enumerate(train_loader):  # train\n                NN.zero_grad()\n                optimizer.zero_grad()\n                inputs,labels = data\n                inputs,labels = inputs.to(device),labels.to(device)\n                def closure():\n                    loss = NN.populate_gradients(inputs,labels,criterion,step = 'S')\n                    return loss\n                optimizer.preprocess_step()\n                loss,outputs = NN.populate_gradients(inputs,labels,criterion)\n                loss_hist+=float(loss.item())/k\n                outputs = outputs.to(device)#NN(inputs).detach().to(device)\n                acc_hist += float(metric(outputs,labels))/k\n                optimizer.step(closure = closure)\n\n            optimizer.preprocess_step()   # last update after training\n            NN.update_step()\n\n            with torch.no_grad():\n                k = len(validation_loader)\n                loss_hist_val = 0.0\n                acc_hist_val = 0.0\n                for i,data in enumerate(validation_loader):   # validation \n                    inputs,labels = data\n                    inputs,labels = inputs.to(device),labels.to(device)\n                    outputs = NN(inputs).detach().to(device)\n                    loss_val = criterion(outputs,labels)\n                    loss_hist_val+=float(loss_val.item())/k\n                    acc_hist_val += float(metric(outputs,labels))/k\n\n\n                k = len(test_loader)\n                loss_hist_test = 0.0\n                acc_hist_test= 0.0\n                for i,data in enumerate(test_loader):   # validation \n                    inputs,labels = data\n                    inputs,labels = inputs.to(device),labels.to(device)\n                    outputs = NN(inputs).detach().to(device)\n                    loss_test = criterion(outputs,labels)\n                    loss_hist_test += float(loss_test.item())/k\n                    acc_hist_test += float(metric(outputs,labels))/k\n\n            print(f'epoch[{epoch}]: loss: {loss_hist:9.4f} | {metric_name}: {acc_hist:9.4f} | val loss: {loss_hist_val:9.4f} | val {metric_name}:{acc_hist_val:9.4f}')\n            print('='*100)\n            ranks = []\n            for i,l in enumerate(NN.layer):\n                if hasattr(l,'lr') and l.lr:\n                    print(f'rank layer {i} {l.dynamic_rank}')\n                    ranks.append(l.dynamic_rank)\n            print('\\n')\n\n            params_test = count_params_test(NN,count_bias)\n            cr_test = round(params_test/total_params_full,3)\n            params_train = count_params_train(NN,count_bias)\n            cr_train = round(params_train/total_params_full,3)\n            params_train_grads = count_params_train(NN,count_bias,True)\n            cr_train_grads = round(params_train_grads/total_params_full_grads,3)\n            epoch_data = [epoch,optimizer.theta,round(optimizer.tau,5),round(loss_hist,3),round(acc_hist*100,4),round(loss_hist_val,3),\\\n                        round(acc_hist_val*100,4),round(acc_hist_test*100,4),ranks,params_test,round(100*(1-cr_test),4),\\\n                            params_train,round(100*(1-cr_train),4),params_train_grads,round(100*(1-cr_train_grads),4)]\n\n            running_data.loc[epoch] = epoch_data\n\n            if file_name is not None and (epoch%10 == 0 or epoch == epochs-1):\n\n                running_data.to_csv(file_name)\n\n            if scheduler is not None:\n\n                scheduler.step(loss_hist)\n\n            # if epoch%scheduler_rate == 0:\n\n            #     optimizer.scheduler_step()\n\n            if epoch == 0:\n\n                best_val_loss = loss_hist_val\n\n            if loss_hist_val<best_val_loss:\n\n                torch.save(NN.state_dict(),path+'\\_best_weights_'+str(optimizer.theta)+'.pt')\n\n        return running_data\n\n    else:\n\n        if path is not None:\n            file_name += '_finetune.csv'#'\\_running_data_'+str(optimizer.theta)+'.csv'\n\n        for epoch in tqdm(range(epochs)):\n\n            print(f'epoch {epoch}---------------------------------------------')\n            loss_hist = 0\n            acc_hist = 0\n            k = len(train_loader)\n\n            for i,data in enumerate(train_loader):  # train\n                NN.zero_grad()\n                optimizer.zero_grad()\n                inputs,labels = data\n                inputs,labels = inputs.to(device),labels.to(device)\n                outputs = NN(inputs).to(device)\n                loss = criterion(outputs,labels)\n                loss.backward()\n                loss_hist+=float(loss.item())/k\n                acc_hist += float(metric(outputs.detach(),labels))/k\n                optimizer.S_finetune_step()\n\n\n            with torch.no_grad():\n                k = len(validation_loader)\n                loss_hist_val = 0.0\n                acc_hist_val = 0.0\n                for i,data in enumerate(validation_loader):   # validation \n                    inputs,labels = data\n                    inputs,labels = inputs.to(device),labels.to(device)\n                    outputs = NN(inputs).detach().to(device)\n                    loss_val = criterion(outputs,labels)\n                    loss_hist_val+=float(loss_val.item())/k\n                    acc_hist_val += float(metric(outputs,labels))/k\n\n                k = len(test_loader)\n                loss_hist_test = 0.0\n                acc_hist_test= 0.0\n                for i,data in enumerate(test_loader):   # validation \n                    inputs,labels = data\n                    inputs,labels = inputs.to(device),labels.to(device)\n                    outputs = NN(inputs).detach().to(device)\n                    loss_test = criterion(outputs,labels)\n                    loss_hist_test += float(loss_test.item())/k\n                    acc_hist_test += float(metric(outputs,labels))/k\n\n            print(f'epoch[{epoch}]: loss: {loss_hist:9.4f} | {metric_name}: {acc_hist:9.4f} | val loss: {loss_hist_val:9.4f} | val {metric_name}:{acc_hist_val:9.4f}')\n            print('='*100)\n            ranks = []\n            for i,l in enumerate(NN.layer):\n                if hasattr(l,'lr') and l.lr:\n                    print(f'rank layer {i} {l.dynamic_rank}')\n                    ranks.append(l.dynamic_rank)\n            print('\\n')\n            params_test = count_params_test(NN,count_bias)\n            cr_test = round(params_test/total_params_full,3)\n            params_train = count_params_train(NN,count_bias)\n            cr_train = round(params_train/total_params_full,3)\n            params_train_grads = count_params_train(NN,count_bias,True)\n            cr_train_grads = round(params_train_grads/total_params_full_grads,3)\n            epoch_data = [epoch,optimizer.theta,round(optimizer.tau,5),round(loss_hist,3),round(acc_hist*100,4),round(loss_hist_val,3),\\\n                        round(acc_hist_val*100,4),round(acc_hist_test*100,4),ranks,params_test,round(100*(1-cr_test),4),\\\n                                params_train,round(100*(1-cr_train),4),params_train_grads,round(100*(1-cr_train_grads),4)]\n\n            running_data.loc[epoch+epochs] = epoch_data\n\n            if file_name is not None and (epoch%10 == 0 or epoch == epochs-1):\n\n                running_data.to_csv(file_name)\n\n            if scheduler is not None:\n\n                scheduler.step(loss_hist)\n\n            # if epoch%scheduler_rate == 0:\n\n            #     optimizer.scheduler_step()\n\n            if epoch == 0:\n\n                best_val_loss = loss_hist_val\n\n            if loss_hist_val<best_val_loss:\n\n                torch.save(NN.state_dict(),path+'\\_best_weights_finetune_'+str(optimizer.theta)+'.pt')\n\n        return running_data",
    "Experiment Result": "Experimental settings for Lenet5 on MNIST from `Lenet_experiment/run_lenet_mnist.py`:\n- Model: Lenet5, constructed with custom low-rank convolutional (`Conv2d_lr`) and linear (`Linear`) layers (e.g., first Conv2d_lr with rank=20, second with rank=50, first Linear with rank=500).\n- Device: CUDA if available, otherwise CPU.\n- Dataset: MNIST (loaded via `tf.keras.datasets.mnist.load_data`, split using `sklearn.model_selection.train_test_split`).\n    - Training data size: 50000 samples\n    - Validation data size: 10000 samples\n    - Test data size: 10000 samples\n    - Input image dimensions: (1, 28, 28) for grayscale.\n    - Data preprocessing: Normalized to float tensor values between 0 and 1.\n- Training parameters:\n    - Epochs: 20 (configurable via `--epochs` argument, default 100 in parser, but set to 20 in script)\n    - Batch size: 128 (configurable via `--batch_size` argument)\n    - Cross-validation runs: 5 (configurable via `--cv_runs` argument)\n    - Learning Rate (`lr` / `tau`): 0.05 (configurable via `--lr` argument)\n    - Rank Adaptation Threshold (`theta`): [0.4, 0.45] (configurable via `--theta` argument)\n- Optimizer: `dlr_opt` (Dynamical Low-Rank Optimizer) configured to use `torch.optim.SGD` as its internal KLS integrator. `dlr_opt` handles the K, L, and S steps for factor updates and rank adaptivity.\n- Loss Function: `torch.nn.CrossEntropyLoss()`\n- Metric: Accuracy (calculated as `torch.mean(torch.tensor(torch.argmax(outputs.detach(),axis = 1) == labels,dtype = float16))`).\n- Results saving: Training metrics and model weights (best validation loss) are saved to `./results_Lenet5/`.\n"
}{
    "Title": "Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation",
    "Main Contributions": "This research demonstrates that by leveraging inherent low-dimensional data structures and compressible dynamics within model parameters, the benefits of overparameterization can be achieved without computational burdens. Theoretically, it proves that learning dynamics for each weight matrix in deep overparameterized low-rank matrix recovery are confined to an invariant low-dimensional subspace, enabling the construction of compact, highly compressed factorizations. Practically, the method significantly improves training efficiency for deep low-rank matrix completion and introduces \"Deep LoRA\" for fine-tuning language models, which reduces overfitting, simplifies hyperparameter setup, and maintains comparable efficiency, particularly with limited data.",
    "Methodology": "The core methodology involves exploiting compressible learning dynamics and low-dimensional data structures. For deep matrix factorization, it identifies and theoretically proves the existence of invariant low-dimensional subspaces (rank at most 2r) in each weight matrix's learning dynamics under gradient descent (GD) with scaled orthogonal initialization. Based on this, a compression technique is developed to construct and train a much smaller, yet equivalent, compressed factorization. For deep matrix completion, this compression is generalized by introducing a discrepant learning rate (γ) to slowly update the compressed subspace factors (UL,1, V1,1) during training to mitigate misalignment caused by observation masks. For language model fine-tuning, \"Deep LoRA\" proposes replacing vanilla LoRA's two-layer low-rank update with a deep (e.g., three-layer) full-width overparameterized update, and then applying the developed compression method to these updates for each adapted layer. This allows Deep LoRA to adaptively select appropriate ranks and leverage depth for regularization.",
    "Experimental Setup": "The methods are validated across several setups: 1. Deep Matrix Factorization: Theoretical SVD dynamics are visualized on synthetic data (d=30, r*=3). Compression efficiency is demonstrated on L=3 deep matrix factorizations (d=1000, r=r*=5, ϵl=10^-3) by comparing principal components of GD trajectories and training loss vs. wall-time. 2. Deep Matrix Completion: Compression is applied to L=3 deep matrix completion (d=1000, r=r*=5, ϵl=10^-3, 20% observed entries), comparing trajectories and recovery error vs. wall-time for original, compressed with discrepant updates (γ=0.01), and without. 3. Language Model Fine-tuning (Deep LoRA): A pretrained BERT base model is fine-tuned on all attention and feedforward weights (72 layers). Adam optimizer is used, with learning rates (η) and LoRA scale (α) tuned. Benchmarks include the GLUE natural language understanding tasks (CoLA, MNLI, MRPC, QNLI, QQP, RTE, SST-2, STS-B) with limited data (1024 samples) and few-shot settings (n ∈ {16, 64, 256} samples for STS-B). Natural language generation is evaluated on the E2E dataset with a T5 base model using 16 samples. Performance is measured by validation set metrics (e.g., accuracy, Pearson correlation, BLEU, ROUGE, METEOR) and numerical rank analysis, with experiments run on a single NVIDIA Tesla V100 GPU.",
    "Limitations": "The theoretical results on network compression specifically exploit the gradient structure of deep linear matrix factorizations. While an empirical observation for non-linear settings is provided, a rigorous theoretical extension to fully non-linear models is a recognized challenge. For deep matrix completion, directly applying the compression method can lead to divergence, necessitating the introduction of a slowly updated factor and a discrepant learning rate (γ) for the factors (UL,1, V1,1), which adds an additional hyperparameter that needs careful tuning. Deep LoRA, while efficient, still requires a fractionally larger memory cost for storage compared to vanilla LoRA (e.g., 12.648GB vs. 12.526GB on the tested hardware).",
    "Future Research Directions": "Future work includes extending the compressibility analysis to non-linear settings (e.g., with ReLU activations) by leveraging shared gradient structures and approximate spectral properties, potentially drawing parallels with the masking effect in deep matrix completion. For Deep LoRA, further evaluations in other modalities such as diffusion models, where limited data fine-tuning is prevalent, are suggested. Investigating the use of SGD for the outer factors to further reduce memory costs, given the observed alignment of adapted subspaces at initialization, is another direction. Finally, exploring second-order methods to accelerate fine-tuning along the low-rank subspace is proposed. The research also highlights implications for representation learning, such as connecting low-rank bias to emergent phenomena like deep neural collapse and progressive neural collapse.",
    "Experiment Code": "File Path: dlt/models.py\nContent:\nclass MatrixFactorization(nn.Module):\n    shape: Tuple[int, int]\n    init_scale: float\n    depth: int\n    rank: Optional[int]\n\n    def setup(self):\n        assert self.depth >= 2, \"Depth must be at least 2\"\n        set_width = self.rank if self.rank else max(self.shape)\n        misc_utils.check_rank(set_width, self.shape)\n\n        if self.depth == 2:\n            init_fn = nn.initializers.normal(stddev=1)\n            last_init_fn = nn.zeros_init()\n        else:\n            init_fn = nn.initializers.orthogonal(scale=self.init_scale)\n            last_init_fn = init_fn\n\n        layers = []\n        layers.append(\n            self.param(\n                \"W1\",\n                init_fn,\n                (set_width, self.shape[1]),\n            )\n        )\n        for i in range(2, self.depth):\n            layers.append(\n                self.param(\n                    f\"W{i}\",\n                    init_fn,\n                    (set_width, set_width),\n                )\n            )\n        layers.append(\n            self.param(\n                f\"W{self.depth}\",\n                last_init_fn,\n                (self.shape[0], set_width),\n            )\n        )\n        self.layers = layers\n\n    def __call__(self):\n        return jnp.linalg.multi_dot(self.layers[::-1])\n\n\nclass CompressedMatrixFactorization(nn.Module):\n    shape: Tuple[int, int]\n    init_scale: float\n    depth: int\n    rank: int\n\n    def setup(self):\n        self.left_factor = self.param(\n            \"left\", nn.initializers.orthogonal(), (self.shape[0], self.rank)\n        )\n        self.right_factor = self.param(\n            \"right\", nn.initializers.orthogonal(), (self.shape[1], self.rank)\n        )\n        self.mf = MatrixFactorization(\n            (self.rank, self.rank), self.init_scale, self.depth, None\n        )\n\n    def __call__(self):\n        return jnp.linalg.multi_dot([self.left_factor, self.mf(), self.right_factor.T])\n\n\nclass Lora(nn.Module):\n    flat_params_shape_dict: dict\n    init_scale: float\n    depth: int\n    rank: Optional[int]\n    compressed: bool\n\n    def setup(self):\n        mfs = {}\n        for flat_param_path, shape in self.flat_params_shape_dict.items():\n            if self.compressed:\n                assert (\n                    self.rank is not None\n                ), \"Rank must be specified for compressed LoRA\"\n                mf = CompressedMatrixFactorization(\n                    shape=shape,\n                    init_scale=self.init_scale,\n                    depth=self.depth,\n                    rank=self.rank,\n                    name=flat_param_path,\n                )\n                assert self.depth >= 3, \"Depth must be at least 3 for compressed LoRA\"\n            else:\n                mf = MatrixFactorization(\n                    shape=shape,\n                    init_scale=self.init_scale,\n                    depth=self.depth,\n                    rank=self.rank,\n                    name=flat_param_path,\n                )\n            mfs[flat_param_path] = mf\n        self.mfs = mfs\n\n    def __call__(self):\n        return {k: v() for k, v in self.mfs.items()}\n\n    def adapt(self, model_params: ArrayTree) -> ArrayTree:\n        updates = self()\n\n        def f(k, v):\n            flat_k = \"/\".join(k)\n            if flat_k in updates.keys():\n                return v + updates[flat_k]\n            else:\n                return v\n\n        return flax.traverse_util.path_aware_map(\n            f,\n            model_params,  # type: ignore\n        )\n\nFile Path: dlt/train.py\nContent:\ndef create_compressed_lora_train_state(\n    uncompressed_lora_state: LoraState,\n    uncompressed_lora_model: Lora,\n    model_state: ModelState,\n    batch: dict[str, np.ndarray],\n    task_config: TaskConfig,\n):\n    assert task_config.lora_compress, \"Lora compression is not enabled.\"\n    rank = task_config.lora_rank\n    assert rank is not None, \"Rank must be specified.\"\n    assert rank % 2 == 0, \"Rank must be even.\"\n    compressed_lora_model = models.Lora(\n        flat_params_shape_dict=model_utils.get_filtered_flat_params_shape_dict(\n            model_state.params, task_config.lora_adapt_type\n        ),\n        depth=task_config.lora_depth,\n        init_scale=task_config.lora_init_scale,\n        rank=rank,\n        compressed=True,\n    )\n\n    uncompressed_e2e = uncompressed_lora_model.apply(\n        {\"params\": uncompressed_lora_state.params}\n    )\n\n    # Get gradient of uncompressed factors\n    loss_fn = create_lora_loss_fn(\n        model_state,\n        uncompressed_lora_state,\n        task_config.finetune_task_name == \"stsb\",\n        False,\n    )\n\n    uncompressed_grads = jax.grad(loss_fn)(uncompressed_lora_state.params, batch)\n\n    # Move to numpy (do compression on CPU to save GPU memory)\n    uncompressed_lora_params_numpy = jax.tree_map(\n        np.array, uncompressed_lora_state.params\n    )\n    uncompressed_grads_numpy = jax.tree_map(np.array, uncompressed_grads)\n    uncompressed_e2e_numpy = jax.tree_map(np.array, uncompressed_e2e)\n\n    def svd(A):\n        U, s, VT = np.linalg.svd(A, full_matrices=True)\n        return U, s, VT.T\n\n    def get_left_right_factors(W1, W1_grad, e2e):\n\n        m, n = W1.shape\n        assert m == n, \"Need square matrix at this point\"\n\n        half_rank = rank // 2\n        Ugrad, _, Vgrad = svd(W1_grad)\n        Va = W1.T @ Ugrad[:, half_rank:] / task_config.lora_init_scale\n        Vb = Vgrad[:, half_rank:]\n        V0 = Va @ svd(np.concatenate([Va, -Vb], axis=1))[2][: Va.shape[1], n:]\n        V = svd(V0)[0][:, ::-1]\n        right = V[:, :rank]\n        left = e2e @ right / (task_config.lora_init_scale**task_config.lora_depth)\n\n        return left, right\n\n    compressed_lora_params_numpy = {}\n\n    pbar = tqdm(uncompressed_grads_numpy.items())\n    pbar.set_description(\"Compressing LoRA parameters\")\n\n    for k, g in pbar:\n        comp_mf_params = {}\n        m, n = uncompressed_lora_params_numpy[k][\"W1\"].shape\n        if m != n:\n            # WL.T will act like W1\n            right, left = get_left_right_factors(\n                uncompressed_lora_params_numpy[k][f\"W{task_config.lora_depth}\"].T,\n                g[f\"W{task_config.lora_depth}\"].T,\n                uncompressed_e2e_numpy[k].T,\n            )\n        else:\n            left, right = get_left_right_factors(\n                uncompressed_lora_params_numpy[k][\"W1\"],\n                g[\"W1\"],\n                uncompressed_e2e_numpy[k],\n            )\n        comp_mf_params[\"left\"] = left\n        comp_mf_params[\"right\"] = right\n        mf_params = {}\n        for w in g.keys():\n            mf_params[w] = task_config.lora_init_scale * jnp.eye(rank)\n        comp_mf_params[\"mf\"] = mf_params\n        compressed_lora_params_numpy[k] = comp_mf_params\n\n    compressed_lora_params = jax.tree_map(jnp.array, compressed_lora_params_numpy)\n\n    inner_tx = uncompressed_lora_state.tx\n    outer_tx = create_optimizer(\n        create_learning_rate_fn(\n            task_config.num_train_steps,\n            task_config.num_warmup_steps,\n            task_config.lora_gamma * task_config.learning_rate,\n            task_config.decay_ratio,\n        ),\n        task_config.weight_decay,\n    )\n    tx = optax.multi_transform(\n        {\"inner\": inner_tx, \"outer\": outer_tx},\n        flax.traverse_util.path_aware_map(\n            lambda p, _: \"outer\" if p[-1] == \"left\" or p[-1] == \"right\" else \"inner\",\n            compressed_lora_params,\n        ),\n    )\n\n    return LoraState.create(\n        apply_fn=partial(\n            compressed_lora_model.apply, method=compressed_lora_model.adapt\n        ),\n        params=compressed_lora_params,\n        tx=tx,\n        dropout_rng=uncompressed_lora_state.dropout_rng,\n    )",
    "Experiment Result": "File Path: dlt/configs.py\nContent:\n@dataclass_json\n@dataclass\nclass TaskConfig:\n    identifier: Optional[str] = None\n\n    # Data hparams\n    task_type: TaskType = TaskType.GLUE\n    finetune_task_name: Union[GlueTaskName, NLGTaskName] = GlueTaskName.STSB\n    max_seq_length: Union[int, Tuple[int, int]] = 128\n    num_train_samples: Optional[int] = None\n\n    # Model hparams\n    pretrain_model: ModelType = ModelType.BERT\n\n    # Lora hparams\n    lora_adapt_type: LoraAdaptType = LoraAdaptType.ONLY_QUERY_VALUE\n    lora_depth: int = 3\n    lora_init_scale: float = 1e-3\n    lora_rank: Optional[int] = None\n    lora_compress: bool = False\n    lora_gamma: float = 0\n\n    # Training hparams\n    num_train_steps: int = 200\n    train_batch_size: int = 1\n    eval_batch_size: int = 32\n    num_warmup_steps: int = 0\n    learning_rate: float = 1e-4\n    weight_decay: float = 0.0\n    decay_ratio: float = 0.1\n\n    # Logging hparams\n    log_eval_steps: int = 200\n    save_step_points: list = field(default_factory=list)\n    save_dir: str = \"checkpoints\"\n\nExperimental Settings Summary:\n- **Model and Task:** Experiments are conducted on BERT for GLUE tasks (e.g., STSB, MNLI) and T5 for NLG tasks (e.g., E2E_NLG).\n- **Deep LoRA Configuration (`lora_depth`):** Vanilla LoRA is typically configured with `lora_depth=2`, while Deep LoRA uses `lora_depth=3` (or higher in `MatrixFactorization` if `rank` is not `None`).\n- **LoRA Adaptation Type (`lora_adapt_type`):** Commonly `LoraAdaptType.ALL_DENSE` is used, adapting all dense layers. Other options include `ONLY_QUERY_VALUE` and `ATTENTION_MLP`.\n- **LoRA Rank (`lora_rank`):** The default `lora_rank` is often `8`, but experiments vary this up to `64` (e.g., `stsb_varying_rank.py`). For uncompressed Deep LoRA (where `lora_rank=None`), the effective rank can be adaptive.\n- **Scaled Orthogonal Initialization (`lora_init_scale`):** Generally set to `1e-3`.\n- **Compression (`lora_compress`, `lora_gamma`):** When compression is enabled (`lora_compress=True`), a `lora_rank` must be specified and must be an even number. A discrepant learning rate `lora_gamma` (e.g., `1e-2` or `1.0`) is applied to the compressed subspace factors (`left` and `right`) to update them slower than the inner matrix factorization. The `dlt/train.py:create_compressed_lora_train_state` function ensures `lora_depth >= 3` for compressed LoRA.\n- **Training Hyperparameters:**\n    - `num_train_steps`: Varies from `200` to `2000` depending on the task and dataset size (e.g., `1000` for GLUE 1024 samples, `400` for NLG 16 samples).\n    - `train_batch_size`: Typically `16`.\n    - `learning_rate`: Commonly `1e-4`.\n    - `weight_decay`: `0.0`.\n    - `decay_ratio`: Often `1.0` (no decay after warmup) or `0.1`.\n    - `num_warmup_steps`: `0` by default."
}{
    "Title": "Spectral Adapter: Fine-Tuning in Spectral Space",
    "Main Contributions": "The paper introduces Spectral Adapter, a novel Parameter-Efficient Fine-Tuning (PEFT) method that integrates spectral information of pretrained weight matrices into the fine-tuning process. It proposes two mechanisms: Spectral AdapterA (additive tuning) and Spectral AdapterR (orthogonal rotation) of the top singular vectors, both applied after Singular Value Decomposition (SVD) of pretrained weights. Theoretically, it's shown that Spectral AdapterA offers twice the rank capacity of LoRA for a given parameter budget and that tuning top singular vectors aligns with ideal neuron directions. Experimentally, the method demonstrates superior parameter efficiency, improved tuning performance in LLMs, and enhanced multi-adapter fusion in diffusion models compared to existing PEFT approaches.",
    "Methodology": "The core methodology involves applying Singular Value Decomposition (SVD) to pretrained model weight matrices (W = USV^T) and then fine-tuning only the top-r columns of the singular vector matrices (U and V). Two specific adaptation mechanisms are explored: Spectral AdapterA, which additively tunes the top-r columns with trainable matrices AU and AV initialized to zero; and Spectral AdapterR, which orthogonally rotates the top-r columns using trainable orthogonal matrices RU and RV, initialized as identity matrices. The orthogonality constraint for Spectral AdapterR is efficiently handled using Cayley parameterization. Unlike prior spectral tuning methods, this approach is applicable to generic layers, allows flexible parameter budgets by varying 'r', and minimizes storage by only requiring the top columns to be stored.",
    "Experimental Setup": "Experiments were conducted on various large models including Llama3 8B, DeBERTaV3-base (185M), Mistral 7B for Language Model Fine-Tuning, and Chilloutmix diffusion model for Diffusion Model Fusion and Expressiveness. Datasets and benchmarks included Orca Math dataset and GSM8K for Llama3 8B, GLUE benchmarks (MNLI, SST-2, MRPC, CoLA, QNLI, QQP, RTE, STS-B) for DeBERTaV3-base, and GSM8K for Mistral 7B. For diffusion models, custom concepts (animals, toys, vase, chair) and multi-character generation (computer scientists) were used. Comparisons were made against various PEFT baselines: LoRA, DoRA, OFT, AdaLoRA, SVDiff, LiDB, VeRA, Gradient Fusion, Orthogonal Adaptation, and FedAvg. All experiments utilized NVIDIA RTX A6000 GPUs. Hyperparameters generally followed official implementations and original reports, with specific learning rates, batch sizes, epochs, optimizers, and LoRA alpha values mentioned for different tasks and models. Validation involved training loss, accuracy (for LLMs), qualitative visual generation results, and quantitative alignment scores (CLIP embedding cosine similarity for images and texts) for diffusion models.",
    "Limitations": "A primary limitation lies in the current choice of exclusively tuning the top spectral space. While theoretically supported under simple settings, further comprehensive investigation into tuning different columns (e.g., bottom spectral space) of singular vector matrices is needed to fully understand the role of spectral information in fine-tuning. Additionally, the time consumption of the Singular Value Decomposition procedure increases with larger models, posing a challenge.",
    "Future Research Directions": "Future research could explore fine-tuning the spectral representation of specific components within large models, such as only the attention layer. There is also potential to dynamically combine spectral adaptation with other existing PEFT methods like AdaLoRA. Further in-depth investigation into tuning different columns of singular vector matrices beyond just the top ones is crucial. Lastly, developing faster Singular Value Decomposition methods would be beneficial to alleviate the computational overhead as models continue to grow in size.",
    "Experiment Code": "class SpectralLinearLayer_OFT(nn.Module):\n    def __init__(self, name, original_module, rank=4, alpha=1, top=True, idx=0, revised_r=-1):\n        rank = 8\n        super().__init__()\n        self.name = name\n        if original_module.__class__.__name__ == 'Conv2d':\n            self.conv = True\n            in_channels, out_channels = original_module.in_channels, original_module.out_channels\n        else:\n            self.conv = False\n            in_channels, out_channels = original_module.in_features, original_module.out_features\n        W = original_module.weight.data.view(out_channels, in_channels)\n        U, S, V = torch.svd(W)\n        self.U = torch.nn.Parameter(U, requires_grad=False)\n        self.S = torch.nn.Parameter(S, requires_grad=False)\n        self.V = torch.nn.Parameter(V, requires_grad=False)\n        self.spectral_A = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True)\n        self.spectral_B = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True)\n        self.spectral_C = torch.nn.Parameter(torch.ones(revised_r), requires_grad=True)\n        original_module.forward = self.forward\n        self.original_module = original_module\n        self.top = top\n        self.idx = idx\n        assert revised_r>0\n        self.rank = revised_r\n\n    def cayley(self, data: torch.Tensor) -> torch.Tensor:\n        r, _ = data.shape\n        skew = 0.5 * (data - data.T)\n        I = torch.eye(r, device=data.device)\n        Q = torch.mm(I - skew, torch.inverse(I + skew))\n        return Q\n\n    def forward(self, hidden_states):\n        if self.top:\n            pad_U = self.U.clone()\n            pad_U[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.U[:,self.idx*self.rank:(self.idx+1)*self.rank]@self.cayley(self.spectral_A)\n            pad_S = self.S.clone()\n            pad_S[self.idx*self.rank:(self.idx+1)*self.rank] = self.S[self.idx*self.rank:(self.idx+1)*self.rank]*self.spectral_C\n            pad_V = self.V.clone()\n            pad_V[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.V[:,self.idx*self.rank:(self.idx+1)*self.rank]@self.cayley(self.spectral_B)\n        else:\n            raise Exception('')\n        pad_W = pad_U@pad_S.diag()@pad_V.T\n        if self.conv :\n            raise Exception('')\n        else:\n            return F.linear(hidden_states, pad_W, bias=self.original_module.bias)\n\ndef merge_spectraloft_into_weight(original_state_dict, lora_state_dict, model_type, alpha, top=True, idx=0):\n    def get_spectral_A_name(original_layer_name):\n        if model_type == 'text_encoder':\n            spectral_A_name = original_layer_name.replace('q_proj.weight', 'q_proj.spectral_A')                 .replace('k_proj.weight', 'k_proj.spectral_A')                 .replace('v_proj.weight', 'v_proj.spectral_A')                 .replace('out_proj.weight', 'out_proj.spectral_A')                 .replace('fc1.weight', 'fc1.spectral_A')                 .replace('fc2.weight', 'fc2.spectral_A')\n        else:\n            spectral_A_name = k.replace('to_q.weight', 'to_q.spectral_A')                 .replace('to_k.weight', 'to_k.spectral_A')                 .replace('to_v.weight', 'to_v.spectral_A')                 .replace('to_out.0.weight', 'to_out.0.spectral_A')                 .replace('ff.net.0.proj.weight', 'ff.net.0.proj.spectral_A')                 .replace('ff.net.2.weight', 'ff.net.2.spectral_A')                 .replace('proj_out.weight', 'proj_out.spectral_A')                 .replace('proj_in.weight', 'proj_in.spectral_A')\n\n        return spectral_A_name\n    \n    def cayley(data):\n        r, _ = data.shape\n        skew = 0.5 * (data - data.T)\n        I = torch.eye(r, device=data.device)\n        Q = torch.mm(I - skew, torch.inverse(I + skew))\n        return Q\n\n    assert model_type in ['unet', 'text_encoder']\n    new_state_dict = copy.deepcopy(original_state_dict)\n    load_cnt = 0\n    for k in new_state_dict.keys():\n        spectral_A_name = get_spectral_A_name(k)\n        spectral_B_name = spectral_A_name.replace('spectral_A', 'spectral_B')\n        spectral_C_name = spectral_A_name.replace('spectral_A', 'spectral_C')\n        U_name = spectral_A_name.replace('spectral_A', 'U')\n        S_name = spectral_A_name.replace('spectral_A', 'S')\n        V_name = spectral_A_name.replace('spectral_A', 'V')\n        if spectral_B_name in lora_state_dict:\n            load_cnt += 1\n            original_params = new_state_dict[k]\n            spectral_A_params = lora_state_dict[spectral_A_name].to(original_params.device)\n            spectral_B_params = lora_state_dict[spectral_B_name].to(original_params.device)\n            spectral_C_params = lora_state_dict[spectral_C_name].to(original_params.device)\n            U_params = lora_state_dict[U_name].to(original_params.device)\n            S_params = lora_state_dict[S_name].to(original_params.device)\n            V_params = lora_state_dict[V_name].to(original_params.device)\n            r = spectral_A_params.shape[0]\n            if top:\n                pad_U = U_params \n                pad_U[:,idx*r:(idx+1)*r] = U_params[:,idx*r:(idx+1)*r]@(alpha*(cayley(spectral_A_params)-torch.eye(r).to(spectral_A_params.device))+torch.eye(r).to(spectral_A_params.device))\n                pad_V = V_params\n                pad_V[:,idx*r:(idx+1)*r] = V_params[:,idx*r:(idx+1)*r]@(alpha*(cayley(spectral_B_params)-torch.eye(r).to(spectral_A_params.device))+torch.eye(r).to(spectral_A_params.device))\n                pad_S = S_params \n                pad_S[idx*r:(idx+1)*r] = S_params[idx*r:(idx+1)*r]*(alpha*(spectral_C_params-torch.ones(r).to(spectral_A_params.device))+torch.ones(r).to(spectral_A_params.device))\n            else:\n                raise Exception('')\n            if len(original_params.shape) == 4:\n                raise Exception('')\n            else:\n                spectral_param = pad_U@pad_S.diag()@pad_V.T\n            new_state_dict[k] = spectral_param\n    print(f'load {load_cnt} Spectrals of {model_type}')\n    return new_state_dict",
    "Experiment Result": "The core methodology involves Singular Value Decomposition (SVD) on pretrained model weight matrices (W = USV^T) within a Stable Diffusion model's text encoder and UNet layers. Specifically, the `SpectralLinearLayer_OFT` is designed for adaptation. The original U, S, and V matrices obtained from SVD are kept fixed (non-trainable). The adaptation is applied by introducing three sets of trainable parameters: `self.spectral_A` and `self.spectral_B` (both `revised_r x revised_r` matrices, initialized to zeros) and `self.spectral_C` (a vector of size `revised_r`, initialized to ones). Cayley parameterization (`self.cayley` function) is used to ensure orthogonality for the updates to U and V, effectively implementing Spectral AdapterR. The top-r columns of the U and V singular vector matrices are orthogonally rotated using these trainable matrices. The corresponding singular values in S are scaled by `self.spectral_C`. The `revised_r` parameter, explicitly set to `rank` in `__init__`, controls the adaptable parameter budget (the 'r' value). An `alpha` parameter further scales the magnitude of the adapter's contribution to the original weights, where the scaled contribution is `alpha * (Cayley(spectral_params) - Identity)` for U/V and `alpha * (spectral_C_params - ones)` for S, which are then added to identity/ones before being applied. This approach allows flexible parameter budgets and is applied to 'Linear' layers (and potentially 'Conv2d' layers with 1x1 kernel size, though not fully implemented for Conv2d in the provided code)."
}{
    "Title": "Adapters Strike Back",
    "Main Contributions": "The paper provides an in-depth and systematic study of adapters for Vision Transformers (ViTs), identifying pitfalls in previous implementations and proposing an improved architecture called Adapter+. The main contributions are: (1) the first comprehensive study on adapter position, inner structure, and initialization for ViTs, (2) the proposal of a learnable, channel-wise scaling as an extension beneficial for computer vision tasks, and (3) the introduction of Adapter+, which achieves state-of-the-art average accuracy on the VTAB benchmark (77.6%) without per-task hyperparameter optimization and on FGVC (90.7%) with the lowest number of parameters, demonstrating superior parameter-accuracy trade-off and robustness compared to other adaptation mechanisms.",
    "Methodology": "The study systematically investigates bottleneck adapter modules, their integration into ViT transformer layers, and various implementation choices. Key methodological aspects include: (1) evaluating four adapter positions (Pre, Post, Parallel, Intermediate) relative to the Feed-Forward Network (FFN), with Post-Adapter identified as optimal, (2) analyzing inner adapter structures, proposing a learnable, channel-wise scaling as a beneficial alternative to layer-wise scaling, and (3) comparing parameter initialization methods (Houlsby, BERT, LoRA), with Houlsby initialization found to be best. The final Adapter+ configuration combines the Post-Adapter position, learnable channel-wise scaling, and Houlsby initialization. The methodology also emphasizes the importance of using data normalization consistent with the pre-trained backbone.",
    "Experimental Setup": "Experiments were conducted using a ViT-B/16 network pre-trained on ImageNet-21k, with additional ablations on ImageNet-1k fine-tuned and AugReg pre-trained backbones. Two standard benchmarks were used: the Visual Task Adaptation Benchmark (VTAB) comprising 19 tasks grouped into Natural, Specialized, and Structured categories (800 train, 200 validation images per task), and a Fine-Grained Visual Classification (FGVC) benchmark (CUB-200-2011, NABirds, Oxford Flowers, Stanford Dogs, Stanford Cars) for abundant data scenarios. Models were trained with an AdamW optimizer (learning rate 10^-3, weight decay 10^-4, batch size 64) for 100 epochs, using a cosine learning rate schedule with linear warm-up. Stochastic depth regularization was applied to both frozen layers and adapters. Input images were resized to 224x224px. For fair comparison, many competing methods (LoRA, VPT, SSF, FacT, SPT) were re-evaluated using consistent data normalization and full training schedules, correcting for issues like early stopping on test sets found in original implementations.",
    "Limitations": "The study primarily focuses on the ViT-B/16 architecture, which may limit the direct generalizability of the findings to other Vision Transformer variants or sizes without further empirical validation. While Adapter+ performs well without per-task hyperparameter optimization, its peak performance still benefits from per-task optimization of the adapter rank 'r', indicating some degree of hyperparameter sensitivity. The extensive re-evaluation of other methods revealed that previous comparisons often suffered from unfair practices (e.g., early stopping on test sets, unsuitable data normalization), suggesting that Adapter+'s reported superiority is partly attributable to a more rigorous and fair evaluation methodology. Furthermore, the paper notes that layer normalization within the adapter, while suggested by previous work in NLP, was found to be detrimental in their vision task settings, which might imply a specific context dependency.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": "import torch\nfrom torch import nn\nfrom timm.models.layers import DropPath\nfrom timm.models.vision_transformer import Block\nimport pytorch_lightning as pl\nfrom typing import Optional\n\n# Core Adapter module with scaling and initialization logic\nclass Adapter(nn.Module):\n    def __init__(\n        self,\n        embed_dim,\n        bottleneck_dim=8,\n        drop_path=0.0,\n        dropout=0.0,\n        act_layer=nn.GELU,\n        norm_layer=nn.LayerNorm, # For Adapter+ set to None\n        scaling=1.0, # For Adapter+ set to \"channel\"\n        init=\"houlsby\",\n        bias=True,\n        pre_dropout=False,\n    ):\n        super().__init__()\n        self.bottleneck = nn.Sequential(\n            nn.Dropout(dropout) if dropout > 0 and pre_dropout else nn.Identity(),\n            nn.Linear(embed_dim, bottleneck_dim, bias=bias),\n            act_layer() if act_layer else nn.Identity(),\n            nn.Dropout(dropout) if dropout > 0 and not pre_dropout else nn.Identity(),\n            nn.Linear(bottleneck_dim, embed_dim, bias=bias),\n        )\n        self.norm_a = norm_layer(embed_dim) if norm_layer else nn.Identity()\n        self.drop_path_a = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n\n        # Learnable channel-wise scaling\n        if scaling == \"channel\":\n            self.scaling = nn.Parameter(torch.ones(embed_dim))\n        else:\n            self.scaling = scaling\n\n        # Houlsby initialization\n        if init == \"houlsby\":\n            std = 0.01\n            nn.init.trunc_normal_(self.bottleneck[1].weight, std=std, a=-2 * std, b=2 * std)\n            if self.bottleneck[1].bias is not None: nn.init.zeros_(self.bottleneck[1].bias)\n            nn.init.trunc_normal_(self.bottleneck[4].weight, std=std, a=-2 * std, b=2 * std)\n            if self.bottleneck[4].bias is not None: nn.init.zeros_(self.bottleneck[4].bias)\n\n    def forward(self, x: torch.Tensor, skip: Optional[torch.Tensor] = None) -> torch.Tensor:\n        x = self.norm_a(x)\n        x = self.drop_path_a(self.bottleneck(x))\n        x = x * self.scaling # Apply scaling\n        y = x\n        if skip is not None: y = y + skip\n        return y\n\n# Adapter integration into a transformer block (Post-Adapter position)\nclass AdapterBlock(Block): # Block class from timm.models.vision_transformer\n    def __init__(self, dim: int, num_heads: int, mlp_ratio: float = 4.0, adapter_config=None, **kwargs):\n        super().__init__(dim, num_heads, mlp_ratio=mlp_ratio, **kwargs)\n        self.adapter_config = adapter_config\n        if adapter_config is not None:\n            # Instance of Adapter with specific config, e.g., scaling=\"channel\", init=\"houlsby\", norm_layer=None\n            self.adapter = Adapter(\n                dim,\n                bottleneck_dim=adapter_config.dim,\n                dropout=adapter_config.dropout,\n                drop_path=adapter_config.drop_path,\n                act_layer=kwargs.get('act_layer') if adapter_config.act_layer else None,\n                norm_layer=kwargs.get('norm_layer') if adapter_config.norm_layer else nn.Identity(), # Expected None for Adapter+\n                bias=adapter_config.bias,\n                scaling=adapter_config.scaling, # \"channel\" for Adapter+\n                init=adapter_config.init, # \"houlsby\" for Adapter+\n            )\n\n    def forward_post(self, x: torch.Tensor) -> torch.Tensor:\n        x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))\n        x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\n        x = self.adapter(x, skip=x) # Adapter applied after FFN\n        return x\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if self.adapter_config and self.adapter_config.config == \"post\":\n            return self.forward_post(x)\n        # ... (other adapter positions or no adapter logic)\n        return super().forward(x)\n\n# Model setup for training adapters\nclass AdapterModel(pl.LightningModule):\n    def __init__(self, cfg, num_classes=1000, **kwargs):\n        super().__init__()\n        # timm.create_model is patched to use VisionTransformerAdapter and AdapterBlock\n        self.vit = timm.create_model(\n            cfg.vit.model,\n            adapter=True, # Activates adapter integration\n            pretrained=True,\n            num_classes=num_classes,\n            adapter_config=cfg.get(\"adapter\", None), # Configuration for Adapter module\n            # ...\n        )\n\n        if cfg.get(\"adapter\", None): # If adapter is configured\n            if not cfg.vit.finetune:\n                self.vit.requires_grad_(False) # Freeze backbone\n            self.vit.head.requires_grad_(True) # Unfreeze classifier head\n            for m in self.vit.modules():\n                if isinstance(m, Adapter):\n                    m.requires_grad_(True) # Unfreeze Adapter modules\n                if cfg.train.train_ln and isinstance(m, nn.LayerNorm):\n                    m.requires_grad_(True) # Optionally unfreeze LayerNorms\n\n# Function to handle weight decay, specifically for learnable scaling parameters\ndef add_weight_decay(model, weight_decay=1e-5, skip_list=(), exclude_list=()):\n    decay = []\n    no_decay = []\n    for name, param in model.named_parameters():\n        if not param.requires_grad or name in exclude_list:\n            continue\n        if (\n            len(param.shape) == 1\n            or name.endswith(\".bias\")\n            or name.endswith(\".scaling\") # Skip learnable scaling parameters from weight decay\n            or name in skip_list\n        ):\n            no_decay.append(param)\n        else:\n            decay.append(param)\n    return [\n        {\"params\": no_decay, \"weight_decay\": 0.0},\n        {\"params\": decay, \"weight_decay\": weight_decay},\n    ]",
    "Experiment Result": "The optimal adapter configuration (Adapter+) is used, integrating bottleneck adapter modules into ViT transformer layers. The adapter is placed in the **Post-Adapter position** (after the Feed-Forward Network, FFN). The inner structure of the adapter employs **learnable, channel-wise scaling** (`scaling=\"channel\"`), with Layer Normalization within the adapter module explicitly set to `None`. **Houlsby initialization** (`std=0.01`) is used for the adapter's weights.\n\nThe **ViT backbone weights are largely frozen** (`requires_grad_(False)`), except for the adapter modules and the final classification head, which are made trainable (`requires_grad_(True)`). Optionally, all ViT Layer Normalization layers can also be set to be trainable. During optimization, the learnable scaling parameters of the adapter are excluded from weight decay.\n\nInput images are preprocessed with **data normalization consistent with the pre-trained backbone**, typically using ImageNet's default mean and standard deviation values. The optimization typically uses the **AdamW optimizer** and a **Linear Warmup Cosine Annealing learning rate scheduler**.\n\nDefault hyperparameters for the adapter include a **bottleneck dimension of 8** (`bottleneck_dim=8`) and a **dropout rate of 0.0** within the adapter module. The overall model's drop path rate is configurable."
}{
    "Title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone",
    "Main Contributions": "The paper introduces Res-Tuning, a novel paradigm that unbinds tuners from the backbone of large foundation models to address restrictions in design flexibility and high computational costs of existing parameter-efficient tuning (PETL) methods. It proposes a unified unbinding formulation for popular PETL methods (prefix, prompt, adapters) and demonstrates its seamless integration. The framework allows for flexible combination of various tuning strategies, leading to stronger performance. A memory-efficient variant, Res-Tuning-Bypass, detaches tuners from the backbone to enable gradient propagation only to tuners, reducing training memory and facilitating one-time backbone forward for multi-task inference, achieving state-of-the-art efficacy and efficiency across discriminative and generative tasks.",
    "Methodology": "Res-Tuning unbinds tuners from the pre-trained backbone by re-formulating existing PETL methods (prefix tuning, prompt tuning, adapter tuning) into a parallel structure, expressed as x' = OP(x) + Res-Tuner(x). OP is a frozen backbone operation, and Res-Tuner is a learnable parallel structure. This allows flexible design and combination of tuners (e.g., Single, Dual, Tri-Res-Tuner). Res-Tuning-Bypass, a memory-efficient variant, physically detaches the Res-Tuners from the backbone during training, creating a bypass network. This prevents backpropagation through the massive backbone parameters, only updating the tuners, and enables a single backbone forward pass for multi-task inference.",
    "Experimental Setup": "The framework was evaluated on discriminative tasks (transfer learning, few-shot learning, domain generalization) and generative tasks (text-to-image generation). Backbones included ViT-B/16 (ImageNet-21K) and ViT-L/14 (CLIP) for discriminative tasks, and Stable Diffusion v1.5 (U-Net architecture) for generative tasks. Discriminative datasets used were CIFAR-100, VTAB-1K (19 diverse tasks), five fine-grained datasets for few-shot learning, and ImageNet variants for domain generalization. Generative datasets included COCO2017, Oxford Flowers, and Food-101. Metrics were Top-1 accuracy for discriminative tasks and FID score plus qualitative results for generative tasks. Baselines included fully fine-tuning, linear probing, and various parameter-efficient and memory-efficient tuning methods (e.g., Adapter, LoRA, VPT, SSF, Side-Tuning, LST). Hyperparameters involved AdamW optimizer, cosine decay learning rate schedule, and specific tuner dimensions.",
    "Limitations": "The transfer ability of Res-Tuning largely depends on the performance of the upstream pre-trained foundation model. Additionally, if the upstream pre-training model contains illegal content, this could lead to the illegal use of tuning methods with Res-Tuning.",
    "Future Research Directions": "The authors express hope that their discoveries will facilitate further research in the flexible and efficient tuning of large foundation models, implying future exploration of more sophisticated tuner designs, combinations, and application to an even wider range of foundation models or tasks, leveraging the unbinding formulation and memory efficiency.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data",
    "Main Contributions": "This paper addresses challenges in Multi-Task Learning (MTL) for Natural Language Processing (NLP), such as overfitting to low-resource tasks, catastrophic forgetting, and negative task transfer, which often necessitate a separate model per task. The authors propose Conditionally Adaptive Multi-Task Learning (CA-MTL), a novel Transformer-based Adapter that incorporates a new conditional attention mechanism and task-conditioned modules to facilitate efficient weight sharing. A key contribution is fixing half of the pretrained model weights to mitigate forgetting and introducing a new uncertainty-based multi-task data sampling strategy (MT-Uncertainty Sampling) to address data imbalance across tasks. CA-MTL surpasses single-task fine-tuning methods while being parameter and data efficient (using 66% of data for weight updates). Empirically, their 8-task model outperforms other Adapter methods by 2.8% on GLUE, and their 24-task model surpasses MTL and single-task fine-tuning models by 0.7-1.0%. The approach achieves competitive performance across 26 NLP tasks and state-of-the-art results on several test and development sets, being the first to explore latent representations for modularizing pretrained architectures and uncertainty sampling for large-scale NLP MTL.",
    "Methodology": "The CA-MTL framework is built upon a task-conditioned Transformer architecture that either adds conditional layers or modulates existing pretrained weights using a task embedding (zi). This involves Conditional Weight Transformations of the form φ(W|zi) = γi(zi)W + βi(zi), where γi and βi are learned functions. The architecture integrates several novel components: (1) Conditional Attention, a block-diagonal attention mechanism that incorporates task-specific biases via a learnable weight matrix M(zi). (2) Conditional Alignment, a task-conditioned layer between the input embedding and the first Transformer layer, where a single alignment matrix ˆR is generated as a function of the task embedding. (3) Conditional Layer Normalization (CLN), which extends Conditional Batch Normalization to adapt layer normalization statistics to specific tasks. (4) A Conditional Bottleneck, a task-conditioned two-layer feed-forward bottleneck that facilitates weight sharing and information flow. To balance different tasks in MTL, the paper introduces Multi-Task Uncertainty Sampling, an active learning-inspired task selection strategy. It evaluates model uncertainty using Shannon Entropy (Hi) and normalizes it to account for differing class numbers and high entropy outliers. The algorithm prioritizes tasks with higher uncertainty by choosing 'b' samples with the highest uncertainty from 'b × T' candidates to train the model.",
    "Experimental Setup": "The CA-MTL implementation is based on HuggingFace and uses Adam optimizer with a learning rate of 2e-5, a batch size of 32, and a fixed seed of 12. Learning rate decay with warm-up is applied over the first 10% of training steps. For 8-task models, 5 epochs and a sequence length of 128 were used, while for 24-task models, 8 epochs and a sequence length of 256 were employed. A dropout rate of 0.1 was applied across all layers. The bottom half of the Transformer layers were frozen in most experiments to preserve pretrained knowledge, with ablation studies confirming this choice. Experiments were conducted using either four NVIDIA P100 GPUs for base models or four NVIDIA V100 GPUs for larger models. No parameter search, model ensembles, or task-specific tricks were used. The evaluation involved 26 NLP tasks across various benchmarks: GLUE (9 tasks including MNLIm/MNLImm), SuperGLUE (8 tasks), MRQA (6 tasks), and WNUT2017 (Named Entity Recognition). Domain adaptation capabilities were tested on SciTail and SNLI datasets. Performance was measured using GLUE average scores (accuracy, F1, Matthew's correlation, Spearman's correlation as appropriate), Task σ (standard deviation of scores across tasks), and covariance similarity scores. Baselines included single-task fine-tuned BERT/RoBERTa models, MTL models (BERT, RoBERTa, MT-DNN, PALs+Anneal Samp.), and other adapter networks (Adapters-256). Comparisons were also made against MT-DNNSMART, STILTS, BAM!, ALUM, and SemBert.",
    "Limitations": "The paper notes that the performance gain on RTE, while positive for MTL, might be a side effect of the chosen layer freezing configuration. An ablation study indicated that the Conditional Bottleneck module did not consistently improve overall performance. Experiments with a full-block Conditional Attention variant showed it performed significantly worse and required more parameters than the block-diagonal variant. For the WNUT2017 Named Entity Recognition task, CA-MTL, despite significantly outperforming the MTL baseline, did not fully close the gap with the single-task baselines, suggesting it had not yet overfit and could have benefited from more training cycles. The Evolutionary Data Measures (EDM) used to estimate task difficulty for analyzing MT-Uncertainty sampling behavior were acknowledged to lack precision, being more effective at classifying task difficulty rather than providing a regression-like value. Furthermore, CA-MTL's zero-shot transfer ability to new tasks was found to be sensitive to the initialization of the new task's embedding. The hypothesis that preserving more pretrained weights by freezing layers is beneficial when scaling to 24 or more tasks was stated but not further explored.",
    "Future Research Directions": "The authors state that extending the ideas of dynamically adapting and modularizing knowledge embedded in large monolithic pretrained models will be a primary objective for future work. Additionally, they implicitly suggest further exploration into the hypothesis regarding the benefits of preserving more pretrained weights when increasing the total number of tasks (to 24 or more), as this aspect was not fully investigated in the current study.",
    "Experiment Code": "class FiLM(nn.Module):\n    \"\"\" Feature-wise Linear Modulation (FiLM) layer\"\"\"\n    def __init__(self, input_size, output_size, num_film_layers=1, layer_norm=False):\n        \"\"\"\n        :param input_size: feature size of x_cond\n        :param output_size: feature size of x_to_film\n        :param layer_norm: true or false\n        \"\"\"\n        super(FiLM, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.num_film_layers = num_film_layers\n        self.layer_norm = nn.LayerNorm(output_size) if layer_norm else None\n        film_output_size = self.output_size * num_film_layers * 2\n        self.gb_weights = nn.Linear(self.input_size, film_output_size)\n        self.gb_weights.bias.data.fill_(0)\n\n    def forward(self, x_cond, x_to_film):\n        gb = self.gb_weights(x_cond).unsqueeze(1)\n        gamma, beta = torch.chunk(gb, 2, dim=-1)\n        out = (1 + gamma) * x_to_film + beta\n        if self.layer_norm is not None:\n            out = self.layer_norm(out)\n        return out\n\n\nclass CBDA(nn.Module):\n    \"\"\" Conditional Block Diagonal Attention (CBDA) layer\"\"\"\n    def __init__(self, input_size, output_size, blocks=1, num_film_layers=1, layer_norm=False):\n        \"\"\"\n        :param input_size: feature size of x_cond\n        :param output_size: feature size of x_to_film\n        :param layer_norm: true or false\n        \"\"\"\n        super(CBDA, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.num_film_layers = num_film_layers\n        self.layer_norm = nn.LayerNorm(output_size) if layer_norm else None\n        self.blocks = blocks\n        film_output_size = self.output_size * num_film_layers * 2\n        self.gb_weights = nn.Linear(self.input_size, film_output_size)\n        self.gb_weights.bias.data.fill_(0)\n\n    def forward(self, x_cond, x_to_film):\n        gb = self.gb_weights(x_cond).unsqueeze(1)\n        gamma, beta = torch.chunk(gb, 2, dim=-1)\n        out = (1 + gamma) * x_to_film + beta\n        if self.layer_norm is not None:\n            out = self.layer_norm(out)\n        out = [torch.block_diag(*list(out_b.chunk(self.blocks, 0))) for out_b in out]\n        out = torch.stack(out)\n        return out[:, :, :out.size(1)]\n\n# Usage of CBDA in attention (e.g., from MyBertSelfAttention9.forward in ca_mtl_base.py):\n# attention_scores2 = self.cond_block_diag_attn(\n#     x_cond=task_embedding,\n#     x_to_film=self.random_weight_matrix,\n# )\n# attention_scores = attention_scores1 + attention_scores2.unsqueeze(1)\n\n\nclass ConditionalLayerNorm(nn.Module):\n    r\"\"\"Applies Conditional Layer Normalization over a mini-batch of inputs.\"\"\"\n    __constants__ = ['normalized_shape', 'condition_size', 'weight', 'bias', 'eps']\n\n    def __init__(self, normalized_shape, condition_size, eps=1e-5):\n        super(ConditionalLayerNorm, self).__init__()\n        if isinstance(normalized_shape, numbers.Integral):\n            normalized_shape = (normalized_shape,)\n        self.normalized_shape = tuple(normalized_shape)\n\n        self.condition_size = condition_size\n        self.eps = eps\n\n        self.weight = nn.Parameter(torch.Tensor(*normalized_shape))\n        self.ln_weight_modulation = FiLM(condition_size, sum(normalized_shape))\n        self.bias = nn.Parameter(torch.Tensor(*normalized_shape))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.ones_(self.weight)\n        nn.init.zeros_(self.bias)\n\n    def forward(self, input_, condition, task_id):\n        unique_task_ids = torch.unique(task_id)\n        cln_output = torch.zeros_like(input_)\n        for unique_task_id in unique_task_ids:\n            task_id_filter = task_id == unique_task_id\n            task_emb = condition[task_id_filter][0].unsqueeze(0)\n            weight = self.ln_weight_modulation(task_emb, self.weight).view(-1)\n            cln_output[task_id_filter] = F.layer_norm(input_[task_id_filter], self.normalized_shape, weight, self.bias, self.eps)\n        return cln_output\n\n    def extra_repr(self):\n        return '{normalized_shape}, {condition_size}, eps={eps}'.format(**self.__dict__)\n\n\nclass ConditionalBottleNeck(nn.Module):\n    \"\"\"Down projection and up projection with FiLM layers within Transformer layer.\"\"\"\n    def __init__(self, config):\n        super(ConditionalBottleNeck, self).__init__()\n        self.emb_transf = nn.Linear(config.hidden_size, config.hidden_size)\n        self.hidden_modulation = FiLM(config.hidden_size, config.hidden_size)\n        self.down_proj_layer = nn.Linear(config.hidden_size, config.hidden_size//3)\n        self.up_proj_layer = nn.Linear(config.hidden_size//3, config.hidden_size)\n\n    def forward(self, x_cond, hidden_states):\n        x_cond = self.emb_transf(x_cond)\n        hidden_states = self.hidden_modulation(x_cond=x_cond, x_to_film=hidden_states)\n        hidden_states = self.down_proj_layer(hidden_states)\n        hidden_states = self.up_proj_layer(hidden_states)\n        return hidden_states\n\n\n# Conditional Alignment (FiLM applied after embeddings, e.g., from CaMtlBaseEncoder.forward):\n# embedding_output = self.embeddings(\n#     input_ids=input_ids,\n#     position_ids=position_ids,\n#     token_type_ids=token_type_ids,\n#     inputs_embeds=inputs_embeds,\n# )\n# embedding_output = self.conditional_alignment(\n#     x_cond=task_embedding,\n#     x_to_film=embedding_output,\n# )\n\n\n# Multi-Task Uncertainty Sampling - Entropy Calculation (from Decoder.py):\n# class Decoder(torch.nn.Module):\n#     # ... other methods ...\n#     def calculate_entropy(self, logits):\n#         probas = Softmax(dim=1)(logits.detach())\n#         samples_entropy = entropy(probas.transpose(0, 1).cpu())\n#         even_preds = numpy.array(\n#             [[1 / self.num_labels for _ in range(self.num_labels)]]\n#         )\n#         max_entropy = entropy(even_preds.T)\n#         epsilon = 1e-5\n#         samples_entropy = samples_entropy / (max_entropy.item() + epsilon)\n#         return torch.tensor(samples_entropy)\n\n\n# Multi-Task Uncertainty Sampling - Sampling Logic (from MtUcertaintyIterator.__next__ in mtl_trainer.py):\n# test_batch = {}\n# for idx, loader_iter in enumerate(self.loader_iters):\n#     try:\n#         batch = loader_iter.__next__()\n#     except StopIteration:\n#         new_loader_iter = iter(self.my_loader.loaders[idx])\n#         self.loader_iters[idx] = new_loader_iter\n#         batch = new_loader_iter.__next__()\n#\n#     test_batch = self.batchify_data(batch, test_batch)\n#\n# inputs = {}\n# for k, v in test_batch.items():\n#     if k not in [\"labels\"]:\n#         inputs[k] = v.detach().to(self.my_loader.args.device)\n#\n# with torch.no_grad():\n#     model.select_batch_mode = True # Placeholder for context, actual code might not have this line\n#     outputs = model(**inputs)\n#     model.select_batch_mode = False # Placeholder for context, actual code might not have this line\n#\n# (\n#     test_batch_entropy,\n#     test_batch_entropy_mean,\n#     max_mean_batch_entropy,\n# ) = outputs[-3:]\n#\n# # ... del inputs ...\n#\n# test_batch_entropy_mean = (\n#     test_batch_entropy_mean / max_mean_batch_entropy\n# )\n# test_batch_entropy = test_batch_entropy * test_batch_entropy_mean\n#\n# # ... handling specific task types (sts-b, mrpc) for entropy adjustment ...\n#\n# select_size = min(\n#     self.my_loader.args.train_batch_size,\n#     test_batch[\"input_ids\"].shape[0],\n# )\n# top_entropy = torch.topk(test_batch_entropy, select_size)\n#\n# for k, v in test_batch.items():\n#     test_batch[k] = torch.index_select(v, 0, top_entropy.indices)",
    "Experiment Result": "CA-MTL Model Variants and Architectural Details: CA-MTL-base implements Conditional Attention (CBDA) and Conditional Layer Normalization (CLN) in its attention and output layers, respectively. It applies a Conditional Bottleneck only in its top encoder layer, and Conditional Alignment (FiLM) after the embedding layer. CA-MTL-large, on the other hand, also uses CBDA and CLN in its attention and output layers, but applies the Conditional Bottleneck to *all encoder layers*. Both variants utilize task embeddings for conditioning various modules. Weight Freezing Strategy: The framework allows freezing a range of encoder layers (e.g., '0-5'). Critically, when layers are frozen, specific task-conditioned components are *explicitly unfrozen* to enable adaptation. These include `random_weight_matrix` (for CBDA), `film.gb_weights` (for FiLM in alignment and bottleneck), `ln_weight_modulation.gb_weights` (for CLN), and `adapter` (for the Conditional Bottleneck). Multi-Task Uncertainty Sampling: This active learning-inspired strategy is activated by the `use_mt_uncertainty` argument. It calculates model uncertainty using Shannon Entropy on softmax probabilities, which is then normalized by the maximum possible entropy. This sample-wise entropy is further scaled by a normalized mean batch entropy. `torch.topk` selects the samples with the highest uncertainty for training. The `percent_of_max_data_size` argument controls the number of candidate samples. An alternative, `uniform_mt_sampling`, ensures equal samples per task per epoch. General Data Settings: The `data_dir` specifies the input data location. `tasks` defines the list of GLUE benchmarks used (e.g., CoLA, MNLI, RTE, WNLI, QQP, STS-B, SST-2, QNLI, MRPC). `max_seq_length` sets the maximum sequence length (default 128). Training Configuration: The `warmup_proportion` (default 0.1) dictates the fraction of total training steps for linear learning rate warmup. The optimizer used is AdamW."
}{
    "Title": "Towards Modular LLMs by Building and Reusing a Library of LoRAs",
    "Main Contributions": "The paper addresses the challenge of reusing trained parameter-efficient adaptations (LoRAs) to enhance Large Language Model (LLM) performance on new tasks, particularly in zero-shot settings. It introduces Model-Based Clustering (MBC) for building a library of LoRA adapters, which groups tasks based on the similarity of their privately trained LoRA parameters and then trains a single adapter per cluster. A novel zero-shot routing mechanism, Arrow (↗↗), is proposed, dynamically selecting relevant LoRAs by leveraging the Singular Value Decomposition (SVD) of adapter parameters to identify directions of maximum variance. The research demonstrates that MBC-based adapters combined with Arrow routing achieve superior generalization, matching or outperforming traditional joint training methods (like full fine-tuning) on various LLMs (Phi-2, Mistral 7B) across zero-shot and supervised adaptation.",
    "Methodology": "The study utilizes LoRA for parameter-efficient fine-tuning. For library construction, it proposes Model-Based Clustering (MBC): initially training private LoRAs for each task, then computing cosine similarity between their flattened and SVD-reduced parameter vectors, clustering tasks using K-means, and finally training a single adapter for each cluster on the combined cluster data. For reusing the library, several routing strategies are explored. Zero-shot routing includes µ Routing (uniform averaging), TP Routing (a task predictor classifier), CM Routing (centroid matching with hidden state prototypes), and the novel Arrow (↗↗) Routing. Arrow computes a prototype for each LoRA expert (Ai, Bi) by taking the first right singular vector of AiBᵀi, then routes per token and per layer by calculating the absolute dot product between the hidden state and these prototypes, selecting top-k experts. Supervised task routing methods examined are Poly Routing (learning input-independent layer-specific weights and tuning expert parameters), LoraHub Routing (gradient-free optimization of routing coefficients only), and π-tuning (using Fisher Information for task embeddings, retrieving similar experts, and tuning coefficients and expert parameters). LoRA composition involves linearly combining selected adapters based on routing probabilities.",
    "Experimental Setup": "Experiments were conducted using Phi-2 (2.8B parameters) and Mistral 7B as base LLMs, with LoRA adapters applied only to attention layers (rank 4, dropout 0.05, learning rate 1e-4, alpha 16). The multi-task training dataset comprised 256 tasks from Flan v2, with 10,000 examples per task. SuperNatural Instructions (SNI) tasks were held out from training. Evaluation for zero-shot generalization involved 10 diverse held-out tasks (common-sense reasoning, QA, coding, general reasoning), measured by accuracy, with overlaps removed from the training set. Supervised adaptation was evaluated on 12 held-out SNI tasks, using Rouge-L scores, in full-data and limited-data (10%, 5%, 0.5%) regimes. MBC was configured with 10 clusters, and its training budget was matched to other methods by allocating 40% for initial private LoRA training and 60% for cluster adapter training. Zero-shot routing used top-4 expert selection with temperature 1.",
    "Limitations": "The research is currently limited to LoRA adapters, with other adapter types (e.g., soft prompts, MLPs) not yet explored. The scalability of the proposed MBC and Arrow methods to significantly larger datasets and models remains an open question for future investigation. The paper notes that the performance gains from advanced routing strategies like Arrow diminish for smaller adapter libraries, a phenomenon that contrasts with sparse Mixture-of-Experts models and warrants further study, possibly due to the linear nature of LoRA experts. Additionally, LoraHub's underperformance in supervised adaptation is attributed to its design, which optimizes only routing coefficients without fine-tuning the expert LoRA weights themselves.",
    "Future Research Directions": "Future work includes exploring a more heterogeneous 'universe' of adapters beyond LoRA, such as soft and hard prompts, MLPs, and their combinations. Investigating the scalability of the proposed approach to larger datasets and models is also a key direction. The authors suggest applying the Arrow routing strategy to modular continual learning, anticipating that its local nature and independence from gradient-based training could make it less susceptible to catastrophic forgetting. Further research is also needed to understand why the benefits of sophisticated routing diminish for smaller libraries, potentially by contrasting the linearity of LoRA experts with the MLP experts in sparse Mixture-of-Experts models. Lastly, a deeper exploration into why expert clusters with lower similarity (higher diversity) lead to better performance, possibly by examining distinct feature contributions, is proposed.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "On the Weight Dynamics of Deep Normalized Networks",
    "Main Contributions": "The paper formalizes how effective learning rate (ELR) disparities evolve over time in deep normalized networks, which can negatively affect trainability. It models weight dynamics (expected gradient and weight norms) and predicts the evolution of layer-wise ELR ratios. Key findings include proving that ELR ratios converge to 1 with any constant learning rate despite initial gradient explosion, identifying a 'critical learning rate' beyond which ELR disparities widen, and devising a hyper-parameter-free warm-up method to minimize ELR spread quickly. The research empirically links high ELR spread with low trainability, particularly in very deep networks.",
    "Methodology": "The methodology involves formalizing weight dynamics by modeling the evolution of expected gradient and weight norms in networks with normalization layers, assuming that these layers are scale-invariant and that gradient updates are orthogonal to weights. This leads to a discrete model described by Eq. 5. In the gradient flow limit (continuous model), this behavior reduces to a non-linear ordinary differential equation with a closed-form solution (Eq. 12), predicting smooth convergence of ELR ratios to 1. For bigger learning rates, the discrete model is analyzed, revealing a 'critical learning rate' (κjk) at which ELR ratios can temporarily widen or 'flip'. A 'subcritical warm-up' scheme is derived by setting the learning rate to this critical value, ensuring convergence in L steps. An alternative method of 'constraining layer-wise ELRs' by scaling gradients to maintain constant effective learning rates is also proposed.",
    "Experimental Setup": "Experiments were conducted on ResNet v1 architectures (56 and 110 layers), both with ('Short') and without ('NoShort') residual connections, chosen to amplify the observed effects. Standard image classification datasets were used: CIFAR-10, CIFAR-100, and ILSVRC 2012 (ImageNet). Training employed vanilla SGD with momentum, weight decay, affine BatchNorm parameters, and bias on linear layers disabled to isolate weight dynamics. Various learning rate schedulers, with and without warm-up, were tested. Validation involved comparing predicted vs. measured weight/gradient norms and ELR evolution, assessing the model's predictive accuracy under 'random walk' (randomized gradients) and 'real training' scenarios. The 'Relative Logarithmic ELR Spread' (Srel) was used to quantify ELR disparities. The effectiveness of the proposed warm-up and ELR-constraining methods was evaluated by observing their impact on ELR spread and network trainability (test accuracies).",
    "Limitations": "The theoretical model primarily assumes that the 'base gradient' magnitude (excluding normalization effects) remains constant over time, which is not strictly true in practical settings where gradient norms typically shrink as the objective function saturates. The model exclusively focuses on norm-induced dynamics from scale-invariant linear layers and does not consider correlations in gradient magnitudes. Its applicability is limited for architectures with higher degree nonlinearities, such as Transformer models, where base gradients can vary significantly more, and attention blocks are not scale-invariant, violating the model's core assumptions (inverse scaling property and orthogonality). In real training with super-critical learning rates, auto-rate tuning effects can become too weak compared to base gradient fluctuations, causing ELRs to not converge. Numerical issues were also observed for very high learning rates during short-term validation.",
    "Future Research Directions": "Future research could extend the current model to include an error analysis for non-constant base gradients, aiming to estimate when auto-rate tuning effects might vanish due to other dynamic factors. Another potential direction is to investigate the weight dynamics of networks optimized with momentum SGD, as the current work deliberately excludes its influence to simplify the analysis.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training",
    "Main Contributions": "The paper introduces TempBalance, a novel layer-wise learning rate schedule grounded in Heavy-Tailed Self-Regularization (HT-SR) Theory. It effectively balances 'temperature' (learning rates) across network layers by analyzing the heavy-tail structure of Empirical Spectral Density (ESD) using the PL Alpha Hill metric. Key findings include improved test accuracy over ordinary SGD, spectral norm regularization (SNR), and several state-of-the-art optimizers, demonstrating that a scale-free mapping of PL Alpha Hill to learning rates and fixing λmin as the ESD median enhances stability and performance. The work also confirms the complementary roles of TempBalance and SNR for optimal training.",
    "Methodology": "TempBalance assigns layer-wise learning rates based on the PL Alpha Hill metric derived from the Empirical Spectral Density (ESD) of neural network weight matrices. It calculates eigenvalues of the correlation matrix (W^T W) for each layer and fits a power law distribution to the heavy-tail part of the ESD to extract PL Alpha Hill using the Hill estimator (with k=n/2). Layers with smaller PL Alpha are considered 'overtrained' and receive lower learning rates, while 'undertrained' layers (larger PL Alpha) get higher rates. A linear, scale-free mapping function is used to convert PL Alpha Hill values to layer-specific learning rates, scaled relative to a global base learning rate. The λmin parameter for PL fitting is fixed as the median of the ESD for stability and computational efficiency.",
    "Experimental Setup": "The method was evaluated on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using VGG (VGG16, VGG19), ResNet (ResNet18, ResNet34, ResNet101), and WideResNet (WRN16-8, WRN28-6) architectures, varying depths and widths. Baselines included ordinary SGD with Cosine Annealing Learning Rate (CAL), Spectral Norm Regularization (SNR), and state-of-the-art optimizers/schedulers like SGDR, LARS, Lookahead, SGDP, Adam, and LAMB. Hyperparameters, including initial learning rates and regularization coefficients, were carefully tuned. Validation focused on test accuracy (mean and standard deviation over five random seeds). Ablation studies were conducted on initial learning rates, model widths, different HT-SR layer-wise metrics, and PL fitting methods. Further evaluation included object detection (PASCAL VOC2007 with YOLOv8n) and language modeling (Penn TreeBank with tensorized transformer). Computational overhead was analyzed on a Quadro RTX 6000 GPU.",
    "Limitations": "The current computation of ESDs and PL Alpha Hill is performed once per epoch, leading to a minimal increase in training time (e.g., 6% for ResNet18 on CIFAR100), but could be accelerated to enable more adaptive learning rate adjustments (e.g., every few gradient updates). The current scope of HT-SR metrics applied in TempBalance is limited to layer-wise learning rate schedules, and its extension to parameter-wise or global learning rate schedules or other hyperparameters is an open question. While optimal PL Alpha values exist, the method relies on the relative ranking of layer-wise PL Alpha for learning rate assignment rather than their absolute numerical values for direct interpretation/tuning.",
    "Future Research Directions": "Future work includes extending HT-SR metrics to parameter-wise and global learning rate schedules, or other hyperparameters, to develop a more comprehensive suite of hyperparameter tuning tools. Another direction is to accelerate the computation of ESDs and PL Alpha Hill to enable a more adaptive learning rate scheduler that can adjust learning rates more frequently, potentially every few gradient updates, instead of once per epoch. Further research into layer-wise tuning approaches and the broader concept of load-temperature balancing in deep neural network training is also suggested.",
    "Experiment Code": "def net_esd_estimator(net=None,EVALS_THRESH=0.00001,bins=100,fix_fingers=None,xmin_pos=2,conv_norm=0.5, filter_zeros=False):results = {'alpha':[],'spectral_norm': [],'D': [],'longname':[],'eigs':[],'norm':[],'alphahat': []}for name, m in net.named_modules():if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):if name == 'model.22.dfl.conv':continue;matrix = m.weight.data.clone();if isinstance(m, nn.Conv2d):matrix = torch.flatten(matrix, start_dim=2) * math.sqrt(conv_norm);matrix = matrix.transpose(1, 2).transpose(0, 1);eigs = torch.square(torch.linalg.svdvals(matrix).flatten());eigs, _ = torch.sort(eigs, descending=False);spectral_norm = eigs[-1].item();fnorm = torch.sum(eigs).item();if filter_zeros:nz_eigs = eigs[eigs > EVALS_THRESH];N = len(nz_eigs);if N == 0:nz_eigs = eigs;N = len(nz_eigs);else:nz_eigs = eigs;N = len(nz_eigs);log_nz_eigs  = torch.log(nz_eigs);if fix_fingers == 'xmin_mid':i = int(len(nz_eigs) / xmin_pos);xmin = nz_eigs[i];n = float(N - i);seq = torch.arange(n).cuda();final_alpha = 1 + n / (torch.sum(log_nz_eigs[i:]) - n * log_nz_eigs[i]);final_D = torch.max(torch.abs(1 - (nz_eigs[i:] / xmin) ** (-final_alpha + 1) - seq / n));else:alphas = torch.zeros(N-1);Ds     = torch.ones(N-1);if fix_fingers == 'xmin_peak':hist_nz_eigs = torch.log10(nz_eigs);min_e, max_e = hist_nz_eigs.min(), hist_nz_eigs.max();counts = torch.histc(hist_nz_eigs, bins, min=min_e, max=max_e);boundaries = torch.linspace(min_e, max_e, bins + 1);h = counts, boundaries;ih = torch.argmax(h[0]);xmin2 = 10 ** h[1][ih];xmin_min = torch.log10(0.95 * xmin2);xmin_max = 1.5 * xmin2;for i, xmin in enumerate(nz_eigs[:-1]):if fix_fingers == 'xmin_peak':if xmin < xmin_min:continue;if xmin > xmin_max:break;n = float(N - i);seq = torch.arange(n).cuda();alpha = 1 + n / (torch.sum(log_nz_eigs[i:]) - n * log_nz_eigs[i]);alphas[i] = alpha;if alpha > 1:Ds[i] = torch.max(torch.abs(1 - (nz_eigs[i:] / xmin) ** (-alpha + 1) - seq / n));min_D_index = torch.argmin(Ds);final_alpha = alphas[min_D_index];final_D = Ds[min_D_index];final_alpha = final_alpha.item();final_D = final_D.item();final_alphahat=final_alpha*math.log10(spectral_norm);results['spectral_norm'].append(spectral_norm);results['alphahat'].append(final_alphahat);results['norm'].append(fnorm);results['alpha'].append(final_alpha);results['D'].append(final_D);results['longname'].append(name);results['eigs'].append(eigs.detach().cpu().numpy());return results;def get_layer_temps(args, temp_balance, n_alphas, epoch_val):n = len(n_alphas);idx = [i for i in range(n)];temps = np.array([epoch_val] * n);if temp_balance == 'tbr':idx = np.argsort(n_alphas);temps = [epoch_val * (args.lr_min_ratio + args.lr_slope * i / n) for i in range(n)];return [value for _, value in sorted(list(zip(idx, temps)), key=itemgetter(0))];elif temp_balance == 'tb_linear_map':lr_range = [args.lr_min_ratio * epoch_val,  (args.lr_min_ratio + args.lr_slope) * epoch_val];score_range = [min(n_alphas),  max(n_alphas)];temps = np.interp(n_alphas, score_range, lr_range);return temps;elif temp_balance == 'tb_sqrt':temps = np.sqrt(n_alphas)/np.sum(np.sqrt(n_alphas)) * n * epoch_val;return temps;elif temp_balance == 'tb_log2':temps = np.log2(n_alphas)/np.sum(np.log2(n_alphas)) * n * epoch_val;return temps;else:raise NotImplementedError;class BaseTrainer: # excerpt from ultralytics/yolo/engine/trainer.py with relevant modifications for TempBalance integration\n    # ... (lines before _setup_train in BaseTrainer) ...\n    def _setup_train(self, world_size):\n        # ... (lines before ESD analysis in _setup_train) ...\n        ###########################ESD analysis###########################\n        ##################################################################\n        dir = self.save_dir / 'stats'\n        if not os.path.exists(dir):\n            os.makedirs(dir)\n\n        filtered_layers = []\n        metrics = net_esd_estimator(self.model, \n                    EVALS_THRESH = 0.00001,\n                    bins = 100,\n                    fix_fingers=self.args.fix_fingers,\n                    xmin_pos=self.args.xmin_pos, \n                    filter_zeros = self.args.filter_zeros=='True')\n        \n        # pd.DataFrame(metrics).to_csv(os.path.join(self.save_dir, 'stats',  f\"metrics.csv\")) \n        \n        # summary and submit to wandb\n        metric_summary = {}\n        for key in metrics:\n            if key != 'eigs' and key != 'longname':\n                metric_summary[key] = np.mean(metrics[key])\n\n        #######################  Filter out layers who has little amount of eigenvalues ##########################\n        layer_with_few_eigs = []\n        for i, name in enumerate(metrics['longname']):\n            if len(metrics['eigs'][i]) <= self.args.tb_eig_filter:\n                # print(f\"layer [{name}] has {len(metrics['eigs'][i])} eigenvalues, less than or equal to {self.args.tb_eig_filter}, remove it\")\n                layer_with_few_eigs.append(name)\n\n\n        layer_stats=pd.DataFrame({key:metrics[key] for key in metrics if key!='eigs'})\n        layer_stats_origin = layer_stats.copy()\n        \n        # pd.DataFrame(layer_with_few_eigs).to_csv(os.path.join(self.save_dir, 'stats',  f\"removed layers.csv\")) \n        # layer_stats_origin.to_csv(os.path.join(self.save_dir, 'stats',  f\"origin_layer_stats_epoch_start.csv\"))\n        # np.save(os.path.join(self.save_dir, 'stats', 'esd_epoch_{0}.npy'), metrics)\n\n\n        ###################End  ESD analysis############################\n        ##################################################################\n        ######################  TBR scheduling ##########################\n        ##################################################################\n        if self.args.temp_balance_lr != 'None':\n            # print(\"--------------Enable temp balance --------------\")\n            \n            if self.args.remove_first_layer == 'True':\n                # print(\"remove first layer of alpha<---------------------\")\n                layer_stats = layer_stats.drop(labels=0, axis=0)\n                # index must be reset otherwise may delete the wrong row \n                layer_stats.index = list(range(len(layer_stats[self.args.metric])))\n            if self.args.remove_last_layer == 'True':\n                # print(\"remove last layer of alpha<---------------------\")\n                layer_stats = layer_stats.drop(labels=len(layer_stats) - 1, axis=0)\n                # index must be reset otherwise may delete the wrong row \n                layer_stats.index = list(range(len(layer_stats[self.args.metric])))\n\n            ####remove with the few eig values\n            drop_layers = layer_stats['longname'].isin(layer_with_few_eigs)\n            layer_stats = layer_stats[~drop_layers]\n            \n            metric_scores = np.array(layer_stats[self.args.metric])\n            #args, temp_balance, n_alphas, epoch_val\n            scheduled_lr = get_layer_temps(self.args, temp_balance=self.args.temp_balance_lr, n_alphas=metric_scores, epoch_val=self.args.lr0)\n            layer_stats['scheduled_lr'] = scheduled_lr\n\n            # these params should be tuned\n            layer_name_to_tune = list(layer_stats['longname'])\n            all_params = []\n            params_to_tune_ids = []\n\n            # these params should be tuned\n            for name, module in self.model.named_modules():\n                # these are the conv layers\n                if name in layer_name_to_tune:\n                    params_to_tune_ids += list(map(id, module.parameters()))\n                    scheduled_lr_item = layer_stats[layer_stats['longname'] == name]['scheduled_lr'].item()\n                    all_params.append({'params': module.parameters(), 'lr': scheduled_lr_item})\n                # decide should we tune the batch norm accordingly,  is this layer batchnorm and does its corresponding conv in layer_name_to_tune\n                elif self.args.batchnorm == 'True' \\\n                        and isinstance(module, nn.BatchNorm2d) \\\n                            and name.replace('bn', 'conv') in layer_name_to_tune:\n                    params_to_tune_ids += list(map(id, module.parameters()))\n                    scheduled_lr_item = layer_stats[layer_stats['longname'] == name.replace('bn', 'conv')]['scheduled_lr'].item()\n                    all_params.append({'params': module.parameters(), 'lr': scheduled_lr_item})\n                # another way is to add a else here and append params with self.args.lr0\n\n            # those params are untuned\n            untuned_params = filter(lambda p: id(p) not in params_to_tune_ids, self.model.parameters())\n            all_params.append({'params': untuned_params, 'lr': self.args.lr0}) \n\n            # create optimizer\n            if self.args.optim_type == 'SGDP':\n                # print(f\"---->>>> Initialze the SGDP with lr {self.args.lr0}  {weight_decay}\")\n                optimizer = SGDP(all_params, \n                            lr=self.args.lr0,  \n                            momentum=0.9, \n                            weight_decay=weight_decay)\n            elif self.args.optim_type == 'SNR':\n                optimizer = SGDSNR(all_params, \n                                    momentum=0.9, \n                                    weight_decay=weight_decay, \n                                    spectrum_regularization=self.args.sg,\n                                    stage_epoch=self.args.stage_epoch,\n                                    epoch=1)\n            elif self.args.optim_type == 'SGD':\n                optimizer = optim.SGD(all_params, \n                                    lr=self.args.lr0,  \n                                    momentum=0.9, \n                                    weight_decay=weight_decay) \n            elif self.args.optim_type == 'Adam':\n                optimizer = optim.Adam(all_params, \n                                    lr=self.args.lr0,  \n                                    weight_decay=weight_decay) \n            elif self.args.optim_type == 'AdamW':\n                optimizer = optim.AdamW(all_params, \n                                    lr=self.args.lr0,  \n                                    weight_decay=weight_decay) \n            else:\n                raise NotImplementedError\n        else:\n            # print(\"-------------> Disable temp balance\")\n            if self.args.optim_type == 'SNR':\n                optimizer = SGDSNR(self.model.parameters(), \n                                    momentum=0.9, \n                                    lr=self.args.lr0,  \n                                    weight_decay=weight_decay, \n                                    spectrum_regularization=self.args.sg,\n                                    stage_epoch=self.args.stage_epoch,\n                                    epoch=1)\n            elif self.args.optim_type == 'SGD':\n                optimizer = optim.SGD(self.model.parameters(), \n                                    lr=self.args.lr0,  \n                                    momentum=0.9, \n                                    weight_decay=weight_decay) \n            elif self.args.optim_type == 'Adam':\n                optimizer = optim.Adam(self.model.parameters(), \n                                    lr=self.args.lr0,  \n                                    weight_decay=weight_decay) \n            elif self.args.optim_type == 'AdamW':\n                optimizer = optim.AdamW(self.model.parameters(), \n                                    lr=self.args.lr0,  \n                                    weight_decay=weight_decay) \n            else:\n                raise NotImplementedError\n\n            \n        # save scheduled learning rate \n        # layer_stats.to_csv(os.path.join(self.save_dir, 'stats', f\"layer_stats_with_lr_epoch_{0}.csv\"))\n\n        #########################################################################\n\n        # ... (lines for self.optimizer, self.lf, self.scheduler, self.stopper, self.train_loader, self.test_loader, self.validator, self.ema) ...\n\n\n    def _do_train(self, world_size=1):\n        # ... (lines before epoch loop) ...\n        for epoch in range(self.start_epoch, self.epochs):\n            self.epoch = epoch\n            # self.run_callbacks('on_train_epoch_start')\n\n            # consider use another (maybe bigger) minimum learning rate in tbr\n            if self.args.stage_epoch > 0 and epoch >= self.args.stage_epoch:\n                # print(\"------> Enter the second stage!!!!!!!!!!\")\n                self.args.lr0_min_ratio = self.args.lr0_min_ratio_stage2\n            else:\n                pass\n            \n            # this is current LR\n            current_lr = self.untuned_lr\n            # print(f\"##############Epoch {epoch+1}  current LR: {current_lr:.8f}################\")\n\n            ####################start training#####################\n            self.model.train()\n            if RANK != -1:\n                self.train_loader.sampler.set_epoch(epoch)\n            pbar = enumerate(self.train_loader)\n            # Update dataloader attributes (optional)\n            if epoch == (self.epochs - self.args.close_mosaic):\n                # LOGGER.info('Closing dataloader mosaic')\n                if hasattr(self.train_loader.dataset, 'mosaic'):\n                    self.train_loader.dataset.mosaic = False\n                if hasattr(self.train_loader.dataset, 'close_mosaic'):\n                    self.train_loader.dataset.close_mosaic(hyp=self.args)\n                self.train_loader.reset()\n\n            if RANK in (-1, 0):\n                # LOGGER.info(self.progress_string())\n                pbar = tqdm(enumerate(self.train_loader), total=nb, bar_format=TQDM_BAR_FORMAT)\n            self.tloss = None\n            self.optimizer.zero_grad()\n            for i, batch in pbar:\n                # self.run_callbacks('on_train_batch_start')\n                # Warmup\n                ni = i + nb * epoch\n                # ... (warmup code) ...\n\n                # Forward\n                with torch.cuda.amp.autocast(self.amp):\n                    batch = self.preprocess_batch(batch)\n                    preds = self.model(batch['img'])\n                    self.loss, self.loss_items = self.criterion(preds, batch)\n                    if RANK != -1:\n                        self.loss *= world_size\n                    self.tloss = (self.tloss * i + self.loss_items) / (i + 1) if self.tloss is not None \\\n                        else self.loss_items\n\n                # Backward\n                self.scaler.scale(self.loss).backward()\n\n                # Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\n                if ni - last_opt_step >= self.accumulate:\n                    self.optimizer_step()\n                    last_opt_step = ni\n\n                # Log            \n                # mem = f'{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}G'  # (GB)\n                # loss_len = self.tloss.shape[0] if len(self.tloss.size()) else 1\n                # losses = self.tloss if loss_len > 1 else torch.unsqueeze(self.tloss, 0)\n                if RANK in (-1, 0):\n                    # pbar.set_description(\n                    #     ('%11s' * 2 + '%11.4g' * (2 + loss_len)) %\n                    #     (f'{epoch + 1}/{self.epochs}', mem, *losses, batch['cls'].shape[0], batch['img'].shape[-1]))\n                    self.run_callbacks('on_batch_end')\n                    if self.args.plots and ni in self.plot_idx:\n                        self.plot_training_samples(batch, ni)\n\n                # self.run_callbacks('on_train_batch_end')\n\n            self.lr = {f'lr/pg{ir}': x['lr'] for ir, x in enumerate(self.optimizer.param_groups)}  # for loggers\n\n            self.scheduler.step()\n            # self.run_callbacks('on_train_epoch_end')\n            ########epoch end#############\n\n            if RANK in (-1, 0):\n\n                # Validation\n                self.ema.update_attr(self.model, include=['yaml', 'nc', 'args', 'names', 'stride', 'class_weights'])\n                final_epoch = (epoch + 1 == self.epochs) or self.stopper.possible_stop\n\n                if self.args.val or final_epoch:\n                    self.metrics, self.fitness = self.validate()\n                self.save_metrics(metrics={**self.label_loss_items(self.tloss), **self.metrics, **self.lr})\n                self.stop = self.stopper(epoch + 1, self.fitness)\n\n                # Save model\n                if self.args.save or (epoch + 1 == self.epochs):\n                    self.save_model()\n                    self.run_callbacks('on_model_save')\n                 # save in interval\n                # state = {\n                    \n                #         'net': self.model.state_dict(),\n                #         'precision': self.metrics['metrics/precision(B)'],\n                #         'recall': self.metrics['metrics/recall(B)'],\n                #         'mAP50': self.metrics['metrics/mAP50(B)'],\n                #         'mAP': self.metrics['metrics/mAP50-95(B)'],\n                #         'epoch':epoch\n                #     }\n                # #torch.save(state, os.path.join(self.save_dir, 'stats', f'epoch_{epoch}.ckpt'))\n                # # save best\n                # if self.best_fitness == self.fitness:\n                #     # print('| Saving Best model')\n                #     state = {\n                #         'net': self.model.state_dict(),\n                #         'optimizer': self.optimizer.state_dict(),\n                #         'precision': self.metrics['metrics/precision(B)'],\n                #         'recall': self.metrics['metrics/recall(B)'],\n                #         'mAP50': self.metrics['metrics/mAP50(B)'],\n                #         'mAP': self.metrics['metrics/mAP50-95(B)'],\n                #         'epoch':epoch\n                #     }\n                # #    torch.save(state, os.path.join(self.save_dir, 'stats', f'epoch_best.ckpt'))\n\n                \n            #######################ESD analysis###############################\n            ##################################################################\n            self.model.eval()\n\n            if self.epoch == 1 or self.epoch % self.args.ww_interval == 0:\n                # print(\"------------ Start ESD analysis -----------\")\n                # a=datetime.now() \n                model_input = self.model\n\n\n                metrics = net_esd_estimator(model_input, \n                            EVALS_THRESH = 0.00001,\n                            bins = 100,\n                            fix_fingers=self.args.fix_fingers,\n                            xmin_pos=self.args.xmin_pos,\n                            filter_zeros=self.args.filter_zeros=='True')\n                \n                metric_summary = {}\n                for key in metrics:\n                    if key != 'eigs' and key != 'longname':\n                        metric_summary[key] = np.mean(metrics[key])\n\n                \n                #######################  Filter out layers who has little amount of eigenvalues ##########################\n                layer_with_few_eigs = []\n                for i, name in enumerate(metrics['longname']):\n                    if len(metrics['eigs'][i]) <= self.args.tb_eig_filter:\n                        # print(f\"layer [{name}] has {len(metrics['eigs'][i])} eigenvalues, less than or equal to {self.args.tb_eig_filter}, remove it\")\n                        layer_with_few_eigs.append(name)\n\n\n                layer_stats=pd.DataFrame({key:metrics[key] for key in metrics if key!='eigs'})\n                \n                # save metrics to disk and ESD\n                layer_stats_origin = layer_stats.copy()\n                # layer_stats_origin.to_csv(os.path.join(self.save_dir, 'stats',  f\"origin_layer_stats_epoch_{epoch}.csv\"))\n                # np.save(os.path.join(self.save_dir, 'stats', f'esd_epoch_{epoch}.npy'), metrics)\n                # if self.best_fitness == self.fitness:\n                #     np.save(os.path.join(self.save_dir, 'stats',f'esd_best.npy'), metrics)\n\n                # b=datetime.now() \n                # print('seconds:', (b-a).seconds)\n                ###################End  ESD analysis#############\n            else:\n                metric_summary = {}\n\n            ##################################################################\n            # Reschedule the learning rate\n            self.untuned_lr = self.lr_schedule(self.args.lr0, epoch=self.epoch, total_epoch=self.epochs, warmup_epochs=self.args.warmup_epochs)\n            # print(f\"------------>Rescheduled decayed LR: {self.untuned_lr:.8f}<--------------------\")\n\n            if self.args.temp_balance_lr != 'None':\n                ######################  TBR scheduling ##########################\n                ##################################################################\n\n                # print(\"---------- Schedule by Temp Balance---------------\")\n                assert len(metric_summary) > 0, \"in TBR, every epoch should has an updated metric summary\"\n                if self.args.remove_first_layer == 'True':\n                    # print('remove first layer <--------------------')\n                    layer_stats = layer_stats.drop(labels=0, axis=0)\n                    # index must be reset otherwise next may delete the wrong row \n                    layer_stats.index = list(range(len(layer_stats[self.args.metric])))\n                if self.args.remove_last_layer == 'True':\n                    # print('remove last layer <--------------------')\n                    layer_stats = layer_stats.drop(labels=len(layer_stats) - 1, axis=0)\n                    # index must be reset otherwise may delete the wrong row \n                    layer_stats.index = list(range(len(layer_stats[self.args.metric])))\n                \n                ####remove with the few eig values\n                drop_layers = layer_stats['longname'].isin(layer_with_few_eigs)\n                layer_stats = layer_stats[~drop_layers]\n\n                metric_scores = np.array(layer_stats[self.args.metric])\n                scheduled_lr = get_layer_temps(self.args, self.args.temp_balance_lr, metric_scores, self.untuned_lr)\n                layer_stats['scheduled_lr'] = scheduled_lr\n                layer_name_to_tune = list(layer_stats['longname'])\n                all_params_lr = []\n                c = 0\n                \n                #####check the few eig values layers were removed\n                for name, module in self.model.named_modules():\n                    if name in layer_name_to_tune:\n                        assert name not in layer_with_few_eigs\n\n\n                for name, module in self.model.named_modules():\n                    if name in layer_name_to_tune:\n                        # params_to_tune_ids += list(map(id, module.parameters()))\n                        scheduled_lr_item = layer_stats[layer_stats['longname'] == name]['scheduled_lr'].item()\n                        all_params_lr.append(scheduled_lr_item)\n                        c = c + 1\n                    elif self.args.batchnorm == 'True' \\\n                        and isinstance(module, nn.BatchNorm2d) \\\n                            and name.replace('bn', 'conv') in layer_name_to_tune:\n                        # params_to_tune_ids += list(map(id, module.parameters()))\n                        scheduled_lr_item = layer_stats[layer_stats['longname'] == name.replace('bn', 'conv')]['scheduled_lr'].item()\n                        all_params_lr.append(scheduled_lr_item)\n                        c = c + 1\n\n                # layer_stats.to_csv(os.path.join(self.save_dir, 'stats', f\"layer_stats_with_lr_epoch_{self.epoch}.csv\"))\n                # if self.best_fitness == self.fitness:\n                #     layer_stats.to_csv(os.path.join(self.save_dir, 'stats', f\"layer_stats_with_lr_epoch_best.csv\"))\n                for index, param_group in enumerate(self.optimizer.param_groups):\n                    #param_group['epoch'] = param_group['epoch'] + 1\n                    if index <= c - 1:\n                        param_group['lr'] = all_params_lr[index]\n                    else:\n                        param_group['lr'] = self.untuned_lr\n            ##################################################################\n            ##################################################################\n            else:\n                # print(\"------------>  Schedule by default\")\n                for param_group in self.optimizer.param_groups:\n                    #param_group['epoch'] = param_group['epoch'] + 1\n                    param_group['lr'] = self.untuned_lr\n\n            # tnow = time.time()\n            # self.epoch_time = tnow - self.epoch_time_start\n            # self.epoch_time_start = tnow\n            # self.elapsed_time += self.epoch_time\n            # print('| Elapsed time : %d:%02d:%02d'  %(cf.get_hms(self.elapsed_time)))\n            # print('--------------------> <-----------------')\n            # self.run_callbacks('on_fit_epoch_end')\n            # torch.cuda.empty_cache()  # clears GPU vRAM at end of epoch, can help with out of memory errors\n\n            # Early Stopping\n            if RANK != -1:  # if DDP training\n                broadcast_list = [self.stop if RANK == 0 else None]\n                dist.broadcast_object_list(broadcast_list, 0)  # broadcast 'stop' to all ranks\n                if RANK != 0:\n                    self.stop = broadcast_list[0]\n            if self.stop:\n                break  # must break all DDP ranks\n            \n            # print(\"################ END Epoch#############\")\n        #########epoch circle end#############\n        # if RANK in (-1, 0):\n        #     # Do final val with best.pt\n        #     LOGGER.info(f'\\n{epoch - self.start_epoch + 1} epochs completed in '\n        #                 f'{(time.time() - self.train_time_start) / 3600:.3f} hours.')\n            \n        #     float_array = [epoch - self.start_epoch + 1, (time.time() - self.train_time_start)]\n        #     df = pd.DataFrame({\"Float Values\": float_array})\n        #     csv_file_path = \"end_time.csv\"\n        #     df.to_csv(os.path.join(self.save_dir, 'stats', csv_file_path))\n\n        #     self.final_eval()\n        #     if self.args.plots:\n        #         self.plot_metrics()\n        #     self.run_callbacks('on_train_end')\n        # torch.cuda.empty_cache()\n        # self.run_callbacks('teardown')",
    "Experiment Result": "Method: TempBalance dynamically adjusts layer-wise learning rates based on the PL Alpha Hill metric derived from the Empirical Spectral Density (ESD) of neural network weight matrices. The method calculates eigenvalues of the correlation matrix (W^T W) for each `nn.Conv2d` and `nn.Linear` layer.\n\nExperimental Settings:\n- **PL Alpha Hill Metric**: The `alpha` value extracted from the power law fit is used as the metric to assign learning rates.\n- **Power Law Fitting**: The Hill estimator is used, with `\nmin` fixed as the median of the Empirical Spectral Density (ESD). This corresponds to `fix_fingers='xmin_mid'` and `xmin_pos=2`.\n- **Learning Rate Assignment Function**: A linear, scale-free mapping (`temp_balance_lr='tb_linear_map'`) is used to convert PL Alpha values to layer-specific learning rates.\n  - Layers with smaller PL Alpha (considered 'overtrained') receive lower learning rates.\n  - Layers with larger PL Alpha (considered 'undertrained') receive higher learning rates.\n- **Layer-wise Learning Rate Range**: Determined relative to a global base learning rate (`lr0`). The range is bounded by `lr_min_ratio` and `lr_slope`. Default values from `runtrain.py` are `lr_min_ratio=0.0` and `lr_slope=0.0` (which would imply all tuned layers get `0.0 * lr0` unless specifically overridden).\n- **Layers Excluded from Tuning**: \n  - The first layer (`remove_first_layer=True`).\n  - The last layer (`remove_last_layer=True`).\n  - Layers with a number of eigenvalues less than or equal to a threshold (`tb_eig_filter=64`).\n- **Batch Normalization Layers**: Learning rates for `nn.BatchNorm2d` layers are adjusted to correspond to their preceding `nn.Conv2d` or `nn.Linear` layers (`batchnorm=True`).\n- **ESD Analysis Frequency**: ESD analysis and subsequent learning rate rescheduling are performed every `ww_interval=1` epoch.\n- **Stage-wise Learning Rate Adjustment**: If `stage_epoch` is set and the current epoch surpasses it, `lr_min_ratio` can be updated to `lr_min_ratio_stage2` (default 1).\n- **Eigenvalue Threshold for Filtering**: `EVALS_THRESH=0.00001` to filter near-zero eigenvalues. `filter_zeros=False` by default, meaning small eigenvalues are generally not filtered before fitting, unless `tb_eig_filter` applies."
}{
    "Title": "AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly",
    "Main Contributions": "The paper introduces AutoLRS, an automatic and efficient method for tuning learning rate (LR) schedules in deep neural network (DNN) training, eliminating significant manual effort and computational cost. AutoLRS achieves this by optimizing the LR for each training stage using on-the-fly Bayesian Optimization (BO). To make BO computationally feasible, it employs a lightweight exponential time-series forecasting model to predict validation loss after a full stage based on short initial training steps. AutoLRS demonstrated speedups of 1.22x for ResNet-50, 1.43x for Transformer, and 1.5x for BERT compared to their original hand-tuned schedules, and an average speedup of 1.31x over heavily-tuned state-of-the-art schedules like CLR and SGDR, while maintaining or improving test-set performance.",
    "Methodology": "AutoLRS divides DNN training into stages of 'τ' steps, seeking to find a constant LR 'η' for each stage that minimizes validation loss. This is treated as a black-box optimization problem solved by Bayesian Optimization (BO). BO uses a Gaussian Process (GP) with a Matern kernel as a surrogate model to infer the objective function's posterior, and then selects the next LR to evaluate by minimizing the Lower Confidence Bound (LCB) acquisition function (µ(η) - κσ(η), with κ=1000). To reduce BO's computational cost (which would typically require 'τ' steps per evaluation), AutoLRS only runs each candidate LR for 'τ'' << 'τ' steps (e.g., τ/10). The validation loss observed during these 'τ'' steps is used to train a simple exponential time-series forecasting model (L(t) = a*exp(b*t) + c) to predict the validation loss after 'τ' steps. An iterative spline smoothing pre-processes the loss series for stable fitting. BO and the forecasting model operate in a mutual training loop. Practical improvements include gradually increasing 'τ' and 'τ'' over training (starting at 1000/100, doubling until τ_max) and minimizing training loss in early stages (or a small validation subset in later stages) to reduce validation cost. Model states are checkpointed and restored for each LR evaluation within a stage to ensure fair comparison.",
    "Experimental Setup": "AutoLRS was evaluated on three representative DNNs: ResNet-50 for ImageNet classification (SGD with momentum, 32 NVIDIA Tesla V100 GPUs, mini-batch size 1024), Transformer for WMT 2014 English-German Neural Machine Translation (Adam, 8 NVIDIA Tesla V100 GPUs), and BERTBASE for pre-training (Adam with L2 weight decay, mixed precision, 32 NVIDIA Tesla V100 GPUs, mini-batch size 1024) and subsequent fine-tuning on MRPC, MNLI, CoLA, and SQuAD v1.1 NLP tasks. Ablation studies and comparisons with prior methods (Hypergradient Descent, MARTHE, Hyperband) were conducted using VGG-16 and ResNet-50 on CIFAR-10/CIFAR-100 (SGD, NVIDIA Titan RTX GPU, mini-batch size 128). Baselines included original paper's hand-tuned LR schedules, and heavily hand-tuned Cyclical Learning Rate (CLR) and Stochastic Gradient Descent with Warm Restarts (SGDR). Performance was measured by training steps to reach target accuracy/BLEU score, and final validation/test accuracy or F1 scores. AutoLRS hyperparameters were typically k=10, τ'=τ/10, κ=1000, initial τ=1000, τ'=100 doubling to τ_max (8000 for ResNet-50/Transformer, 32000 for BERT), with LR search intervals set using an LR range test.",
    "Limitations": "AutoLRS still requires setting several hyperparameters, including the number of LRs to evaluate by BO (k), the short evaluation steps (τ'), the maximum stage length (τ_max), the trade-off weight in the acquisition function (κ), and the initial LR search interval (η_min, η_max). While defaults often work and τ_max sensitivity is tested, these still represent tuning points. The method does not automatically tune the initial 'warmup' phase of training, which is still handled separately. The efficacy of the exponential forecasting model relies on the assumption that validation loss generally decreases exponentially and converges, which may not hold universally, especially during transient non-monotonic loss behaviors, although pre-processing helps mitigate this. The computational overhead, while significantly reduced compared to full BO, is still approximately twice the training cost of the final schedule.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": "File Path: autolrs_callback.py\nContent:\nimport torch\nimport os\nimport logging\nimport socket\nimport string\nimport random\nimport time\n\nclass AutoLRS():\n    def __init__(self, model, optimizer, val_fn, listening_host='localhost', listening_port=12315, warmup_steps=0, warmup_lr=0, summary_steps=1):\n        self._net = model\n        self._optimizer = optimizer\n        self._val_fn = val_fn \n        self._lr = 0.000001\n        self._warmup_steps = warmup_steps\n        self._warmup_lr = warmup_lr \n        self._global_step = 0\n        self._socket = socket.socket()\n        self._started = False\n        self._summary_steps = summary_steps\n        self._checkpoint_path = './checkpoint/autolrs_ckpt_' + ''.join(random.choices(string.ascii_uppercase + string.digits, k = 7))  + '.pth'\n        self._listening_host = listening_host\n        self._listening_port = listening_port\n        self._best_acc = 0\n\n        if not os.path.exists('checkpoint'):\n            os.makedirs('checkpoint')\n\n        self.connect_server()\n    \n    def connect_server(self):\n        self._socket.connect((self._listening_host, self._listening_port))\n\n    def _verbose_operation(self, _op):\n        if self._global_step % self._summary_steps == 0:\n            logging.info(\"[AutoLRS at {}] {}\".format(self._global_step, _op))\n\n    def save_variables(self):\n        \"\"\"Save model parameters and optimizer states.\"\"\"\n        _start_time = time.time()\n        torch.save({\n            'model_state_dict': self._net.state_dict(),\n            'optimizer_state_dict': self._optimizer.state_dict()\n            }, self._checkpoint_path)\n        logging.info(\"[AutoLRS] backup variables, elapsed: {}s\".format(time.time() - _start_time))\n\n    def restore_variables(self):\n        _start_time = time.time()\n        checkpoint = torch.load(self._checkpoint_path)\n        self._net.load_state_dict(checkpoint['model_state_dict'])\n        self._optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        logging.info(\"[AutoLRS] restoring variables, elapsed: {}s\".format(time.time() - _start_time))\n\n    def on_train_batch_end(self, loss):\n        if self._global_step < self._warmup_steps:\n            # linear warmup\n            self._lr = (self._warmup_lr / self._warmup_steps) * (self._global_step + 1)\n            for param_group in self._optimizer.param_groups:\n            \tparam_group['lr'] = self._lr\n            self._global_step += 1\n\n        elif not self._started:\n            self.save_variables()\n            print(\"backup trainable variables to CPU\") \n            self._started = True\n            self._socket.send(\",\".join(('startBO', str(loss))).encode(\"utf-8\"))\n            self._verbose_operation(\"Start Bayesian Optimization(BO)\")\n            data = self._socket.recv(1024).decode(\"utf-8\")\n            self._verbose_operation(\"Received data: \" + data)\n            self._lr = (float(data.split(\",\")[-1]))\n            for param_group in self._optimizer.param_groups:\n            \tparam_group['lr'] = self._lr\n        else:\n            self._socket.send(','.join(('loss', str(loss))).encode('utf-8'))\n            data = self._socket.recv(1024).decode(\"utf-8\")\n            self._verbose_operation(\"Received data: \" + data)\n            if data.startswith(\"restore\"):\n                self.restore_variables()\n                self._verbose_operation(\"restore trainable variables\")\n            elif data.startswith(\"ckpt\"):\n                self.save_variables()\n                self._verbose_operation(\"backup trainable variables\")\n            elif data.startswith('evaluate'):\n                val_loss = self._val_fn()\n                self._socket.send(\",\".join((\"val_loss\", str(val_loss))).encode(\"utf-8\"))\n                data = self._socket.recv(1024).decode(\"utf-8\")\n            elif data.startswith('save'):\n                pass\n            else:\n                self._lr = (float(data.split(\",\")[-1]))\n                for param_group in self._optimizer.param_groups:\n                    param_group['lr'] = self._lr\n                self._global_step += 1\n\nFile Path: autolrs_server.py\nContent:\nimport argparse\nimport socket                \nimport random\nimport numpy as np \nimport threading\nimport time\nimport math\nimport os\nfrom skopt import Optimizer\nfrom skopt.space import Real\nfrom scipy.interpolate import UnivariateSpline\nfrom scipy import optimize \nimport sys\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\ndef f(b, x, y):\n    A = np.vstack([np.exp(-np.exp(b) * x), np.ones(len(x))]).T\n    res = np.linalg.lstsq(A, y, rcond=None)[1]\n    return res\n\ndef spline_iter(xs, ys, is_training, spline_deg=2, filter_ratio=0.03, num_of_iter=10, bound=0.5):\n    \"\"\" Use iterative spline to eliminate noise and outliers in the loss series.\n        is_training specifies whether the loss series in use is training loss or validation loss.\n    \"\"\"\n    bound = xs[int((len(xs) - 1) * bound)]\n    if is_training:\n        num_of_iter = 10\n    else:\n        num_of_iter = 1\n\n    for _ in range(num_of_iter):\n        spline_ys = UnivariateSpline(xs, ys, k=spline_deg)(xs)\n        dys = np.abs(ys - spline_ys)\n\n        if is_training:\n            outliers = set(sorted(range(len(dys)), key=lambda i: dys[i])[int(round(-len(dys) * filter_ratio)):])\n        else:\n            outliers = set(sorted(range(len(dys)), key=lambda i: dys[i])[-1:])\n        outliers = [i for i in outliers if i < bound]\n\n        xs2 = np.zeros(len(xs) - len(outliers))\n        ys2 = np.zeros(len(xs) - len(outliers))\n        i1 = 0\n        for i2 in range(len(xs)):n            if i2 not in outliers:\n                xs2[i1], ys2[i1] = xs[i2], ys[i2]\n                i1 += 1\n        xs, ys = xs2, ys2\n    return xs, ys\n\ndef exp_forecast(loss_series, end_step, is_training, spline_order=2):\n    \"\"\" Do exponential forecasting on a loss series.\"\"\"\n    xs = np.arange(end_step - len(loss_series), end_step)\n    xs2, ys2 = spline_iter(xs, loss_series, is_training)\n    ys = UnivariateSpline(xs2, ys2, k=spline_order)(xs)\n    logging.debug('ys after spline iter: {}'.format(ys))\n    b = optimize.fmin(f, 0, args=(xs, ys), xtol=1e-5, ftol=1e-5, disp=False)[0]\n    b = -np.exp(b)\n    A = np.vstack([np.exp(b * xs), np.ones(len(xs))]).T\n    a, c = np.linalg.lstsq(A, ys, rcond=None)[0]\n    return a, b, c\n\nclass RingBuffer:\n    \"\"\" A class for storing and manipulating loss series and do exponential forecasting. \"\"\"\n\n    def __init__(self, size):\n        self.data = [None for i in range(size)]\n\n    def reset(self):\n        self.data = [None for i in self.data]\n\n    def append(self, x):\n        self.data.pop(0)\n        self.data.append(x)\n\n    def get(self):\n        return self.data\n\n    def average(self):\n        return sum(self.data)/len(self.data)\n\n    def exponential_forcast(self, pred_index, is_training):\n        loss_series = self.data[:]\n        end_epoch = len(loss_series)\n        x = np.arange(end_epoch - len(loss_series), end_epoch)\n        y = np.array(loss_series)\n        a3, b3, c3 = exp_forecast(y, len(y), is_training)\n        forcast_y = a3 * np.exp(b3 * pred_index) + c3\n        logging.debug(\"Exponential fit: {}, {}, {}\".format(a3, b3, c3))\n        return forcast_y\n\nclass Controller(object):\n    def __init__(self, host, port, min_lr, max_lr):\n        # Constants\n        EXPLOITATION_STEP = 1000\n        LR_STEPS = 100\n        RING_BUFFER_LEN = 100\n        LR_TO_EXPLORE = 10\n        TAU_MAX = 8000\n\n        self.min_lr = float(min_lr)\n        self.max_lr = float(max_lr)\n        self.host = host\n        self.port = port\n        self.threads = []\n        self.num_threads = 1\n        self.event = threading.Event()\n        self.sock = socket.socket()\n        self.sock.bind((self.host, self.port))\n        self.global_step = 0\n        self.last_total_loss = 0.0\n        self.average_loss = 0.0\n        self.loss_vector = []\n        self.lr = 0\n        self.lr_steps = LR_STEPS \n        self.tau_max = TAU_MAX\n        self.val_freq = int(self.lr_steps/16)\n        self.lr_counter = 0\n        self.lr_to_explore = LR_TO_EXPLORE\n        self.BO_stage = True\n        self.val_stage = False\n        self.message = ''\n        self.loss_after_exploitation = None\n        self.ring_buffer_len = RING_BUFFER_LEN\n        if self.val_stage:\n            self.ring_loss_buffer = RingBuffer(self.ring_buffer_len // self.val_freq)\n        else:\n            self.ring_loss_buffer = RingBuffer(self.ring_buffer_len)\n\n        self.exploitation_step = EXPLOITATION_STEP\n        self.exploitation_flag = False \n        self.exploitation_counter = 0\n        \n        self.opt = None\n        self.x_func_dict = dict()\n        self.x_iters = []\n        self.func_val_iters = []\n\n        self.num_ranks = 0\n        self.finished_minions = 0\n        self.lock1 = threading.Lock()\n        self.lock2 = threading.Lock()\n\n    def listen(self):\n        self.sock.listen(20)\n        while True:\n            client, address = self.sock.accept()\n            logging.info('[Server]: Got connection from {}'.format(address))\n            self.threads.append(threading.Thread(target = self.run, args = (client, address, self.event)))\n            if len(self.threads) == self.num_threads:\n                self.num_ranks = len(self.threads)\n                self.num_minions = self.num_ranks - 1\n                logging.info('[Server]: num_ranks: {}'.format(self.num_ranks))\n                for thread in self.threads:\n                    thread.start()\n                logging.info('[Server]: threads started')\n                for thread in self.threads:\n                    thread.join()\n                    self.threads = []\n                logging.info('[Server]: join finished')\n                sys.exit()\n\n    def run(self, c, address, event):\n        size = 1024\n        while True:\n            data = c.recv(size).decode()\n            if not data:\n                sys.exit()\n            logging.debug(data.split(','))\n            total_loss = float(data.split(',')[-1])\n            self.lock2.acquire()\n            self.loss_vector.append(total_loss)\n\n            # compute average loss across ranks\n            if len(self.loss_vector) == self.num_ranks:\n                self.average_loss = sum(self.loss_vector) / len(self.loss_vector) \n                logging.info('[Server]: average loss = {}, step = {}'.format(self.average_loss, self.global_step))\n                if self.val_stage:\n                    if 'val' in data:\n                        self.ring_loss_buffer.append(self.average_loss)\n                    else:\n                        self.global_step += 1\n                else:\n                    self.ring_loss_buffer.append(self.average_loss)\n                    self.global_step += 1\n                self.loss_vector = []\n            self.lock2.release()\n\n            if 'val' in data:\n                c.send(str(self.lr).encode('utf-8')) \n                continue\n\n            if 'minion' in data:\n                # blocking\n                event_is_set = event.wait()\n                c.send(self.message.encode('utf-8')) \n                logging.debug('[Server] message: %s', self.message)\n                self.lock1.acquire()\n                self.finished_minions += 1\n                self.lock1.release()\n                if self.finished_minions == self.num_minions:\n                    event.clear()\n                    self.finished_minions = 0\n                continue\n\n            else:\n                if data.startswith('startBO'):\n                    self.last_total_loss = self.average_loss\n                    self.init_loss = self.average_loss\n                    self.loss_after_exploitation = self.average_loss\n\n                # exploitation stage -- actual training stage using the best-found LR\n                if self.exploitation_flag:\n                    logging.debug('[Server exploitation]: average loss ' + str(self.average_loss) + ' step=' + str(self.global_step))\n                    if self.exploitation_counter == self.exploitation_step:\n                        self.BO_stage = True\n                        self.exploitation_flag = False\n                        self.exploitation_counter = 0\n                        logging.info('[Server]: exploitation stage done')\n                        logging.info('[Server]: reconfigure...')\n                        if self.lr_steps < self.tau_max / 10:\n                            self.lr_steps = self.lr_steps * 2\n                            self.val_freq = int(self.lr_steps/16)\n                            self.ring_buffer_len = self.lr_steps \n                            self.exploitation_step = self.exploitation_step * 2\n                            self.ring_loss_buffer = RingBuffer(self.ring_buffer_len)\n                        else:\n                            self.val_stage = True\n                        if self.val_stage:\n                            self.ring_loss_buffer = RingBuffer(self.ring_buffer_len // self.val_freq)\n                        self.loss_after_exploitation = self.average_loss\n\n                        self.message = 'save'\n                        c.send(self.message.encode('utf-8'))\n                        event.set()\n                        continue\n\n                    else:\n                        self.exploitation_counter += 1\n                        self.message = str(self.lr)\n                        c.send(str(self.lr).encode('utf-8')) \n                        event.set()\n                        continue\n\n                # BO stage -- LR search stage\n                if self.BO_stage:\n                    self.opt = Optimizer([Real(self.min_lr, self.max_lr, 'log-uniform')], \"GP\", n_initial_points=1, acq_func='LCB', acq_func_kwargs={'kappa':1e6})\n                    self.BO_stage = False\n                    self.lr = self.opt.ask()[0]\n\n                    # prevent BO in scikit-optimize from searching for the same LR explored before\n                    while True:\n                        if self.lr in self.x_func_dict:\n                            self.opt.tell([self.lr], self.x_func_dict[self.lr])\n                            self.lr = self.opt.ask()[0]\n                        else:\n                            break\n\n                    self.message = str(','.join(('ckpt', str(self.lr))))\n                    c.send(','.join(('ckpt', str(self.lr))).encode('utf-8'))\n                    event.set()\n                    logging.debug('[Server]: checkpoint command sent')\n                    continue\n\n                # ask BO to suggest the next LR \n                if self.lr_counter == self.lr_steps:\n                    logging.debug('ring_buffer: {}'.format(self.ring_loss_buffer.get()))\n                    if any([math.isnan(x) for x in self.ring_loss_buffer.get()]):\n                        predicted_loss = \"nan\"\n                    elif self.val_stage:\n                        predicted_loss = self.ring_loss_buffer.exponential_forcast(pred_index=int(self.exploitation_step/self.val_freq), is_training=False)\n                        current_loss = sum(self.ring_loss_buffer.get()[-1:])/1.0\n                    else:\n                        predicted_loss = self.ring_loss_buffer.exponential_forcast(pred_index=self.exploitation_step, is_training=True)\n                        current_loss = sum(self.ring_loss_buffer.get()[-10:])/10.0\n\n                    logging.info('[Server]: predicted loss: {} due to LR {}'.format(predicted_loss, self.lr))\n\n                    # Huge loss jump can make the exponential prediction inaccurate, so set a threshold here. \n                    #if self.loss_after_exploitation is not None and max(self.ring_loss_buffer.get()) > 10 * self.loss_after_exploitation:\n                    #    predicted_loss = current_loss \n                    #    logging.info('New predicted_loss: ' + str(predicted_loss))\n\n                    if self.loss_after_exploitation is not None and max(self.ring_loss_buffer.get()) >= 1.0 * self.init_loss and self.val_stage:\n                        predicted_loss = current_loss \n                        logging.info('[Server]: New predicted_loss: ' + str(predicted_loss))\n\n                    if self.val_stage:\n                        self.ring_loss_buffer = RingBuffer(int(math.floor(self.ring_loss_buffer_len)/self.val_freq))\n                    else:\n                        self.ring_loss_buffer = RingBuffer(self.ring_buffer_len)\n\n                    # feed a (LR, predicted loss in tau steps) instance to BO.\n                    if str(predicted_loss) == 'nan':\n                        self.opt.tell([float(self.lr)], 1e6)\n                    else:\n                        self.opt.tell([float(self.lr)], predicted_loss)\n                    self.x_iters.append(float(self.lr))\n                    self.func_val_iters.append(predicted_loss)\n                    self.x_func_dict[self.lr] = predicted_loss\n                    self.lr_counter = 1\n\n                    if len(self.func_val_iters) == self.lr_to_explore:\n                        min_index = self.func_val_iters.index(min(self.func_val_iters))\n\n                        # log the best lr found for the next stage.\n                        logging.info('[Server]: best LR: {}, min loss: {}'.format(self.x_iters[min_index], self.func_val_iters[min_index]))\n\n                        self.lr = self.x_iters[min_index]\n                        self.message = str(','.join(('restore', str(self.lr))))\n                        c.send(','.join(('restore', str(self.lr))).encode('utf-8'))\n                        event.set()\n                        logging.debug('[Server]: restore command sent')\n                        self.exploitation_flag = True\n\n                        self.func_val_iters = []\n                        self.x_iters = []\n                        self.x_func_dict = dict()\n                    else:\n                        # Ask BO for the next LR to explore\n                        self.lr = self.opt.ask()[0]\n                        while True:\n                            if self.lr in self.x_func_dict:\n                                self.opt.tell([self.lr], self.x_func_dict[self.lr])\n                                self.lr = self.opt.ask()[0]\n                            else:\n                                break\n                        self.message = str(','.join(('restore', str(self.lr))))\n                        c.send(','.join(('restore', str(self.lr))).encode('utf-8'))\n                        event.set()\n                        logging.debug('[Server]: restore command sent')\n                else:\n                    self.lr_counter += 1\n                    if self.val_stage and self.lr_counter % self.val_freq == 0:\n                        self.message = \"evaluate\"\n                        c.send(self.message.encode('utf-8')) \n                    else:\n                        self.message = str(self.lr)\n                        c.send(str(self.lr).encode('utf-8')) \n                    event.set()\n\ndef main():\n    parser = argparse.ArgumentParser(description='AutoLRS server.')\n    parser.add_argument('--min_lr', \n                        help='minimum LR',\n                        required=True)\n    parser.add_argument('--max_lr', \n                        help='maximum LR',\n                        required=True)\n    parser.add_argument('--host', \n                        help='host',\n                        default='localhost',\n                        type=str)\n    parser.add_argument('--port', \n                        help='port',\n                        required=True,\n                        type=int)\n    args = parser.parse_args()\n    Controller(args.host, args.port, args.min_lr, args.max_lr).listen()\n\nif __name__ == '__main__': \n    main() \n",
    "Experiment Result": "### AutoLRS Constants and Configuration:\n- **Initial Stage Length (τ)**: `EXPLOITATION_STEP = 1000` steps.\n- **Initial Evaluation Length (τ')**: `LR_STEPS = 100` steps for each candidate LR.\n- **Maximum Stage Length (τ_max)**: `TAU_MAX = 8000` steps.\n- **Loss Ring Buffer Length**: `RING_BUFFER_LEN = 100`.\n- **Number of LR Candidates to Explore**: `LR_TO_EXPLORE = 10` within each BO stage.\n- **Bayesian Optimization (BO) Setup**:\n    - **Optimizer**: `skopt.Optimizer`.\n    - **Search Space**: `Real(min_lr, max_lr, 'log-uniform')` (log-uniform distribution for learning rate).\n    - **Surrogate Model**: Gaussian Process (\"GP\").\n    - **Number of Initial Points**: `n_initial_points=1`.\n    - **Acquisition Function**: Lower Confidence Bound (`'LCB'`).\n    - **Kappa Parameter for LCB**: `kappa=1e6`.\n- **Loss Forecasting Model**:\n    - **Type**: Exponential time-series forecasting `L(t) = a * np.exp(b * t) + c`.\n    - **Spline Smoothing (Pre-processing loss series)**:\n        - `UnivariateSpline` with `spline_deg=2`.\n        - For training loss (`is_training=True`): `num_of_iter=10`, `filter_ratio=0.03`.\n        - For validation loss (`is_training=False`): `num_of_iter=1`, `filter_ratio` implicitly used but primarily `outliers = set(sorted(range(len(dys)), key=lambda i: dys[i])[-1:])` to remove only the largest outlier.\n- **Dynamic Stage Length Adjustment**:\n    - Stage length (`lr_steps`, `exploitation_step`) is doubled if `lr_steps < tau_max / 10`.\n    - Once `lr_steps` reaches `tau_max / 10`, `val_stage` is set to `True`.\n- **Loss Collection Strategy**:\n    - In early stages (before `val_stage`), training loss is used for forecasting (implied by `is_training=True` in `exponential_forcast` call).\n    - In later stages (`val_stage=True`), validation loss is used for forecasting (implied by `is_training=False` in `exponential_forcast` call).\n- **Validation Frequency**: When `val_stage` is `True`, validation loss is collected every `val_freq = int(lr_steps/16)` steps.\n- **Model State Management**: Model and optimizer states are checkpointed (`save_variables`) and restored (`restore_variables`) between candidate LR evaluations and BO stages to ensure fair comparison.\n\n### CIFAR-10 Example Specifics:\n- **Validation Subset Size**: Validation loss is calculated on a small subset of the validation set, consisting of `VAL_LEN = 10` mini-batches.\n- **Initial Optimizer Settings (before AutoLRS takes over)**: `optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)`.\n- **Warmup Steps**: `warmup_steps=0` (default, not explicitly set in the example).\n- **Total Training Epochs**: The training loop runs for `350 * 2 = 700` epochs."
}{
    "Title": "Rotational Equilibrium: How Weight Decay Balances Learning Across Neural Networks",
    "Main Contributions": "This study analyzes how weight decay influences the update dynamics of individual neurons in deep neural networks, introducing the concept of 'rotational equilibrium' where expected weight magnitude and angular updates stabilize. Key contributions include deriving steady-state neuronal update dynamics for AdamW, Adam with ℓ2-regularization, Lion, and SGD with momentum, and experimentally validating these. The research demonstrates how weight decay and learning rate jointly determine two distinct effective step sizes (ηg for biases, ηr for weights). It shows that explicitly controlling angular updates via Rotational Optimizer Variants (RVs) offers an alternative to weight decay and normalization, simplifying optimization dynamics and reducing the need for learning rate warmup. Finally, the work reveals that 'balanced rotation' is crucial for the performance benefits of AdamW over Adam+ℓ2 and the effectiveness of Weight Standardization.",
    "Methodology": "The methodology combines applied analysis and experimentation, focusing on fine-grained update dynamics at the neuron level. It describes neuronal updates using expected weight norm (E[∥ωt∥]), RMS update size (ηg) for biases, and expected angular update size (ηr). Analysis is conducted in a simplified setting where updates are dominated by noise, resembling a random walk, allowing for geometric derivation of equilibrium norms and angular updates for various optimizers. The paper introduces Rotational Optimizer Variants (RVs) as a control mechanism, which keep weight magnitudes constant and directly manage average angular updates by projecting gradients to be orthogonal to the weight vector. The analysis also extends to scale-sensitive parameters by modeling radial gradient components as an effective weight decay.",
    "Experimental Setup": "Experiments validate the analytical findings using various neural network architectures (ResNet-20/18/50, DeiT tiny, Transformer-S, GPT2-124M) across several popular datasets: CIFAR-10/100, ImageNet-1k (image classification), IWSLT2014 (German-English translation), Wikitext and OpenWebText (language modeling). Optimizers include SGD with momentum (SGDM), AdamW, Adam with ℓ2-regularization, Lion, and their respective Rotational Variants. Validation methods involve test set performance (mean±std over three seeds), validation accuracy/perplexity/loss curves, and direct measurements of weight norms and average rotation over training steps. A simple random walk system is also used for controlled validation. Experiments are typically run on a single NVIDIA A100-SXM4-40GB GPU.",
    "Limitations": "The analytical models primarily rely on a simplified 'random walk' assumption where gradient noise dominates, which is not a formal theoretical analysis capturing all real-world neural network optimization intricacies. Approximations are used for the recurrence relations and specific optimizer dynamics (e.g., Adam+ℓ2 equilibrium assumes `g2 >> λ2ω2` and perfect second moment tracking). The Lion optimizer's analysis assumes independent and identically distributed normal components for the sign function's argument. The paper acknowledges that the reasons for balanced rotation's empirical effectiveness are not fully clear, and that RVs might not be universally optimal. The random walk model disregards the influence of the true gradient, and approximations in this context can affect prediction accuracy.",
    "Future Research Directions": "The authors suggest numerous opportunities for further theoretical and practical research. This includes exploring if Rotational Optimizer Variants (RVs) can not only replicate but outperform baseline optimizers, and investigating how insights from RVs could lead to better transient phase management to reduce the need for learning rate warmups. Future work could also involve determining the optimal decay factor (β) for RVs based on convergence speed, and exploring whether higher-order information like curvature could guide the determination of relative update sizes more effectively. Further research is needed to fully understand why balanced rotation works and to explore optimal (potentially imbalanced) rotation strategies for specific problems.",
    "Experiment Code": "import torch\ndef tensor_norm(tensor, per_neuron=True):\n    if per_neuron:\n        norm = torch.linalg.vector_norm(tensor.reshape(tensor.shape[0], -1), dim=1)\n        return norm.reshape(-1, *([1]*(tensor.dim()-1)))\n    else:\n        return torch.linalg.vector_norm(tensor)\ndef dot_product(a, b, per_neuron=True):\n    if per_neuron:\n        return (a.flatten(1)*b.flatten(1)).sum(dim=1).reshape(a.shape[0], *([1]*(a.dim()-1)))\n    else:\n        return torch.sum(a*b)\ndef zero_mean(tensor, per_neuron=True):\n    if per_neuron:\n        flat_tensor = tensor.reshape(tensor.shape[0], -1)\n        return (flat_tensor - flat_tensor.mean(dim=1, keepdim=True)).view_as(tensor)\n    else:\n        return tensor - tensor.mean()\n@torch.no_grad()\ndef center_rotational_weights(param_groups, verbose=True):\n    if verbose:\n        print(\"Centering Rotational Weight Vectors\")\n    for group in param_groups:\n        for p in group['params']:\n            if group.get('rotational') is not None:\n                rotational = group['rotational']\n            else:\n                rotational = group['weight_decay'] != 0 and p.dim() > 1\n            if rotational:\n                init_norm = tensor_norm(p, group['per_neuron'])\n                p_zero = zero_mean(p, group['per_neuron'])\n                p_zero = init_norm * p_zero / tensor_norm(p_zero, group['per_neuron'])\n                p.copy_(p_zero)\n@torch.no_grad()\ndef perform_rotational_update(p, d_p, state, group, avg_rotation):\n    if 'rotational_step' not in state:\n        state['rotational_step'] = 0\n    state['rotational_step'] += 1\n    if 'norm' not in state:\n        if group['zero_mean']:\n            p_zero = zero_mean(p, group['per_neuron'])\n            state['norm'] = tensor_norm(p_zero, group['per_neuron'])\n        else:\n            state['norm'] = tensor_norm(p, group['per_neuron'])\n    if group['zero_mean']:\n        d_p = zero_mean(d_p, group['per_neuron'])\n    d_p = d_p - p * (dot_product(d_p, p, group['per_neuron']) / state['norm']**2)\n    undf = group['update_norm_decay_factor']\n    d_p_norm2 = (tensor_norm(d_p, group['per_neuron'])**2).detach()\n    state['update_norm2'] = (1 - undf) * d_p_norm2 + undf * state.get('update_norm2',0)\n    avg_update_norm = torch.sqrt(state['update_norm2'] / (1 - undf**state['rotational_step']))\n    roteps = group['rotational_eps']\n    p_new = p - avg_rotation * (d_p / (roteps + avg_update_norm)) * state['norm']\n    p_new = p_new * state['norm'] / tensor_norm(p_new, group['per_neuron'])\n    p.copy_(p_new)\n\nimport math\nfrom torch.optim.optimizer import Optimizer\nclass RotationalAdamW(Optimizer):\n    def __init__(\n            self,\n            params,\n            lr=1e-3,\n            betas=(0.9, 0.999),\n            eps=1e-8,\n            weight_decay=1e-2,\n            update_norm_decay_factor=0.9,\n            per_neuron=True,\n            zero_mean=True,\n            rotational_eps=1e-8,\n            rotational=None,\n    ):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n        defaults = dict(\n            lr=lr,\n            betas=betas,\n            eps=eps,\n            weight_decay=weight_decay,\n            update_norm_decay_factor=update_norm_decay_factor,\n            per_neuron=per_neuron,\n            zero_mean=zero_mean,\n            rotational_eps=rotational_eps,\n            rotational=rotational,\n        )\n        super().__init__(params, defaults)\n        if zero_mean:\n            center_rotational_weights(self.param_groups)\n    def __setstate__(self, state):\n        super().__setstate__(state)\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n        for group in self.param_groups:\n            weight_decay = group['weight_decay']\n            beta1, beta2 = group['betas']\n            eps = group['eps']\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad\n                if grad.is_sparse:\n                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n                state = self.state[p]\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p)\n                    state['exp_avg_sq'] = torch.zeros_like(p)\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n                state['step'] += 1\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n                if (rotational := group['rotational']) is None:\n                    rotational = group['weight_decay'] != 0 and p.dim() > 1\n                if rotational:\n                    assert group['weight_decay'] != 0\n                    avg_rotation = (2*group['lr']*weight_decay*(1-beta1)/(1+beta1))**0.5\n                    d_p = torch.div(exp_avg, denom) / bias_correction1\n                    perform_rotational_update(p, d_p, state, group, avg_rotation)\n                else:\n                    p.data.mul_(1 - group['lr'] * group['weight_decay'])\n                    step_size = group['lr'] / bias_correction1\n                    p.addcdiv_(exp_avg, denom, value=-step_size)\n        return loss\n\nimport math\nfrom torch.optim.optimizer import Optimizer\nclass RotationalLion(Optimizer):\n    def __init__(\n        self,\n        params,\n        lr=1e-4,\n        betas=(0.9, 0.99),\n        weight_decay=0.0,\n        update_norm_decay_factor=0.9,\n        per_neuron=True,\n        zero_mean=True,\n        rotational_eps=1e-8,\n        rotational=None,\n    ):\n        if not 0.0 <= lr:\n            raise ValueError('Invalid learning rate: {}'.format(lr))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError('Invalid beta parameter at index 0: {}'.format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError('Invalid beta parameter at index 1: {}'.format(betas[1]))\n        defaults = dict(\n            lr=lr,\n            betas=betas,\n            weight_decay=weight_decay,\n            update_norm_decay_factor=update_norm_decay_factor,\n            per_neuron=per_neuron,\n            zero_mean=zero_mean,\n            rotational_eps=rotational_eps,\n            rotational=rotational,\n        )\n        super().__init__(params, defaults)\n        if zero_mean:\n            center_rotational_weights(self.param_groups)\n    def __setstate__(self, state):\n        super().__setstate__(state)\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n        for group in self.param_groups:\n            lr = group['lr']\n            weight_decay = group['weight_decay']\n            beta1, beta2 = group['betas']\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                state = self.state[p]\n                if len(state) == 0:\n                    state['exp_avg'] = torch.zeros_like(p)\n                d_p = torch.sign(state['exp_avg'].mul(beta1).add_(p.grad, alpha=1 - beta1))\n                state['exp_avg'].lerp_(p.grad, 1 - beta2)\n                if (rotational := group['rotational']) is None:\n                    rotational = group['weight_decay'] != 0 and p.dim() > 1\n                if rotational:\n                    assert group['weight_decay'] != 0\n                    avg_rotation = (math.pi/2.0)**0.5 * (2*lr*weight_decay)**0.5 \\\n                        * ((1-beta1)**2 + beta1**2*(1-beta2)/(1+beta2))**0.5\n                    perform_rotational_update(p, d_p, state, group, avg_rotation)\n                else:\n                    p.mul_(1 - lr * weight_decay)\n                    p.add_(d_p, alpha=-lr)\n        return loss\n\nimport torch\nfrom torch.optim.optimizer import Optimizer, required\nclass RotationalSGD(Optimizer):\n    def __init__(\n        self,\n        params,\n        lr=required,\n        momentum=0,\n        weight_decay=required,\n        nesterov=False,\n        update_norm_decay_factor=0.9,\n        per_neuron=True,\n        zero_mean=True,\n        rotational_eps=1e-8,\n        rotational=None,\n    ):\n        if lr is not required and lr < 0.0:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if momentum < 0.0:\n            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n        if weight_decay < 0.0:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        if nesterov and (momentum <= 0):\n            raise ValueError(\"Nesterov momentum requires a momentum\")\n        defaults = dict(\n            lr=lr,\n            momentum=momentum,\n            weight_decay=weight_decay,\n            nesterov=nesterov,\n            update_norm_decay_factor=update_norm_decay_factor,\n            per_neuron=per_neuron,\n            zero_mean=zero_mean,\n            rotational_eps=rotational_eps,\n            rotational=rotational,\n        )\n        super().__init__(params, defaults)\n        if zero_mean:\n            center_rotational_weights(self.param_groups)\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n        for group in self.param_groups:\n            weight_decay = group['weight_decay']\n            momentum = group['momentum']\n            nesterov = group['nesterov']\n            for p in group['params']:\n                if (rotational := group['rotational']) is None:\n                    rotational = group['weight_decay'] != 0 and p.dim() > 1\n                state = self.state[p]\n                if p.grad is None:\n                    continue\n                d_p = p.grad\n                if weight_decay != 0 and not rotational:\n                    d_p = d_p.add(p, alpha=weight_decay)\n                if momentum != 0:\n                    param_state = self.state[p]\n                    if 'momentum_buffer' not in param_state:\n                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n                    else:\n                        buf = param_state['momentum_buffer']\n                        buf.mul_(momentum).add_(d_p)\n                    if nesterov:\n                        d_p = d_p.add(buf, alpha=momentum)\n                    else:\n                        d_p = buf\n                if rotational:\n                    assert group['weight_decay'] != 0\n                    avg_rotation = (2*group['lr']*group['weight_decay']/(1+group['momentum']))**0.5\n                    perform_rotational_update(p, d_p, state, group, avg_rotation)\n                else:\n                    p.add_(d_p, alpha=-group['lr'])\n        return loss\n\nimport math\nimport torch\nfrom torch.optim import Optimizer\nfrom torch.utils._foreach_utils import _group_tensors_by_device_and_dtype\nclass RotationalWrapper(Optimizer):\n    def __init__(\n        self,\n        params,\n        inner_type='adamw',\n        etar_func=None,\n        update_norm_decay_factor=0.9,\n        per_neuron=True,\n        zero_mean=True,\n        rotational_eps=1e-8,\n        **inner_hyperparameters,\n    ):\n        if isinstance(etar_func, str):\n            if etar_func == 'adamw':\n                self.etar_func = adamw_etar_func\n            elif etar_func == 'sgdm':\n                self.etar_func = sgdm_etar_func\n            elif etar_func == 'lion':\n                self.etar_func = lion_etar_func\n            else:\n                raise ValueError(f\"Unknown {etar_func=}\")\n        else:\n            self.etar_func = etar_func\n        if inner_type == 'adamw':\n            self.init_state_get_lists = adamw_init_state_get_lists\n            self.get_inner_update = adamw_get_update\n            if self.etar_func is None:\n                self.etar_func = adamw_etar_func\n            inner_hyperparameters = {\n                'lr': 1e-3,\n                'weight_decay': 1e-2,\n                'betas': (0.9, 0.999),\n                'eps': 1e-8,\n                **inner_hyperparameters,\n            }\n        if inner_type == 'adam':\n            self.init_state_get_lists = adam_init_state_get_lists\n            self.get_inner_update = adam_get_update\n            if self.etar_func is None:\n                raise ValueError(\"No etar_func provided for Adam\")\n            inner_hyperparameters = {\n                'lr': 1e-3,\n                'weight_decay': 0.0,\n                'betas': (0.9, 0.999),\n                'eps': 1e-8,\n                **inner_hyperparameters,\n            }\n        if inner_type == 'sgdm':\n            self.init_state_get_lists = sgdm_init_state_get_lists\n            self.get_inner_update = sgdm_get_update\n            if self.etar_func is None:\n                self.etar_func = sgdm_etar_func\n            inner_hyperparameters = {\n                'momentum': 0.0,\n                'weight_decay': 0.0,\n                **inner_hyperparameters,\n            }\n        if inner_type == 'lion':\n            self.init_state_get_lists = lion_init_state_get_lists\n            self.get_inner_update = lion_get_update\n            if self.etar_func is None:\n                self.etar_func = lion_etar_func\n            inner_hyperparameters = {\n                'lr': 1e-4,\n                'weight_decay': 1.0,\n                'betas': (0.9, 0.99),\n                'eps': 1e-8,\n                **inner_hyperparameters,\n            }\n        defaults = dict(\n            per_neuron=per_neuron,\n            update_norm_decay_factor=update_norm_decay_factor,\n            zero_mean=zero_mean,\n            rotational_eps=rotational_eps,\n            **inner_hyperparameters,\n        )\n        super().__init__(params, defaults)\n        if zero_mean:\n            center_rotational_weights(self.param_groups)\n    @torch.no_grad()\n    def step(self):\n        for group in self.param_groups:\n            state_lists = self.init_state_get_lists(self.state, group)\n            unscaled_delta_grads, unscaled_delta_lambdas = self.get_inner_update(state_lists, group)\n            for p in group['params']:\n                if group.get('rotational') is not None:\n                    rotational = group['rotational']\n                    if rotational:\n                        assert group['weight_decay'] != 0\n                else:\n                    rotational = group['weight_decay'] != 0 and p.dim() > 1\n                if rotational:\n                    state = self.state[p]\n                    if 'norm' not in state:\n                        if group['zero_mean']:\n                            p_zero = zero_mean(p, group['per_neuron'])\n                            state['norm'] = tensor_norm(p_zero, group['per_neuron'])\n                        else:\n                            state['norm'] = tensor_norm(p, group['per_neuron'])\n                    update = unscaled_delta_grads[p]\n                    projection = p * (dot_product(update, p, group['per_neuron']) / state['norm']**2)\n                    update = update - projection\n                    if group['zero_mean']:\n                        update = zero_mean(update, group['per_neuron'])\n                    undf = group['update_norm_decay_factor']\n                    square_update_norm = tensor_norm(update, group['per_neuron'])**2\n                    state['update_norm_sq'] = (1-undf) * square_update_norm + undf * state.get('update_norm_sq', 0)\n                    avg_update_norm = torch.sqrt(state['update_norm_sq'] / (1 - undf**state['step']))\n                    eta_r = self.etar_func(group)\n                    p_new = p - eta_r * state['norm'] * (update / (avg_update_norm + group['rotational_eps']))\n                    p_new = p_new * state['norm'] / tensor_norm(p_new, group['per_neuron'])\n                    p.copy_(p_new)\n                else:\n                    p.add_(-group['lr']*(unscaled_delta_grads[p]+unscaled_delta_lambdas[p]))\n\ndef adamw_init_state_get_lists(optimizer_state, group):\n    state_lists = dict(\n        params_with_grad=(params_with_grad := []),\n        grads=(grads := []),\n        exp_avgs=(exp_avgs := []),\n        exp_avg_sqs=(exp_avg_sqs := []),\n        state_steps=(state_steps := []),\n    )\n    for p in group[\"params\"]:\n        if p.grad is None:\n            continue\n        params_with_grad.append(p)\n        if p.grad.is_sparse:\n            raise RuntimeError(\"AdamW does not support sparse gradients\")\n        grads.append(p.grad)\n        state = optimizer_state[p]\n        if len(state) == 0:\n            state[\"step\"] = torch.tensor(0.0)\n            state[\"exp_avg\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n            state[\"exp_avg_sq\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n        exp_avgs.append(state[\"exp_avg\"])\n        exp_avg_sqs.append(state[\"exp_avg_sq\"])\n        state_steps.append(state[\"step\"])\n    return state_lists\ndef adamw_get_update(state_lists, group):\n    params = state_lists['params_with_grad']\n    grads = state_lists['grads']\n    exp_avgs = state_lists['exp_avgs']\n    exp_avg_sqs = state_lists['exp_avg_sqs']\n    state_steps = state_lists['state_steps']\n    beta1, beta2 = group['betas']\n    weight_decay = group['weight_decay']\n    eps = group['eps']\n    unscaled_delta_grads = dict()\n    unscaled_delta_lambdas = dict()\n    if len(params) == 0:\n        return dict(), dict()\n    grouped_tensors = _group_tensors_by_device_and_dtype([\n        params, grads, exp_avgs, exp_avg_sqs, state_steps])\n    for ((\n        device_params,\n        device_grads,\n        device_exp_avgs,\n        device_exp_avg_sqs,\n        device_state_steps,\n    ), _) in grouped_tensors.values():\n        torch._foreach_add_(device_state_steps, 1)\n        torch._foreach_lerp_(device_exp_avgs, device_grads, 1 - beta1)\n        torch._foreach_mul_(device_exp_avg_sqs, beta2)\n        torch._foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads, 1 - beta2)\n        del device_grads\n        bias_correction1 = [1 - beta1 ** _get_value(step) for step in device_state_steps]\n        bias_correction2 = [1 - beta2 ** _get_value(step) for step in device_state_steps]\n        bias_correction2_sqrt = [_dispatch_sqrt(bc) for bc in bias_correction2]\n        exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n        torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n        torch._foreach_add_(exp_avg_sq_sqrt, eps)\n        scaled_updates = torch._foreach_div(device_exp_avgs, exp_avg_sq_sqrt)\n        torch._foreach_div_(scaled_updates, bias_correction1)\n        unscaled_delta_wd_list = torch._foreach_mul(device_params, weight_decay)\n        for param, udg, udl in zip(device_params, scaled_updates, unscaled_delta_wd_list):\n            unscaled_delta_grads[param] = udg\n            unscaled_delta_lambdas[param] = udl\n    return unscaled_delta_grads, unscaled_delta_lambdas\ndef adamw_etar_func(group):\n    lr = group['lr']\n    wd = group['weight_decay']\n    beta1 = group['betas'][0]\n    return (2*lr*wd*(1-beta1)/(1+beta1))**0.5\n\ndef adam_init_state_get_lists(optimizer_state, group):\n    state_lists = dict(\n        params_with_grad=(params_with_grad := []),\n        grads=(grads := []),\n        grad_exp_avgs=(grad_exp_avgs := []),\n        l2_exp_avgs=(l2_exp_avgs := []),\n        total_exp_avg_sqs=(total_exp_avg_sqs := []),\n        state_steps=(state_steps := []),\n    )\n    for p in group[\"params\"]:\n        if p.grad is None:\n            continue\n        params_with_grad.append(p)\n        if p.grad.is_sparse:\n            raise RuntimeError(\"Adam does not support sparse gradients\")\n        grads.append(p.grad)\n        state = optimizer_state[p]\n        if len(state) == 0:\n            state[\"step\"] = torch.tensor(0.0)\n            state[\"grad_exp_avg\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n            state[\"l2_exp_avg\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n            state[\"total_exp_avg_sq\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n        grad_exp_avgs.append(state[\"grad_exp_avg\"])\n        l2_exp_avgs.append(state[\"l2_exp_avg\"])\n        total_exp_avg_sqs.append(state[\"total_exp_avg_sq\"])\n        state_steps.append(state[\"step\"])\n    return state_lists\ndef adam_get_update(state_lists, group):\n    params = state_lists['params_with_grad']\n    grads = state_lists['grads']\n    grad_exp_avgs = state_lists['grad_exp_avgs']\n    l2_exp_avgs = state_lists['l2_exp_avgs']\n    total_exp_avg_sqs = state_lists['total_exp_avg_sqs']\n    state_steps = state_lists['state_steps']\n    beta1, beta2 = group['betas']\n    weight_decay = group['weight_decay']\n    eps = group['eps']\n    unscaled_delta_grads = dict()\n    unscaled_delta_lambdas = dict()\n    if len(params) == 0:\n        return dict(), dict()\n    grouped_tensors = _group_tensors_by_device_and_dtype([\n        params, grads, grad_exp_avgs, l2_exp_avgs, total_exp_avg_sqs, state_steps\n    ])\n    for ((\n        device_params,\n        device_grads,\n        device_grad_exp_avgs,\n        device_l2_exp_avgs,\n        device_total_exp_avg_sqs,\n        device_state_steps,\n    ), _) in grouped_tensors.values():\n        torch._foreach_add_(device_state_steps, 1)\n        torch._foreach_lerp_(device_grad_exp_avgs, device_grads, 1 - beta1)\n        l2_term = torch._foreach_mul(device_params, weight_decay)\n        torch._foreach_lerp_(device_l2_exp_avgs, l2_term, 1 - beta1)\n        del l2_term\n        device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)\n        torch._foreach_mul_(device_total_exp_avg_sqs, beta2)\n        torch._foreach_addcmul_(device_total_exp_avg_sqs, device_grads, device_grads, 1 - beta2)\n        del device_grads\n        bias_correction1 = [1 - beta1 ** _get_value(step) for step in device_state_steps]\n        bias_correction2 = [1 - beta2 ** _get_value(step) for step in device_state_steps]\n        bias_correction2_sqrt = [_dispatch_sqrt(bc) for bc in bias_correction2]\n        total_exp_avg_sq_sqrt = torch._foreach_sqrt(device_total_exp_avg_sqs)\n        torch._foreach_div_(total_exp_avg_sq_sqrt, bias_correction2_sqrt)\n        torch._foreach_add_(total_exp_avg_sq_sqrt, eps)\n        unscaled_grad_updates = torch._foreach_div(device_grad_exp_avgs, total_exp_avg_sq_sqrt)\n        torch._foreach_div_(unscaled_grad_updates, bias_correction1)\n        unscaled_l2_updates = torch._foreach_div(device_l2_exp_avgs, total_exp_avg_sq_sqrt)\n        torch._foreach_div_(unscaled_l2_updates, bias_correction1)\n        for param, udg, udl in zip(device_params, unscaled_grad_updates, unscaled_l2_updates):\n            unscaled_delta_grads[param] = udg\n            unscaled_delta_lambdas[param] = udl\n    return unscaled_delta_grads, unscaled_delta_lambdas\n\ndef sgdm_init_state_get_lists(optimizer_state, group):\n    state_lists = dict(\n        params_with_grad=(params_with_grad := []),\n        grads=(grads := []),\n        grad_exp_avgs=(grad_exp_avgs := []),\n        l2_exp_avgs=(l2_exp_avgs := []),\n        state_steps=(state_steps := []),\n    )\n    for p in group[\"params\"]:\n        if p.grad is None:\n            continue\n        params_with_grad.append(p)\n        if p.grad.is_sparse:\n            raise RuntimeError(\"SGDM does not support sparse gradients\")\n        grads.append(p.grad)\n        state = optimizer_state[p]\n        if len(state) == 0:\n            state[\"step\"] = torch.tensor(0.0)\n            state[\"grad_exp_avg\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n            state[\"l2_exp_avg\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n        grad_exp_avgs.append(state[\"grad_exp_avg\"])\n        l2_exp_avgs.append(state[\"l2_exp_avg\"])\n        state_steps.append(state[\"step\"])\n    return state_lists\ndef sgdm_get_update(state_lists, group):\n    params = state_lists['params_with_grad']\n    grads = state_lists['grads']\n    grad_exp_avgs = state_lists['grad_exp_avgs']\n    l2_exp_avgs = state_lists['l2_exp_avgs']\n    state_steps = state_lists['state_steps']\n    momentum = group['momentum']\n    weight_decay = group['weight_decay']\n    assert not group.get('nesterov'), \"This implementation doesn't support it\"\n    unscaled_delta_grads = dict()\n    unscaled_delta_lambdas = dict()\n    if len(params) == 0:\n        return dict(), dict()\n    grouped_tensors = _group_tensors_by_device_and_dtype([\n        params, grads, grad_exp_avgs, l2_exp_avgs, state_steps\n    ])\n    for ((\n        device_params,\n        device_grads,\n        device_grad_exp_avgs,\n        device_l2_exp_avgs,\n        device_state_steps,\n    ), _) in grouped_tensors.values():\n        torch._foreach_add_(device_state_steps, 1)\n        torch._foreach_mul_(device_grad_exp_avgs, momentum)\n        torch._foreach_add_(device_grad_exp_avgs, device_grads)\n        torch._foreach_mul_(device_l2_exp_avgs, momentum)\n        torch._foreach_add_(device_l2_exp_avgs, device_params, alpha=weight_decay)\n        for param, udg, udl in zip(device_params, device_grad_exp_avgs, device_l2_exp_avgs):\n            unscaled_delta_grads[param] = udg\n            unscaled_delta_lambdas[param] = udl\n    return unscaled_delta_grads, unscaled_delta_lambdas\ndef sgdm_etar_func(group):\n    lr = group['lr']\n    wd = group['weight_decay']\n    alpha = group['momentum']\n    return (2*lr*wd/(1+alpha))**0.5\n\ndef lion_init_state_get_lists(optimizer_state, group):\n    state_lists = dict(\n        params_with_grad=(params_with_grad := []),\n        grads=(grads := []),\n        exp_avgs=(exp_avgs := []),\n        state_steps=(state_steps := []),\n    )\n    for p in group[\"params\"]:\n        if p.grad is None:\n            continue\n        params_with_grad.append(p)\n        if p.grad.is_sparse:\n            raise RuntimeError(\"AdamW does not support sparse gradients\")\n        grads.append(p.grad)\n        state = optimizer_state[p]\n        if len(state) == 0:\n            state[\"step\"] = torch.tensor(0.0)\n            state[\"exp_avg\"] = torch.zeros_like(\n                p, memory_format=torch.preserve_format\n            )\n        exp_avgs.append(state[\"exp_avg\"])\n        state_steps.append(state[\"step\"])\n    return state_lists\ndef lion_get_update(state_lists, group):\n    params = state_lists['params_with_grad']\n    grads = state_lists['grads']\n    exp_avgs = state_lists['exp_avgs']\n    state_steps = state_lists['state_steps']\n    beta1, beta2 = group['betas']\n    weight_decay = group['weight_decay']\n    eps = group['eps']\n    unscaled_delta_grads = dict()\n    unscaled_delta_lambdas = dict()\n    if len(params) == 0:\n        return dict(), dict()\n    grouped_tensors = _group_tensors_by_device_and_dtype([\n        params, grads, exp_avgs, state_steps])\n    for ((\n        device_params,\n        device_grads,\n        device_exp_avgs,\n        device_state_steps,\n    ), _) in grouped_tensors.values():\n        torch._foreach_add_(device_state_steps, 1)\n        if len(device_params) == 0:\n            return\n        device_grads = [torch.view_as_real(x) if torch.is_complex(x) else x for x in device_grads]\n        device_exp_avgs = [torch.view_as_real(x) if torch.is_complex(x) else x for x in device_exp_avgs]\n        device_params = [torch.view_as_real(x) if torch.is_complex(x) else x for x in device_params]\n        updates = torch._foreach_mul(device_exp_avgs, beta1)\n        torch._foreach_add_(updates, device_grads, alpha=1 - beta1)\n        unscaled_updates = [u.sign() for u in updates]\n        torch._foreach_mul_(device_exp_avgs, beta2)\n        torch._foreach_add_(device_exp_avgs, device_grads, alpha=1 - beta2)\n        unscaled_delta_wd_list = torch._foreach_mul(device_params, weight_decay)\n        for param, udg, udl in zip(device_params, unscaled_updates, unscaled_delta_wd_list):\n            unscaled_delta_grads[param] = udg\n            unscaled_delta_lambdas[param] = udl\n    return unscaled_delta_grads, unscaled_delta_lambdas\ndef lion_etar_func(group):\n    lr = group['lr']\n    wd = group['weight_decay']\n    beta1 = group['betas'][0]\n    beta2 = group['betas'][1]\n    return (math.pi/2.0)**0.5 * (2*lr*wd)**0.5 * ((1-beta1)**2 + beta1**2*(1-beta2)/(1+beta2))**0.5\n\ndef _get_value(x):\n    if not torch.jit.is_scripting() and torch._utils.is_compiling():\n        return x\n    else:\n        return x.item()\ndef _stack_if_compiling(x):\n    if not torch.jit.is_scripting() and torch._utils.is_compiling()():\n        return torch.stack(x)\n    else:\n        return x\ndef _dispatch_sqrt(x: float):\n    if not torch.jit.is_scripting() and isinstance(x, torch.Tensor):\n        return x.sqrt()\n    else:\n        return math.sqrt(x)\n\nimport torch.nn as nn\nclass SLinear(torch.nn.Linear):\n    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n        super().__init__(in_features, out_features, bias=bias, device=device, dtype=dtype)\n        self.gain = nn.Parameter(torch.ones(out_features, device=device, dtype=dtype))\n    def forward(self, x):\n        weight = self.weight\n        weight = self.gain.view(-1, 1) * weight\n        return torch.nn.functional.linear(x, weight, self.bias)",
    "Experiment Result": "Model: Transformer (fairseq transformer_iwslt_de_en architecture)\nOptimizer: rvwrapper (Rotational Optimizer Variant) with inner_type=adamw and etar_func=adamw\nLearning Rate: 0.0005\nWeight Decays: [0.0001, 0.4]\nAdam Betas: (0.9, 0.98)\nClip Norm: 0.0\nLR Scheduler: cosine with warmup_updates=4000\nDropout: 0.3\nCriterion: label_smoothed_cross_entropy with label_smoothing=0.1\nMax Tokens: 4096\nEvaluation: BLEU score with beam=5, max_len_a=1.2, max_len_b=10, detokenized by moses, BPE removed, print samples\nBest Checkpoint Metric: bleu, maximized\nLinear Layer Configuration: slinear (Scale-invariant linear layer with learnable gain)\nMax Update: 22021\nAMP (Automatic Mixed Precision): Enabled\nWeight Decay Zero Bias: Not explicitly enabled/disabled, but `--weight-decay-zero-bias` is present in other non-RV adamw configs, not this one.\nWandB Project: constraining-smd\nSeeds: [0, 1, 2]\nEnvironment Variables: base_dir, lr, wd, iter, seed, output_dir (~/data/runs/fairseq), iwslt14 (data path), cf_linear (slinear)\nData: IWSLT2014 tokenized German-English"
}{
    "Title": "DP-HyPO: An Adaptive Private Framework for Hyperparameter Optimization",
    "Main Contributions": "Introduces DP-HyPO, a pioneering adaptive private hyperparameter optimization framework, to bridge the gap between private and non-private HPO. It enables flexible use of non-DP adaptive HPO methods, such as Gaussian process, while avoiding substantial privacy costs due to composition. The framework provides sharp Differential Privacy (DP) guarantees by accurately characterizing the Rényi divergence between adaptive sampling distributions of neighboring datasets, without relying on stability assumptions, thus strictly generalizing prior non-adaptive methods. Empirically demonstrates that a Gaussian process-based DP-HyPO algorithm outperforms its uniform counterpart across various real-world scenarios and allows practitioners to integrate any non-private adaptive HPO methods and allocate privacy budget for adaptivity.",
    "Methodology": "DP-HyPO is designed to achieve adaptive hyperparameter optimization with differential privacy by maintaining an adaptive sampling distribution (π) at each iteration. This distribution reflects accumulated information from previous runs. To control privacy loss, the sampling distribution π(j) is required to have a density bounded by constants 'c' and 'C' relative to a prior distribution π(0). The framework includes a general projection technique to privatize any non-private update rules by projecting π(j) into a space of essentially bounded density functions SC,c. Privacy guarantees are provided using the Rényi Differential Privacy (RDP) framework, with specific analysis for when the total number of repetitions (T) follows a truncated negative binomial distribution. An instantiation of DP-HyPO with Gaussian Process (AGP) is provided, where GP is used to construct a surrogate model, estimate mean and variance of performance, assign scores (estimated Upper Confidence Bound), and transform these scores into a sampling distribution using a softmax function, which is then projected to satisfy the bounded density constraint.",
    "Experimental Setup": "The DP-HyPO framework, specifically its Gaussian process-based variant (GP), was empirically evaluated against the Uniform DP-HyPO method (a non-adaptive special case with C=c=1). Experiments were conducted under two pragmatic privacy configurations: the white-box setting and the black-box setting.1. White-box setting (adaptive HPO incurs extra privacy cost):- MNIST Simulation: Trained a standard CNN with DP-SGD on the MNIST dataset, optimizing learning rate (η) and clipping norm (R). A semi-real simulation cached mean accuracies for discretized hyperparameters and added Gaussian noise during sampling. Total privacy budget was ε=15, δ=1e-5. Hyperparameter grids included 16 log-spaced η values and 20 linear-spaced R values (total 320 combinations).- CIFAR-10 Simulation: Used the same CNN model and hyperparameters on the CIFAR-10 dataset. Hyperparameter landscapes (mean and standard error of accuracy) were generated using BoTorch [3] from 50 runs. Total privacy budget was ε=12, δ=1e-5. Hyperparameter grids included 50 log-spaced η values and 50 linear-spaced R values (total 2500 combinations).2. Black-box setting (base algorithm privacy fixed, extra budget for HPO):- Federated Learning (FL) Task: Explored an FL task on a proprietary industrial dataset, optimizing learning rates for the central server (AdaGrad) and individual users (SGD). The loss landscape (mean and standard error) was generated by BoTorch [3]. Experiments varied the degree of adaptivity (different C values) and aggregated performance data over a Geometric distribution with various γ values.",
    "Limitations": "The framework requires non-private adaptive HPO update rules to be modified (via a projection technique) to satisfy the bounded adaptive density constraint, which is not automatically met. The benefits of adaptivity were observed to be marginal in datasets with uncomplicated hyperparameter landscapes (e.g., MNIST). Due to computational resource constraints, some experiments (MNIST, CIFAR-10, FL) used semi-real simulations or pre-generated hyperparameter landscapes from BoTorch rather than full end-to-end DP-SGD runs for every trial. Details about the proprietary Federated Learning dataset are limited due to confidentiality constraints.",
    "Future Research Directions": "Two main future research directions are identified: 1. Investigating alternative HPO specifications that are more practically favorable and leveraging advanced HPO methods from the extensive literature to further improve empirical performance. 2. Establishing a theoretical utility guarantee for the DP-HyPO framework, potentially by applying proof methodologies similar to those found in prior work like Theorem 3.3 in [26], for either the general framework or specific configurations within it.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Hyperparameter Optimization through Neural Network Partitioning",
    "Main Contributions": "The paper proposes \"Partitioned Neural Networks,\" a novel and efficient method for hyperparameter optimization (HPO) that operates in a single training run without needing a separate validation set. Inspired by the marginal likelihood, the method partitions the training data into shards and the neural network into corresponding parameter partitions. It optimizes hyperparameters by minimizing an \"out-of-training-sample\" loss on data shards unseen by a subnetwork, thereby approximating the marginal likelihood. This approach is significantly more computationally efficient and scalable than existing marginal likelihood approximations (e.g., Laplace approximations) and is broadly applicable to various hyperparameters like input masks, data augmentations, dropout rates, and feature extractors. It also demonstrates particular advantages in federated learning settings by reducing communication overhead and improving model generalization, especially in low-data regimes and for handling non-i.i.d. data.",
    "Methodology": "The methodology is based on approximating a lower bound of the marginal likelihood, formulated as LML(D,ψ) = Σ_k Eq_k-1(w)[log p(D_k|w,ψ)]. The training data is partitioned into C chunks (D1,..., DC), and the neural network weights (w) are partitioned into C sub-weights (w1,..., wC). A k-th subnetwork, w(k)s, comprises the first k parameter partitions (w1,..., wk) and sets the remaining parameters to default values (e.g., initialization). During training, stochastic gradient updates are interleaved: first, a parameter partition wk is updated on data chunks D1:k using its subnetwork w(k)s; then, hyperparameters ψ are updated using the out-of-training-sample loss, which evaluates log p(Dk|w(k-1)s, ψ) on a newly sampled chunk Dk unseen by the w(k-1)s subnetwork. The primary partitioning scheme used is random weight partitioning, where a fixed proportion of weights in each layer is randomly assigned to a partition. For federated learning, clients are assigned to data chunks, and each client optimizes its relevant parameter partitions (wk:C) and computes hyperparameter gradients, reducing communication by not transmitting unmodified earlier partitions.",
    "Experimental Setup": "Experiments were conducted on various tasks including a toy input selection task (identifying 15 informative features out of 30), differentiable input selection using learnable masks, learning affine image augmentations, and learning general feature extractors. The datasets included synthetic data for the toy tasks, MNIST, CIFAR10, TinyImagenet, and their rotated variants (rotMNIST, rotCIFAR10, rotTinyImagenet), as well as experiments in low-data regimes (subsets of these datasets). Architectures used comprised fully-connected MLPs, fixupResNets (ResNet-8, ResNet-14), ResNet-50 with GroupNorm(2), Wide ResNet-20, and a CNN for MNIST. The method was compared against baselines such as standard training with no augmentations, Augerino, Differentiable Laplace, Last-layer Marginal Likelihood, and traditional validation set optimization. For federated learning, FedAvg and FedAvg with Augerino were used as baselines, with non-i.i.d. data partitioning (label-skew and rotation-skew) across clients. Validation methods included test accuracy, log-likelihood, and an analysis of robustness to different partitioning schemes.",
    "Limitations": "The method introduces an additional forward-backward pass for hyperparameter updates, leading to some computational overhead, though still less than existing marginal likelihood methods. Empirically, it may require more training iterations to converge. There is an inherent constraint on network capacity due to partitioning, which might cause a performance loss compared to a full, non-partitioned network trained with *optimally given* hyperparameters. Furthermore, the partitioning strategy itself (number of chunks, relative data and parameter proportions) becomes an additional hyperparameter that might require tuning for optimal performance, despite observed robustness. Lastly, if default weight values are non-zero (e.g., in normalization-free architectures like FixUp), storing these adds a constant memory overhead, potentially doubling memory for parameters, though this can be mitigated by clever implementation or setting defaults to zero.",
    "Future Research Directions": "Future research could explore dynamic partitioning of network parameters during training, rather than fixing them prior to training. Investigating alternative partitioning schemes beyond random weight and node partitioning is also a promising direction, potentially enabling more efficient gradient computations across multiple partitions or reducing memory overheads. Efforts could be made to alleviate the observed performance loss caused by network partitioning, for instance, by adjusting training rounds or strategically increasing network capacity. Further exploration of different hyperparameter update schedules, such as accumulating gradients from multiple chunks or performing less frequent hyperparameter updates, could lead to improved efficiency or stability. In the federated learning context, investigating alternative sequential updating schemes for client-side partitions is another area for future work.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Implicit differentiation of Lasso-type models for hyperparameter optimization",
    "Main Contributions": "The paper addresses the challenge of setting regularization parameters for Lasso-type estimators, which is crucial but difficult, especially for high-dimensional data. Existing gradient-based hyperparameter optimization (HO) methods suffer from high memory consumption (forward/backward automatic differentiation) or numerical instability and the assumption of smooth loss functions (implicit differentiation). The main contributions are: 1) Introduction of an efficient implicit differentiation algorithm, without matrix inversion, specifically tailored for non-smooth Lasso-type problems. 2) The proposed method scales to high-dimensional data by leveraging the sparsity of the solutions. 3) It demonstrates that forward iterative differentiation of Block Coordinate Descent (BCD) converges linearly to the true gradient once the support is identified, and its limit is independent of the initial point. 4) The proposed algorithm (Algorithm 2) decouples the computation of the Jacobian from the regression coefficients, allowing state-of-the-art convex solvers for coefficient computation and avoiding potentially ill-conditioned linear systems. 5) Experiments show that the method outperforms many standard HO techniques for optimizing error on held-out data or the Stein Unbiased Risk Estimator (SURE).",
    "Methodology": "The hyperparameter optimization (HO) problem is framed as a nested bi-level optimization. The inner problem finds the regression coefficients for Lasso-type models (Lasso or weighted Lasso) given hyperparameters, while the outer problem optimizes a criterion (e.g., held-out loss, SURE) with respect to these hyperparameters using gradient descent. The core methodology relies on an efficient implicit differentiation technique adapted for non-smooth Lasso-type problems. The key insight is leveraging the fixed-point iteration induced by proximal Block Coordinate Descent (BCD) algorithms. The proposed algorithm, 'Implicit Forward Iterdiff' (Algorithm 2), operates in two phases: first, it computes the regression coefficients (e.g., using BCD) to identify the solution's support; second, it computes the Jacobian of the coefficients with respect to hyperparameters using forward differentiation recursion steps, restricted to the identified support. This decoupling and support-restricted computation avoids solving a large (p x p) linear system (as in classical implicit differentiation, Algorithm 1) or storing all intermediate iterates (as in backward iterative differentiation). The convergence of this approach to the true Jacobian is theoretically proven for unique Lasso solutions.",
    "Experimental Setup": "The Python code for the proposed method is open-source (sparse-ho, using Numba for critical parts). For fair comparison, all hypergradient-based methods (proposed Implicit Forward Iterdiff, Implicit, Forward Iterdiff) and non-gradient-based competitors (Grid-search, Random-search, Lattice Hyp., Bayesian optimization) utilized the same vanilla BCD algorithm for the inner optimization problem. The inner solver termination criteria was a relative change in the cost function below 10^-5. Hypergradient methods used a line-search strategy. Lasso initializations were set at λ_max - log(10). The studies included: 1) Held-out loss on real, high-dimensional datasets: rcv1 (p=19,959), 20news (p=130,107), and finance (p=1,668,737), splitting data into training, validation, and test sets. The objective was minimizing validation loss, and test loss measured generalization. Non-convex MCP (Minimax Concave Penalty) with two hyperparameters was also tested. 2) Stein Unbiased Risk Estimator (SURE) for Lasso and weighted Lasso models using synthetic data (n=100, p varied from 200 to 10,000, SNR=3, 50 repetitions). The metric used was normalized Mean Squared Error (MSE). For the weighted Lasso with p hyperparameters, a regularized version of the HO problem was used to find a robust initialization.",
    "Limitations": "The theoretical guarantees for convergence (Proposition 2) assume a unique solution to the inner Lasso problem. While the set of parameters leading to non-unique solutions is typically of measure zero, such pathological settings could lead to non-continuous solution paths for ˆβ(λ), making gradient-based methods theoretically challenging. The current theory does not cover non-convex cases (e.g., MCP penalty), though numerical experiments suggest proper behavior. The hyperparameter optimization problem L(λ) is generally non-convex, meaning gradient descent might converge to local minima rather than a global optimum, making initialization crucial. Backward iterative differentiation (Algorithm 4) was found to be computationally inefficient and memory-intensive for the BCD algorithm in this context, rendering it impractical for extensive benchmarking. The SURE criterion requires knowledge of the noise variance, which might not always be available in practice.",
    "Future Research Directions": "Future research directions include extending the theoretical framework of efficient implicit differentiation to cover non-convex penalty functions (e.g., MCP, Elastic-Net) for Lasso-type estimators. Further investigation into handling other regularization formulations beyond Lasso and weighted Lasso is also suggested. A promising area is to leverage the two-step nature of the proposed algorithm to integrate with advanced state-of-the-art Lasso solvers that employ techniques like active sets or screening rules. Such solvers introduce discontinuities with respect to hyperparameters, and fully combining them with gradient-based HO methods would be a significant advancement, challenging single-step automatic differentiation approaches.",
    "Experiment Code": "class ImplicitForward():\n    \"\"\"Algorithm to compute the hypergradient using implicit forward\n    differentiation.\n\n    First the algorithm computes the regression coefficients.\n    Then the iterations of the forward differentiation are applied to compute\n    the Jacobian.\n\n    Parameters\n    ----------\n    tol_jac: float\n        Tolerance for the Jacobian computation.\n    max_iter: int\n        Maximum number of iterations for the inner solver.\n    n_iter_jac: int\n        Maximum number of iterations for the Jacobian computation.\n    use_stop_crit: bool, optional (default=True)\n        Use stopping criterion in hypergradient computation. If False,\n        run to maximum number of iterations.\n    verbose: bool, optional (default=False)\n        Verbosity of the algorithm.\n    \"\"\"\n\n    def __init__(\n            self, tol_jac=1e-3, max_iter=100, n_iter_jac=100,\n            use_stop_crit=True, verbose=False):\n        self.max_iter = max_iter\n        self.tol_jac = tol_jac\n        self.n_iter_jac = n_iter_jac\n        self.use_stop_crit = use_stop_crit\n        self.verbose = verbose\n\n    def get_beta_jac(\n            self, X, y, log_alpha, model, get_grad_outer, mask0=None,\n            dense0=None, quantity_to_warm_start=None, max_iter=1000, tol=1e-3,\n            full_jac_v=False):\n        \"\"\"Compute beta and hypergradient using implicit forward\n        differentiation.\n\n        Parameters\n        ----------\n        X: array-like, shape (n_samples, n_features)\n            Design matrix.\n        y: ndarray, shape (n_samples,)\n            Observation vector.\n        log_alpha: float or np.array, shape (n_features,)\n            Logarithm of hyperparameter.\n        model:  instance of ``sparse_ho.base.BaseModel``\n            A model that follows the sparse_ho API.\n        get_grad_outer: callable\n            Function which returns the gradient of the outer criterion.\n        mask0: ndarray, shape (n_features,)\n            Boolean of active feature of the previous regression coefficients\n            beta for warm start.\n        dense0: ndarray, shape (mask.sum(),)\n            Initial value of the previous regression coefficients\n            beta for warm start.\n        quantity_to_warm_start: ndarray\n            Previous Jacobian of the inner optimization problem.\n        max_iter: int\n            Maximum number of iteration for the inner solver.\n        tol: float\n            The tolerance for the inner optimization problem.\n        full_jac_v: bool\n            TODO\n        \"\"\"\n\n        mask, dense, jac = get_bet_jac_implicit_forward(\n            X, y, log_alpha, mask0=mask0, dense0=dense0,\n            jac0=quantity_to_warm_start,\n            tol_jac=tol, tol=tol, niter_jac=self.n_iter_jac, model=model,\n            max_iter=self.max_iter, verbose=self.verbose)\n        return mask, dense, jac\n\n    def compute_beta_grad(\n            self, X, y, log_alpha, model, get_grad_outer, mask0=None,\n            dense0=None, quantity_to_warm_start=None, max_iter=1000, tol=1e-3,\n            full_jac_v=False):\n        mask, dense, jac = get_bet_jac_implicit_forward(\n            X, y, log_alpha, mask0=mask0, dense0=dense0,\n            jac0=quantity_to_warm_start,\n            tol_jac=self.tol_jac, tol=tol, niter_jac=self.n_iter_jac,\n            model=model, max_iter=self.max_iter, verbose=self.verbose,\n            use_stop_crit=self.use_stop_crit)\n        jac_v = model.get_jac_v(X, y, mask, dense, jac, get_grad_outer)\n        if full_jac_v:\n            jac_v = model.get_full_jac_v(mask, jac_v, X.shape[1])\n\n        return mask, dense, jac_v, jac\n\n\ndef get_bet_jac_implicit_forward(\n        X, y, log_alpha, model, mask0=None, dense0=None, jac0=None,\n        tol=1e-3, max_iter=1000, niter_jac=1000, tol_jac=1e-6, verbose=False,\n        use_stop_crit=True):\n\n    mask, dense, _ = compute_beta(\n        X, y, log_alpha, mask0=mask0, dense0=dense0, jac0=jac0, tol=tol,\n        max_iter=max_iter, compute_jac=False, model=model, verbose=verbose,\n        use_stop_crit=use_stop_crit)\n    dbeta0_new = model._init_dbeta0(mask, mask0, jac0)\n    reduce_alpha = model._reduce_alpha(np.exp(log_alpha), mask)\n\n    _, dual_var = model._init_beta_dual_var(X, y, mask, dense)\n    jac = get_only_jac(\n        model.reduce_X(X, mask), model.reduce_y(y, mask), dual_var,\n        reduce_alpha, model.sign(dense, log_alpha), dbeta=dbeta0_new,\n        niter_jac=niter_jac, tol_jac=tol_jac, model=model, mask=mask,\n        dense=dense, verbose=verbose, use_stop_crit=use_stop_crit)\n\n    return mask, dense, jac\n\n\ndef get_only_jac(\n        Xs, y, dual_var, alpha, sign_beta, dbeta=None, niter_jac=100,\n        tol_jac=1e-4, model=\"lasso\", mask=None, dense=None, verbose=False,\n        use_stop_crit=True):\n    n_samples, n_features = Xs.shape\n\n    L = model.get_L(Xs)\n\n    residual_norm = []\n\n    if hasattr(model, 'dual'):\n        ddual_var = model._init_ddual_var(dbeta, Xs, y, sign_beta, alpha)\n        dbeta = model.dbeta\n    else:\n        if dbeta is None:\n            dbeta = model._init_dbeta(n_features)\n        ddual_var = model._init_ddual_var(dbeta, Xs, y, sign_beta, alpha)\n\n    for i in range(niter_jac):\n        if verbose:\n            print(\"%i -st iterations over %i\" % (i, niter_jac))\n        if issparse(Xs):\n            model._update_only_jac_sparse(\n                Xs.data, Xs.indptr, Xs.indices, y, n_samples,\n                n_features, dbeta, dual_var, ddual_var, L, alpha, sign_beta)\n        else:\n            model._update_only_jac(\n                Xs, y, dual_var, dbeta, ddual_var, L, alpha, sign_beta)\n        residual_norm.append(\n            model.get_jac_residual_norm(\n                Xs, y, n_samples, sign_beta, dbeta, dual_var,\n                ddual_var, alpha))\n        if use_stop_crit and i > 1:\n            # relative stopping criterion for the computation of the jacobian\n            # and absolute stopping criterion to handle warm start\n            rel_tol = np.abs(residual_norm[-2] - residual_norm[-1])\n            if (rel_tol < np.abs(residual_norm[-1]) * tol_jac\n                    or residual_norm[-1] < 1e-10):\n                break\n    # HACK we only need this for one test, do not rely on it\n    get_only_jac.n_iter = i\n\n    return dbeta",
    "Experiment Result": "The 'Implicit Forward Iterdiff' algorithm is used for hyperparameter optimization (HO) of Lasso-type models, including Lasso, ElasticNet, and Sparse Logistic Regression. The methodology involves a nested bi-level optimization problem, where the inner problem solves for model coefficients and the outer problem optimizes a criterion using gradient-based methods.\n\nKey experimental settings across various examples and experiments include:\n\n1.  **Models & Inner Solvers**: The method is applied to:\n    *   **Lasso**: Typically uses `celer.Lasso(fit_intercept=False, warm_start=True)` or `sklearn.linear_model.Lasso` as the inner solver.\n    *   **ElasticNet**: Uses `celer.ElasticNet(fit_intercept=False, warm_start=True)` or `sklearn.linear_model.ElasticNet`.\n    *   **Sparse Logistic Regression**: Uses `celer.LogisticRegression(penalty='l1', fit_intercept=False)` or `sklearn.linear_model.LogisticRegression` (with 'saga' solver for L1 penalty).\n    Inner solvers are configured with `max_iter` ranging from 50 to 100,000 and `tol` from 1e-5 to 1e-8.\n\n2.  **Outer Optimizers**: Gradient-based methods are employed for the outer optimization problem:\n    *   `LineSearch`: Common settings include `n_outer=10` to `30`, `tol=1e-7`.\n    *   `GradientDescent`: Configured with `n_outer=10` to `75`, `p_grad_norm` (e.g., `1`, `1.5`, `1.9`), `step_size` (often adaptive), and `tol=1e-8`.\n    *   `Adam`: Used with `n_outer=10`, `lr=0.11`, `beta_1=0.9`, `beta_2=0.999`.\n\n3.  **Outer Criteria**: The objective function for HO can be:\n    *   `HeldOutMSE`: Mean Squared Error on a validation set.\n    *   `HeldOutLogistic`: Logistic loss on a validation set.\n    *   `CrossVal`: Cross-validation scores (e.g., 5-fold) based on `HeldOutMSE` or `HeldOutLogistic`.\n    *   `FiniteDiffMonteCarloSure`: Stein Unbiased Risk Estimator.\n\n4.  **Implicit Forward Iterdiff (Algorithm 2) Specifics**: The `ImplicitForward` class parameters are varied:\n    *   `tol_jac`: Tolerance for Jacobian computation ranges from `1e-3` to `1e-8` (and `1e-32` in hypergradient accuracy experiments).\n    *   `n_iter_jac`: Maximum iterations for Jacobian computation, typically `100` to `2000` (up to `5000` for some hypergradient experiments).\n    *   `max_iter`: Maximum iterations for the inner solver, passed to `ImplicitForward`, can be `100` to `50000`.\n    *   `use_stop_crit`: Generally `True` (default), but set to `False` in some hypergradient accuracy tests.\n\n5.  **Datasets**: Experiments are conducted on a variety of datasets:\n    *   **Real-world**: `rcv1` (binary/multiclass), `real-sim`, `news20` (20newsgroups), `leukemia`, `finance`, `mnist`, `usps`, `sector_scale`, `aloi`, MEG data.\n    *   **Synthetic**: `simu` (generated with `make_classification` or `make_correlated_data`).\n    Data splitting typically uses `n_samples // 2` for training and validation, or `KFold` for cross-validation.\n\n6.  **Hyperparameter Initialization & Search Space**:\n    *   **Initialization**: Initial `alpha` or `log_alpha` values (`alpha0`, `log_alpha0`) are commonly set as a fraction of `alpha_max` (e.g., `alpha_max / 5`, `alpha_max / 10`, `0.1 * alpha_max`, `0.9 * alpha_max`).\n    *   **Search Space**: For single hyperparameters (Lasso, LogReg), a logarithmic grid (`np.geomspace`) is used, ranging from `alpha_max` down to `alpha_min` (e.g., `alpha_max / 1_000` to `alpha_max / 100_000`). For two hyperparameters (ElasticNet), 2D grids are constructed (e.g., `n_grid=15` for `alphas_l1` and `alphas_l2`).\n\n7.  **Performance Metrics**: Hyperparameter optimization processes are monitored for:\n    *   Outer criterion value (e.g., validation loss).\n    *   Gradient norm of the outer criterion.\n    *   Computational time.\n    *   Accuracy on validation/test sets (for classification).\n\nOverall, experiments systematically compare `ImplicitForward` against zero-order methods (grid-search, random-search, Bayesian optimization) and other first-order methods (`Forward`, `Implicit`, `Backward`) to demonstrate its efficiency and accuracy, especially in terms of convergence speed and hypergradient computation."
}{
    "Title": "Bayesian Optimization for Iterative Learning",
    "Main Contributions": "The paper introduces Bayesian Optimization for Iterative Learning (BOIL), an approach for efficient hyperparameter tuning that exploits the iterative structure of deep (reinforcement) learning algorithms. It addresses the problem that traditional Bayesian Optimization (BO) often ignores intermediate training information and relies solely on final performance, which is expensive and noisy. BOIL proposes to learn an evaluation function that compresses the entire learning progress into a single numeric score, considering both training success and stability. The framework balances the benefit of assessing hyperparameters over additional training steps against their computational cost and increases efficiency through a selective data augmentation technique. BOIL demonstrates superior performance in identifying optimal hyperparameters in minimal wall-clock time for deep reinforcement learning agents and convolutional neural networks.",
    "Methodology": "BOIL is based on Bayesian Optimization (BO), modeling the cost-sensitive objective function over input hyperparameters (x) and training iterations (t) using a Gaussian Process (GP) with a product covariance kernel. Training time cost c(x,t) is approximated by a linear regressor. The acquisition function maximizes expected improvement while balancing utility against cost. A key innovation is 'training curve compression,' where the entire learning curve is transformed into a single numeric score using a learnable Sigmoid preference function (Logistic function). The parameters of this Sigmoid function are optimized by maximizing the GP's log marginal likelihood. To improve sample efficiency and prevent ill-conditioning of the GP covariance matrix, a selective data augmentation method is employed. This method actively samples a subset of intermediate training points based on maximum GP predictive uncertainty, dynamically adjusting the number of augmented points to ensure the covariance matrix remains well-conditioned.",
    "Experimental Setup": "Experiments were conducted on an NVIDIA 1080 GTX GPU, with results averaged over 20 independent runs. Final performance was estimated by evaluating chosen hyperparameters at the maximum number of iterations. Square-exponential kernels were used for the Gaussian Process. The augmentation strategy used a maximum of 15 augmented points with a threshold of 20 for the natural log of the GP condition number. The method was evaluated by tuning hyperparameters for Dueling DQN on the CartPole-v0 environment, Advantage Actor Critic (A2C) on InvertedPendulum-v2 and Reacher-v2 environments (all from OpenAI gym and Mujoco), and a Convolutional Neural Network on SVHN and CIFAR10 datasets. Baselines for comparison included Hyperband and Continuous Multi-Task/Fidelity BO (CM-T/F-BO), along with ablation studies involving vanilla BO and BO with curve compression (BO-L).",
    "Limitations": "The paper highlights that many existing hyperparameter optimization methods struggle with the unpredictable fluctuations and noisiness of Deep Reinforcement Learning (DRL) reward curves, making techniques like early stopping (e.g., Freeze-thaw BO's exponential decay assumption) often inapplicable. A naive approach of augmenting training data by adding the full learning curve can lead to redundancy and serious ill-conditioning issues for the Gaussian Process covariance matrix, necessitating BOIL's selective augmentation strategy. Furthermore, methods like Hyperband can be misled by early performance fluctuations in noisy DRL tasks. From a broader impact perspective, the authors acknowledge the general dangers of increased automation in ML, such as humans being further removed from the modeling process, potentially making critical failures harder to spot, and contributing to the growing opacity of ML models.",
    "Future Research Directions": "The authors suggest that the BOIL approach is not limited to machine learning algorithms but is generally applicable to any process exhibiting an iterative structure that can be exploited. This opens avenues for applying BOIL to diverse domains, such as optimizing manufacturing pipelines by adjusting factory settings to increase productivity. The work also contributes to the broader goal of constructing automated pipelines for the training and deployment of machine learning models, implying further research into making such pipelines robust and interpretable.",
    "Experiment Code": "import numpy as np\nfrom bayes_opt.acquisition_functions import AcquisitionFunction, unique_rows\nfrom bayes_opt import ProductGaussianProcess\nfrom bayes_opt.acquisition_maximization import acq_max_with_name,acq_min_scipy_kwargs\nimport time\nfrom sklearn import linear_model\nimport copy\nfrom bayes_opt.curve_compression import transform_logistic\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n\nclass BOIL(object):\n\n    def __init__(self, func, SearchSpace,acq_name=\"ei_mu_max\",verbose=1):\n\n        self.method='boil'\n        self.verbose=verbose\n        if isinstance(SearchSpace,dict):\n            self.keys = list(SearchSpace.keys())\n            \n            self.SearchSpace = []\n            for key in list(SearchSpace.keys()):\n                self.SearchSpace.append(SearchSpace[key])\n            self.SearchSpace = np.asarray(self.SearchSpace)\n        else:\n            self.SearchSpace=np.asarray(SearchSpace)\n            \n            \n        self.dim = len(SearchSpace)\n\n        scaler = MinMaxScaler()\n        scaler.fit(self.SearchSpace[:-1,:].T)\n        \n        scalerT = MinMaxScaler()\n        SearchSpace_T=np.atleast_2d(self.SearchSpace[-1,:]).T\n        scalerT.fit(SearchSpace_T)\n\n        self.Xscaler=scaler\n        self.Tscaler=scalerT\n\n        self.scaleSearchSpace=np.array([np.zeros(self.dim), np.ones(self.dim)]).T\n                \n        self.f = func\n    \n        self.X_ori= None\n        self.X = None\n        self.Y = None\n        self.Y_ori = None\n        self.T=None\n        self.T_original=None\n        self.Y_cost_original=None\n        \n        self.time_opt=0\n         \n        self.max_min_gap=self.SearchSpace[:,1]-self.SearchSpace[:,0]\n\n        self.acq_name = acq_name\n        self.logmarginal=0\n\n        self.gp=ProductGaussianProcess(self.scaleSearchSpace,verbose=verbose)\n\n        self.Y_curves=[]\n        self.Y_cost_original=None\n        self.time_opt=0\n        \n        self.acq_func = None\n   \n        self.logmarginal=0\n        \n        self.markVirtualObs=[]\n        \n        self.countVirtual=[]\n\n        self.linear_regression = linear_model.LinearRegression()\n\n        self.condition_number=[]\n        \n        self.max_n_augmentation=10\n        self.threshold_cond=15\n        \n    def init(self, n_init_points=3, seed=1):\n        np.random.seed(seed)\n\n        SearchSpace=np.copy(self.SearchSpace)\n        SearchSpace[-1,0]=SearchSpace[-1,1]\n\n        l = [np.random.uniform(x[0], x[1]) for _ in range(n_init_points) for x in SearchSpace] \n\n        temp=np.asarray(l)\n        temp=temp.T\n        init_X=list(temp.reshape((n_init_points,-1)))\n        \n        self.X_original = np.asarray(init_X)\n        self.T_original=self.X_original[:,-1]\n        self.T_original=np.reshape(self.T_original,(n_init_points,-1))\n        \n        self.X_original=self.X_original[:,:-1]\n        self.X_original=np.reshape(self.X_original,(n_init_points,-1))\n\n        y_init_curves, y_init_cost=self.f(init_X)\n\n        y_init_cost=np.atleast_2d(np.asarray(y_init_cost))\n\n        self.Y_curves+=y_init_curves\n\n        y_init=transform_logistic(y_init_curves,self.gp.logistic_hyper['midpoint'],\\\n                                  self.gp.logistic_hyper['growth'], self.SearchSpace[-1,1])\n        y_init=np.reshape(y_init,(n_init_points,1))\n        \n        self.Y_original = np.asarray(y_init)      \n        self.Y_cost_original=np.reshape(y_init_cost,(-1,1))\n\n        self.X = self.Xscaler.transform(np.asarray(init_X)[:,:-1])\n        self.X=np.reshape(self.X,(n_init_points,-1))\n\n        self.T = self.Tscaler.transform(self.T_original)\n\n        self.markVirtualObs+=[0]*n_init_points\n\n        for ii in range(n_init_points):\n            self.generating_virtual_observations(self.X[ii,:],\\\n                         self.T[ii],[y_init_curves[ii]],y_init_cost[0][ii],IsRandom=False)\n\n        self.Y_cost=(self.Y_cost_original-np.min(self.Y_cost_original))/(np.max(self.Y_cost_original)-np.min(self.Y_cost_original))\n\n        if np.std(self.Y_original)==0:\n            self.Y=(self.Y_original-np.mean(self.Y_original))\n        else:\n            self.Y=(self.Y_original-np.mean(self.Y_original))/np.std(self.Y_original)\n\n       \n    def utility_cost_evaluation(self,x,acq_func,isDebug=False):\n        \n        def utility_cost_evaluation_single(x,acq_func,isDebug=False):\n            utility=acq_func.acq_kind(x,gp=self.gp)\n            \n            try:\n                mean_cost=self.linear_regression.predict(np.reshape(x,(1,-1)))\n                \n            except:\n                print(x)\n                print(\"bug\")\n    \n            mean_cost=max(0,mean_cost)+0.1\n            \n            if 'ei' in acq_func.acq_name:\n                acquisition_function_value= np.log(utility)-np.log(mean_cost)\n            else:\n                acquisition_function_value= np.log(1+np.exp(utility))/np.log(1+np.exp(mean_cost))\n\n            if isDebug==True:\n                print(\"acq_func at the selected point \\t utility:\",np.round(utility,decimals=4),\"\\t cost:\",mean_cost)\n                if utility==0:\n                    print(\"utility =0===============================================================================\")\n       \n            return acquisition_function_value*(-1)\n        \n        \n        if len(x)==self.dim:\n            temp=utility_cost_evaluation_single(x,acq_func,isDebug=isDebug)\n            if isDebug==True:\n                return temp\n            else:\n                utility=np.mean(temp)\n        \n        else:\n            utility=[0]*len(x)\n            for idx,val in enumerate(x):\n                temp=utility_cost_evaluation_single(x=val,acq_func=acq_func,isDebug=isDebug)\n                                                     \n                utility[idx]=np.mean(temp)\n                \n            utility=np.asarray(utility)    \t\t\t\t               \n        return utility   \n    \n        \n    def acq_utility_cost(self):\n\n        acq={}\n        acq['name']=self.acq_name\n        acq['dim']=self.scaleSearchSpace.shape[0]\n        acq['scaleSearchSpace']=self.scaleSearchSpace   \n    \n        if self.acq_name=='ei_mu_max':\n            x_mu_max,mu_max_val=acq_max_with_name(gp=self.gp,scaleSearchSpace=self.scaleSearchSpace,acq_name='mu',IsReturnY=True)\n            acq['mu_max']=  mu_max_val\n\n        myacq=AcquisitionFunction(acq)\n        \n        x_min = acq_min_scipy_kwargs(myfunc=self.utility_cost_evaluation,SearchSpace=self.scaleSearchSpace,\n                        acq_func=myacq, isDebug=False)\n        \n        if self.verbose==True:\n            acq_val=self.utility_cost_evaluation(x_min,myacq,isDebug=False)\n            print(\"selected point from acq func:\",np.round(x_min,decimals=4),\"acq val=log(Utility/Cost)=\",(-1)*np.round(acq_val,decimals=4))\n            if np.round(acq_val,decimals=4)==0:\n                print(\"acq value =0\")\n            \n        return x_min\n    \n    \n    def select_informative_location_by_uncertainty(self,n_virtual_obs,x_max,t_max):\n        \n        SearchSpace=np.copy(self.scaleSearchSpace)\n        for dd in range(self.dim-1):\n            SearchSpace[dd,0],SearchSpace[dd,1]=x_max[dd],x_max[dd]\n            \n        SearchSpace[-1,1]=t_max\n        \n        temp_X,temp_T=self.X.copy(),self.T.copy()\n        temp_gp=copy.deepcopy(self.gp )\n        \n        temp_Y=np.random.random(size=(len(temp_T),1))\n        \n        temp_gp.fit(temp_X,temp_T,temp_Y,self.Y_curves)\n        \n        new_batch_T=None\n\n        pred_var_value=[0]*n_virtual_obs\n        for ii in range(n_virtual_obs):\n            x_max_pred_variance, pred_var_value[ii]=acq_max_with_name(gp=temp_gp,\n                              scaleSearchSpace=SearchSpace,acq_name='pure_exploration',IsReturnY=True)\n            \n            log_cond=np.log( temp_gp.compute_condition_number() )\n            if log_cond>self.threshold_cond or pred_var_value[ii]<(self.gp.noise_delta+1e-3):\n                break\n          \n            if x_max_pred_variance[-1] in temp_T[-ii:]:\n                break\n            \n            temp_X = np.vstack((temp_X, x_max.reshape((1, -1))))\n            temp_T = np.vstack((temp_T, x_max_pred_variance[-1].reshape((1, -1))))\n            temp_gp.X,temp_gp.T=temp_X,temp_T\n            temp_Y=np.random.random(size=(len(temp_T),1))\n            \n            temp_gp.fit(temp_X,temp_T,temp_Y,self.Y_curves)\n\n            if new_batch_T is None:\n                new_batch_T=x_max_pred_variance[-1].reshape((1, -1))\n            else:\n                new_batch_T= np.vstack((new_batch_T, x_max_pred_variance[-1].reshape((1, -1))))\n        \n        if new_batch_T is None:\n            return [],0\n\n        else:\n            output=np.sort(new_batch_T.ravel()).tolist()\n            return output, len(output)\n\n    \n    def generating_virtual_observations(self,x_max,t_max,y_original_curves,y_cost_original,IsRandom=False):\n        \n        temp_X_new_original=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim-1)))\n\n        max_n_virtual_obs=np.int(t_max*self.max_n_augmentation)\n        if max_n_virtual_obs==0:\n            self.countVirtual.append(0)\n            return\n        \n        if IsRandom==True:\n            l = [np.random.uniform(0, t_max) for _ in range(max_n_virtual_obs)]\n        else:\n            l,n_virtual_obs=self.select_informative_location_by_uncertainty(max_n_virtual_obs,x_max,t_max)\n            \n        self.countVirtual.append(n_virtual_obs)\n        \n        if self.verbose:\n            np.set_printoptions(suppress=True)\n            print(\"Max #augmented points\",max_n_virtual_obs, \"\\t #augmented points \",len(l),\n                  \"\\t Augmented points: \",np.round(l,decimals=3))\n            \n        l_original=[self.SearchSpace[-1,0]+val*self.max_min_gap[-1] for val in l]\n                           \n        virtual_obs_t_original=np.asarray(l_original).T\n        virtual_obs_t=np.asarray(l).T\n        \n        y_virtual_original=[0]*n_virtual_obs\n        for ii in range(n_virtual_obs):\n            \n            idx=np.int(virtual_obs_t_original[ii])\n            \n            temp_curve=y_original_curves[0][:idx+1]\n            self.markVirtualObs.append(1)\n\n            y_virtual_original[ii]=transform_logistic([temp_curve],\\\n                      self.gp.logistic_hyper['midpoint'],self.gp.logistic_hyper['growth'],self.SearchSpace[-1,1])\n           \n            self.X = np.vstack((self.X, x_max.reshape((1, -1))))\n            self.X_original=np.vstack((self.X_original, temp_X_new_original))\n        \n            self.T = np.vstack((self.T, virtual_obs_t[ii].reshape((1, -1))))\n            temp=np.asarray(virtual_obs_t_original[ii])\n            self.T_original=np.vstack((self.T_original, temp.reshape((1, -1))))\n\n\n            self.Y_original = np.append(self.Y_original,[y_virtual_original[ii]])\n            self.Y_curves.append(temp_curve)\n            \n            y_cost_estimate=y_cost_original*virtual_obs_t[ii]\n            self.Y_cost_original = np.append(self.Y_cost_original,[y_cost_estimate])\n            \n        \n    def suggest_nextpoint(self):\n \n        self.gp=ProductGaussianProcess(self.scaleSearchSpace,self.gp.hyper,self.gp.logistic_hyper)\n        self.gp.fit(self.X, self.T,self.Y,self.Y_curves)\n            \n        self.condition_number.append(self.gp.cond_num)\n        if self.verbose:\n            print(\"ln of conditioning number of GP covariance matrix\", np.round(np.log(self.gp.cond_num),decimals=1))\n\n        count=len(self.markVirtualObs)-np.sum(self.markVirtualObs)\n        count=np.int(count)\n\n        if  len(self.Y)%(2*self.dim)==0:\n\n            hyper=[self.gp.hyper['lengthscale_x'],self.gp.hyper['lengthscale_t'], \\\n                   self.gp.logistic_hyper['midpoint'],self.gp.logistic_hyper['growth']]\n            newlengthscale_x,newlengthscale_t,new_midpoint, new_growth = self.gp.optimize_lengthscale_logistic_hyper(hyper,self.gp.noise_delta)\n            \n            self.gp.hyper['lengthscale_x']=newlengthscale_x\n            self.gp.hyper['lengthscale_t']=self.gp.hyper['lengthscale_t']\n            self.gp.logistic_hyper['midpoint']=new_midpoint\n            self.gp.logistic_hyper['growth']=new_growth\n          \n            if self.verbose:\n                print(\"==estimated lengthscale_x={:.4f}   lengthscale_t={:.3f}   Logistic_m0={:.1f}   Logistic_g0={:.1f}\".format(\n                    newlengthscale_x,newlengthscale_t,new_midpoint,new_growth))\n                \n        start_opt=time.time()\n\n        combine_input=np.hstack((self.X,self.T))\n        self.linear_regression.fit(combine_input,self.Y_cost)\n        \n        x_max_temp=self.acq_utility_cost()\n        x_max=x_max_temp[:-1]\n        t_max=x_max_temp[-1]       \n            \n        finished_opt=time.time()\n        elapse_opt=finished_opt-start_opt\n        self.time_opt=np.hstack((self.time_opt,elapse_opt))\n\n        self.markVirtualObs.append(0)\n\n        self.X = np.vstack((self.X, x_max.reshape((1, -1))))\n        self.T = np.vstack((self.T, t_max.reshape((1, -1))))\n\n        temp_X_new_original=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim-1)))\n        self.X_original=np.vstack((self.X_original, temp_X_new_original))\n        \n        temp_T_new_original=self.Tscaler.inverse_transform(np.reshape(t_max,(-1,1)))\n        self.T_original=np.vstack((self.T_original, temp_T_new_original))\n\n        x_original_to_test=x_max_temp*self.max_min_gap+self.SearchSpace[:,0]\n\n        y_original_curves, y_cost_original= self.f(x_original_to_test)\n        \n        y_original=transform_logistic(y_original_curves,\\\n              self.gp.logistic_hyper['midpoint'],self.gp.logistic_hyper['growth'],self.SearchSpace[-1,1])\n        \n        if len(y_original_curves)==1:\n            self.Y_curves.append(y_original_curves[0])\n        else:\n            self.Y_curves.append(y_original_curves)\n\n        \n        self.Y_original = np.append(self.Y_original,y_original)\n        self.Y_cost_original = np.append(self.Y_cost_original,y_cost_original)\n\n        self.generating_virtual_observations(x_max,t_max,y_original_curves,y_cost_original[0])\n        \n        if np.std(self.Y_original)==0:\n            self.Y=(self.Y_original-np.mean(self.Y_original))\n        else:\n            self.Y=(self.Y_original-np.mean(self.Y_original))/np.std(self.Y_original)\n            \n        self.Y_cost=(self.Y_cost_original-np.min(self.Y_cost_original))/(np.max(self.Y_cost_original)-np.min(self.Y_cost_original))\n                    \n        np.set_printoptions(suppress=True)\n\n        print(\"[original scale] x={} t={:.0f} current y={:.2f}, ybest={:.2f}\".format( np.round(self.X_original[-1],decimals=4),\\\n              np.asscalar(self.T_original[-1]),np.asscalar(self.Y_original[-1]), np.asscalar(self.Y_original.max())))\n",
    "Experiment Result": "BOIL (Bayesian Optimization for Incremental Learning) is implemented in the `BOIL` class. It uses a `ProductGaussianProcess` for modeling the objective function over hyperparameters (x) and training iterations (t), and a `linear_model.LinearRegression` to approximate the training time cost c(x,t).\n\nThe acquisition function, specified as `acq_name=\"ei_mu_max\"`, maximizes expected improvement while balancing utility against cost. This balance is calculated as `np.log(utility) - np.log(mean_cost)` (for 'ei' acquisition) or `np.log(1 + np.exp(utility)) / np.log(1 + np.exp(mean_cost))` (otherwise). The `ei_mu_max` variant uses the maximum of the GP's predictive mean function as the incumbent value `y_max` for expected improvement calculation.\n\nTraining curve compression is performed using a learnable Sigmoid preference function (Logistic function). The parameters of this function (`midpoint` and `growth`) are optimized alongside the Gaussian Process hyperparameters (`lengthscale_x`, `lengthscale_t`) by maximizing the GP's log marginal likelihood. This joint optimization occurs every `2 * self.dim` iterations.\n\nSelective data augmentation is employed to improve sample efficiency and maintain a well-conditioned GP covariance matrix. Intermediate training points are actively sampled based on maximum GP predictive uncertainty using the `pure_exploration` acquisition function. The number of augmented points for a given observation is dynamically adjusted, capped by `self.max_n_augmentation=10` times the selected `t_max` (normalized), and stops if the logarithm of the GP's covariance matrix condition number (`np.log(self.gp.cond_num)`) exceeds `self.threshold_cond=15` or if the predictive variance is very small. Initial observations are `n_init_points=3` and each initial point also generates virtual observations. The maximum episode length for curve compression is derived from `self.SearchSpace[-1,1]`."
}

# Instructions
Following the instructions below, please provide an evaluation of the new hypothesis.
Since I aim to pursue research of high academic significance, I request that the assessment be conducted with rigorous standards.
- output
    - novelty_reason
        - Determine whether the new hypothesis has novelty, and output the reason.
        - The reason should be as specific as possible.
        - Carefully review the content of the studies provided in "Related Works" before outputting.
    - novelty_score
        - Score the novelty of the new hypothesis on a scale of 1 to 10, where 1 means no novelty at all and 10 means extremely high novelty.
    - significance_reason
        - Determine whether the new hypothesis is significant, and output the reason.
        - Significance includes both academic and societal importance.
    - significance_score
        - Score the significance of the new hypothesis on a scale of 1 to 10, where 1 means no significance at all and 10 means extremely high significance.
Output:
{'novelty_reason': 'Existing PEFT methods already adapt a fixed or dynamically–pruned low-rank subspace, but none of the cited work lets the model itself decide which individual singular directions of Spectral-AdapterA to keep.  Spectral Adapter (and SVFT, S4, ReFT, etc.) always fixes r or sparsity pattern beforehand; AdaLoRA prunes LoRA’s rank but operates in weight space, not along pre-computed singular vectors.  The proposed WSA introduces per-direction learnable gates with an ℓ1 sparsity penalty so that (1) the top-r SVD basis is still used, preserving Spectral-Adapter’s theory, yet (2) the effective rank is automatically selected during fine-tuning and can vary across layers and tasks, a capability absent from prior spectral PEFT papers.  This fine-grained ‘spectral rank search’ therefore represents an incremental but clear technical novelty over the closest prior art.', 'novelty_score': 6, 'significance_reason': 'Choosing the rank hyper-parameter is a practical pain-point for Spectral Adapter users; WSA removes this manual sweep at virtually no extra memory/compute and can even yield slightly higher accuracy while keeping inference cost constant through pruning.  Academically, it extends the spectral-PEFT line with the first adaptive-rank variant, potentially inspiring follow-up work on spectral sparsification and adaptive capacity control.  Societally, the impact is modest: it offers a more user-friendly and possibly better PEFT recipe for moderate-size language models, but does not open a fundamentally new research area or unlock qualitatively new capabilities.', 'significance_score': 6}
